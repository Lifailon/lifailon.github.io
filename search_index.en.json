[{"url":"https://lifailon.github.io/","title":"Home","description":null,"body":"\n\n    \n\n\n    \n    \n    \n    \n    \n\n\n\n    Веб-версия заметок по PowerShell, командам Linux, инструментам DevOps и сервисам Docker Compose из репозитория ruDocs, а также синтаксису Go и Node.js на русском языке, собранные на пути от системного администратора Windows систем до инженера DevOps.\n\n\nПожалуйста, ознакомьтесь с другими проектами на ⭐ GitHub:\n\n\nlazyjournal - терминальный пользовательский интерфейс (TUI) для просмотра логов из journald, auditd, файловой системы, контейнеров Docker и Podman, стеков Compose и подов Kubernetes с поддержкой подсветки вывода и нескольких режимов фильтрации. Написан на Go с использованием библиотеки gocui.\n\n\nmultranslate - терминальный пользовательский интерфейс на базе библиотеки Blessed для одновременного перевода текста с использованием нескольких популярных источников перевода (настройка доступа к API не требуется). Поддерживается использование ИИ (включая локальные LLM и бесплатные модели на OpenRouter), определение исходного и целевого языка на уровне кода, а также сохранение истории переводов в SQLite.\n\n\nTorAPI - неофициальный API (backend) на базе Express для торрент трекеров RuTracker, Kinozal, RuTor и NoNameClub. Используется для быстрого и централизованного поиска раздач, получения торрент файлов, магнитных ссылок и подробной информации о раздаче по названию фильма, сериала или идентификатору раздачи, а также предоставляет новостную RSS ленту для всех провайдеров с фильтрацией по категориям.\n\n\nLibreKinopoisk - расширение для Google Chrome, Mozilla Firefox и мобильных устройств, которое добавляет кнопки на сайт Кинопоиск и в контекстное меню браузера, а также реализует интерфейс (frontend) TorAPI в стиле Jackett для быстрого поиска фильмов и сериалов в открытых источниках без использования VPN.\n\n\nKinozal-Bot - это Telegram бот, который позволяет автоматизировать процесс доставки контента до вашего телевизора, используя только телефон. Предоставляет удобный интерфейс для взаимодействия с торрент трекером Кинозал и базой данных TMDB для отслеживания даты выхода серий, сезонов и поиска актеров для каждой серии, а также возможность управлять торрент клиентом qBittorrent или Transmission на вашем компьютере, находясь удаленно от дома и из единого интерфейса.\n\n\nssh-bot - менеджер SSH подключений в Telegram, который позволяет выполнять команды на выбранном хосте в вашей домашней сети и возвращать результат их выполнения. Бот не устанавливает постоянного соединения с удалённым хостом, что позволяет выполнять команды асинхронно. Такое решение предоставляет возможность не тратить время на настройку VPN и деньги на внешний IP адрес или VPS сервер для доступа в локальную сеть, а также исключает необходимость использования сторонних приложений (VPN и ssh клиентов) на удаленном устройстве и не требует стабильного подключения к Интернету.\n\n\nOpenRouter-Bot - этот проект позволяет за несколько минут запустить своего Telegram бота для общения с бесплатными или платными моделями AI через OpenRouter или локальными LLM, например, через LM Studio.\n\n\nlogporter - простая и легкая альтернатива cAdvisor для получения всех базовых метрик из контейнеров Docker с поддержкой пользовательских метрик по логам. По сравнению с cAdvisor, среднии показатели потребления CPU в 15–20 раз, а потребление памяти в 10 раз ниже.\n\n\nFroxy - прямой и обратный прокси сервер на базе .NET для запуска в режиме командной строки или контейнере Docker. Поддерживает проксирование HTTPS трафика (CONNECT запросы) и протокол SOCKS5 для туннелирования TCP трафика, а также TCP, UDP и HTTP/HTTPS протоколы для обратоного проксирования (поддерживается обработка GET и POST запросов с передачей заголовков и тела запроса для работы с API и передачи Cookie).\n\n\nIntelli Shell - это обработчик, работающий поверх оболочки Bash и реализующий механизм автодополнения команд с использованием выпадающего списка в режиме реального времени. Вы можете просматривать историю выполненных команд с поддержкой фильтрации и регулярных выражений, а также использовать навигацию по каталогам, не покидая текущую строку ввода.\n\n\nRSA (Remote Shadow Administrator) - интерфейс для удаленного подключения к текущим RDP сессиям пользователей на базе RDShadow и WinForms. Также содержит набор модулей для автоматизации удаленного администрирования и управления ОС Windows (пользовательские процессы, службы, обновления, настройки KMS, NTP и другие функции).\n\n\nWinAPI - веб-сервер для удаленного управления ОС Windows через браузер или REST-запросы (например, curl в Linux). Запуск и остановка служб и процессов, получение информации о системе, просмотр и фильтрация журналов событий (логов) в браузере и другие функции. Статья на Хабр: REST API/Web сервер на PowerShell.\n\n\niPerf-GUI - графический интерфейс для управления клиентом и сервером iperf3.\n\n\nPST-Export-GUI - графический интерфейс для сбора статистики состояния почтовых ящиков, баз данных, DAG и просмотра Message Tracking Log, а также создания и управления заданями экспорта почтовых ящиков в формате PST на серверах MS Exchange.\n\n\nAD-Manager - графический интерфейс для автоматизации создания УЗ, а также управления группами, пользователями и хостами в Active Directory.\n\n\n","path":null},{"url":"https://lifailon.github.io/powershell/","title":"PowerShell","description":null,"body":"\n    \n\n\n    Большая база заметок PowerShell на русском языке.\n\nPowerShell - это объектно-ориентированный и кроссплатформенный язык программирования с открытым исходным кодом (начиная с 6-ой версии Core). Он способен напрямую взаимодействовать с классами и методами C# через платформу .NET, что позволяет создавать программы с графическим интерфейсом на базе WinForms или WPF, TUI на базе Terminal.Gui, веб-сервера и REST API с помощью класса HttpListener или Pode framework, управлять браузером с помощь библиотеки Selenium, базами данных (поддерживается большенство СУБД через ODBC драйверы или .NET коннекторы) и языками разметки (нативная поддержка XML, JSON и CSV, а также другими с помощью модулей или парсинг HTML через библиотеку HAP) как с любыми другими объектами за счет типовой экосистемы взаимодействия. Такой язык в первую очередь будет полезен DevOps инженерам и системным администраторам, так как является незаменимым инструментом для автоматизации Windows систем, управления облачной инфрастуры Microsoft Azure и компонентами Windows Server, такими как Hyper-V, Active Directory, MS Exchange, DNS, DHCP, SMB и другими.\n\n\nCheat-Sheet\n\n\nHelp\nGet-Verb действия/глаголы, утвержденные для использования в командлетах \nGet-Command *Language* поиск команды по имени \n(Get-Command Get-Language).Module узнать к какому модулю принадлежит команда \nGet-Command Get-Content | fl Module,DLL узнать принадлежность команды к модулю и dll \nGet-Command -Module LanguagePackManagement отобразить список команд указанного модуля \n(Get-Module LanguagePackManagement).ExportedCommands.Values отобразить список команд указанного модуля \nGet-Language | Get-Member отобразить список методов команды (действия), объекты вывода и Event (события объектов: Click) \n(Get-Help Get-Service).Aliases узнать псевдонимом команды \nGet-Alias gsv узнать имя команды по псевдониму \nGet-Help Get-Service синтаксис \nGet-Help Get-Service -Parameter * описание всех параметров \nGet-Help Get-Service -Online \nGet-Help Get-Service -ShowWindow описание параметров в GUI с фильтрацией \nShow-Command вывести список команд в GUI \nShow-Command Get-Service список параметров команды в GUI \nInvoke-Expression iex принимает текст для выполнения в консоли как команды \n$PSVersionTable текущая версия PowerShell \nSet-ExecutionPolicy Unrestricted \nGet-ExecutionPolicy \n$Metadata = New-Object System.Management.Automation.CommandMetaData (Get-Command Get-Service) получить информацию о командлете \n[System.Management.Automation.ProxyCommand]::Create($Metadata) исходный код функции\n\nObject\n\nVariable\n$var = Read-Host \"Enter\" ручной ввод \n$pass = Read-Host \"Enter Password\" -AsSecureString скрывать набор \n$global:path = \"\\\\path\" задать глобальную переменную, например в функции \n$using:srv использовать переменную текущей сесси в Invoke-сессии \nGet-Variable отобразить все переменные \nls variable:/ отобразить все переменные \nGet-Variable *srv* найти переменную по имени \nGet-Variable -Scope Global отобразить все глобальные переменные \nGet-Variable Error последняя команда с ошибкой \nRemove-Variable -Name * очистить все переменные \n$LASTEXITCODE содержит код вывода последней запущенной программы, например ping. Если код возврата положительный (True), то $LastExitCode = 0\n\nENV\nGet-ChildItem Env: отобразить все переменные окружения \n$env:PSModulePath директории импорта модулей \n$env:userprofile \n$env:computername \n$env:username \n$env:userdnsdomain \n$env:logonserver \n([DirectoryServices.ActiveDirectory.Forest]::GetCurrentForest()).Name \n[Environment]::GetFolderPath('ApplicationData')\n\nHistory\nGet-History история команд текущей сессии \n(Get-History)[-1].Duration.TotalSeconds время выполнения последней команды \n(Get-PSReadLineOption).HistorySavePath путь к сохраненному файлу с 4096 последних команд (из модуля PSReadLine) \nGet-Content (Get-PSReadlineOption).HistorySavePath | Select-String Get поиск по содержимому файла (GREP) \nSet-PSReadlineOption -MaximumHistoryCount 10000 изменить количество сохраняемых команд в файл \nGet-PSReadLineOption | select MaximumHistoryCount \nSet-PSReadlineOption -HistorySaveStyle SaveNothing отключить ведение журнала \nF2 переключиться с InlineView на ListView\n\nClipboard\nSet-Clipboard $srv скопировать в буфер обмена \nGet-Clipboard вставить\n\nWrite-Host\n\nWrite-Error \"False\" \nWrite-Warning \"False\"\n\nWrite-Progress\n\n\nfor\n\n\nArray\n$srv = @(\"server-01\", \"server-02\")  создать массив \n$srv += @(\"server-03\") добавить в массив новый элемент \n$srv.Count отобразить кол-во элементов в массиве \nOut-String построчный вывод\n\nIndex\n$srv[0] вывести первое значение элемента массива \n$srv[0] = Name замена элемента в массиве \n$srv[0].Length узнать кол-во символов первого значения в массиве \n$srv[10..100] срез\n\n\nHashTable\n\n$hashtable.Keys список всех ключей \n$hashtable[\"User\"] получить значение (Values) по ключу \n$hashtable[\"User\"] = \"Test\" изменить \n$hashtable.Remove(\"User\") удалить ключ\n\nCollections/List\n\n\nPSCustomObject\n\n\nAdd and Remove Property\n$CustomObject | Add-Member –MemberType NoteProperty –Name Arr –Value @(1,2,3) добавить свойство/стобец \n$CustomObject.Arr = @(1,3,5) изменить содержимое \n$CustomObject.PsObject.Properties.Remove('User') удалить Property\n\nAdd Method\n\n\nClass\n\n$Class = New-Object -TypeName CustomClass \n$Class.User = $env:username \n$Class.Server = $env:computername \n$Class.Start(1)\n\nPipeline\n$CustomObject | Add-Member -MemberType NoteProperty -Name \"Type\" -Value \"user\" -Force добавление объкта вывода NoteProperty \n$CustomObject | Add-Member -MemberType NoteProperty -Name \"User\" -Value \"admin\" -Force изменеие содержимого для сущности объекта User \nping $srv | Out-Null перенаправить результат вывода в Out-Null\n\nSelect-Object\nGet-Process | Select-Object -Property * отобразить все доступные объекты вывода \nGet-Process | select -Unique \"Name\" удалить повторяющиеся значения в массиве \nGet-Process | select -ExpandProperty ProcessName преобразовать из объекта-коллекции в массив (вывести содержимое без наименовая столбца) \n(Get-Process | ? Name -match iperf).Modules список используемых модулей процессом\n\nExpression\n\n\nSelect-String\n$(ipconfig | Select-String IPv4) -replace \".+: \" | Where-Object {$_ -match \"^172.\"} узнать только IP \n$Current_IP = Get-Content $RDCMan_RDG_PATH | Select-String $RDCMan_Display_Name -Context 0,1 получить две строки \n$Current_IP = $Current_IP.Context.DisplayPostContext[0] -replace \".+&lt;name&gt;|&lt;\\/name&gt;\" забрать только вторую строку и удалить тэги\n\nFormat-List/Format-Table\nGet-Process | fl ProcessName, StartTime \nGet-Process | ft ProcessName, StartTime -Autosize автоматическая группировка размера столбцов\n\nMeasure-Object\nGet-Process | Measure | select Count кол-во объектов \nGet-Process | Measure -Line -Word -Character кол-во строк, слов и Char объектов \nGet-Process | Measure-Object PM -sum | Select-Object Count,@{Name=\"MEM_MB\"; Expression={[int]($_.Sum/1mb)}} кол-во процессов и общий объем занятой памяти в МБайт\n\nCompare-Object\nCompare-Object -ReferenceObject (Get-Content -Path .\\file1.txt) -DifferenceObject (Get-Content -Path .\\file2.txt) сравнение двух файлов \n$group1 = Get-ADGroupMember -Identity \"Domain Admins\" \n$group2 = Get-ADGroupMember -Identity \"Enterprise Admins\" \nCompare-Object -ReferenceObject $group1 -DifferenceObject $group2 -IncludeEqual сравнение друх объектов\n== нет изменений \n&lt;= есть изменения в $group1 \n=&gt; есть изменения в $group2\n\nWhere-Object (?)\nGet-Process | Where-Object {$_.ProcessName -match \"zabbix\"} фильтрация/поиск процессов по имени свойства объекта \nGet-Process | where CPU -gt 10 | Sort-Object -Descending CPU вывести объекты, где значения CPU больше 10 \nGet-Process | where WS -gt 200MB отобразить процессы где WS выше 200МБ \nGet-Service | where Name -match \"zabbix\" поиск службы \nGet-Service -ComputerName $srv | Where {$_.Name -match \"WinRM\"} | Restart-Service перезапустить службу на удаленном компьютере \n(Get-Service).DisplayName вывести значения свойства массива \nnetstat -an | where {$_ -match 443} \nnetstat -an | ?{$_ -match 443} \n(netstat -an) -match 443\n\nSort-Object\nGet-Process | Sort-Object -Descending CPU | ft обратная (-Descending) сортировка по CPU \nGet-Process | Sort-Object -Descending cpu,ws сортировка по двум свойствам \n$path[-1..-10] обратная сборка массива без сортировки \n$arr = @(1..20); $arr[$($arr.Count - 1)..0] пересобрать массив с конца\n\nLast/First\nGet-Process | Sort-Object -Descending CPU | select -First 10 вывести первых 10 объектов \nGet-Process | Sort-Object -Descending CPU | select -Last 10 вывести последних 10 объектов\n\nGroup-Object\n\n\nProperty\n$srv.Count кол-во элементов в массиве \n$srv.Length содержит количество символом строки переменной [string] или количество значений (строк) объекта \n$srv.Chars(2) отобразить 3-й символ в строке \n$srv[2] отобразить 3-ю строку в массиве\n\nMethod\n$srv = \"127.0.0.1\" \n$srv.Insert(0,\"https://\") добавить значение перед первым символом \n$srv.Substring(4) удалить (из всего массива) первые 4 символа \n$srv.Remove(3) удалить из всего массива все после 3 символа \n$string = \"123\" создать строку \n$int = [convert]::ToInt32($string) преобразовать строку в тип данных число \n[string]::Concat($text,$num) объеденить переменные в одну строку \n[string]::Join(\":\",$text,$num) объеденить используя разделитель \n[string]::Compare($text,$num,$true) выдает 0 при совпадении или 1/-1 при несовпадении, $true (без учета регистра) или $false (с учетом регистра) \n[string]::Equals($text,$num) производит сравнение двух строк и выдает $true при их совпадении или $false при несовпадении \n[string]::IsNullOrEmpty($text) проверяет наличие строки, если строка пуста $true, если нет $false \n[string]::IsNullOrWhiteSpace($text2) проверяет на наличие только символов пробел, табуляция или символ новой строки\n\nError\n$Error выводит все ошибки текущего сеанса \n$Error[0].InvocationInfo развернутый отчет об ошибке \n$Error.clear() \n$LASTEXITCODE результат выполнения последней команды (0 - успех) \nexit 1 код завершения, который возвращается $LASTEXITCODE\n\nExecutionStatus\n\n\nMeasure-Command\n$(Measure-Command {ping ya.ru}).TotalSeconds получить время выполнения в секундах\n\nDateTime\n[DateTime]::UtcNow время в формате UTC 0 \n$(Get-Date).AddHours(-3) вычесть три часа из текущего времени \n$Date = $(Get-Date -Format \"dd/MM/yyyy HH:mm:ss\") изменить формат отображения времени \n$Date = Get-Date -f \"dd/MM/yyyy\" получаем тип данных [string] $($Date.GetType().Name) \n$Date = \"19.05.2024\" \n[DateTime]$Date = Get-Date \"$Date\" преобразовать строку подходящую под формат даты в тип данных [DateTime] \n$BeforeDate = Get-Date \"12.05.2024\" \n[int32]$days=$($Date - $BeforeDate).Days посчитать разницу в днях \n\"5/7/07\" -as [DateTime] преобразовать входные данные в тип данных [DateTime]\n\nTimeSpan\nNew-TimeSpan -Start $(Get-Date) -End $($(Get-Date).AddMinutes(+1)) получить разницу во времени \n$TimeZone = (Get-TimeZone).BaseUtcOffset.TotalMinutes получить разницу в минутах от текущего часового пояса относительно UTC 0 \n$UnixTime  = (New-TimeSpan -Start (Get-Date \"01/01/1970\") -End ((Get-Date).AddMinutes(-$tz))).TotalSeconds вычесть минуты для получения UTC 0 \n$TimeStamp = ([string]$UnixTime -replace \"\\..+\") + \"000000000\" получить текущий TimeStamp\n\nFormat\n\n\nTimer\n$start_time = Get-Date зафиксировать время до выполнения команды \n$end_time = Get-Date зафиксировать время по завершению \n$time = $end_time - $start_time высчитать время работы скрипта \n$min = $time.minutes \n$sec = $time.seconds \nWrite-Host \"$min минут $sec секунд\"\n$timer = [System.Diagnostics.Stopwatch]::StartNew() запустить таймер \n$timer.IsRunning статус работы таймера \n$timer.Elapsed.TotalSeconds отобразить время с момента запуска (в секундах) \n$timer.Stop() остановить таймер\n\nRegex\n\n\nЯкори\n^ или \\A определяет начало строки ($url -replace '^','https:' - добавить текст в начало строки) \n$ или \\Z обозначают конец строки ($ip -replace \"\\d{1,3}$\",\"0\") \n(?=text) поиск слова слева. Пишем слева на право от искомого (ищет только целые словосочетания - \"Server:\\s(.{1,30})\\s(?=$username)\") \n(?&lt;=text) поиск слова справа ($in_time -replace \".+(?&lt;=Last)\" - удалить все до Last) \n(?!text) не совпадает со словом слева \n(?&lt;!text) не совпадает со словом справа\n$test = \"string\" \n$test -replace \".{1}$\" удалить любое кол-во символов в конце строки \n$test -replace \"^.{1}\" удалить любое кол-во символов в начале строки\n\nГруппы захвата\n$date = '12.31.2021' \n$date -replace '^(\\d{2}).(\\d{2})','$2.$1' поменять местами \n$1 содержимое первой группы в скобках \n$2 содержимое второй группы\n-replace \"1\",\"2\" замена элементов в индексах массива (везде где присутствует 1, заменить на 2), для удаления используется только первое значение \n-split \" \" преобразовать строку в массив, разделителем указан пробел, которой удаляется ($url.Split(“/”)[-1]) \n-join \" \" преобразовать массив (коллекцию) в единую строку (string), добавить разделителем пробел\n@(1,2,3) -contains 3 проверить, что элемент справа содержится в массиве слева \n@(1,2) -notcontains 3 проверить, что элемент справа не содержится в массиве слева\n-like *txt* поиск по маскам wildcard, выводит значение на экран \n-match txt поиска по шаблонам, проверка на соответствие содержимого текста \n-match \"zabbix|rpc\" условия, для поиска по нескольким словам \n-NotMatch проверка на отсутствие вхождения \\\n\nMatches\n\"num: 777\" -match \"num: ([0-9]+)\" | Out-Null \n$Matches[1] выводим только номер\n$ip = \"192.168.10.1\" \n$ip -match \"(\\.\\d{1,3})\\.\\d{1,2}\" True \n$Matches отобразить все подходящие переменные последнего поиска, которые входят и не входят в группы ()\n$String = \"09/14/2017 12:00:27 - mtbill_post_201709141058.txt 7577_Delivered: OK\" \n$String -Match \".*(?=\\.txt)\" | Out-Null \n$Matches[0][-4..-1] -Join \"\"\n$string.Substring($string.IndexOf(\".txt\")-4, 4) 2-й вариант (IndexOf)\n\nФорматирование\n[string]::Format(\"{1} {0}\",\"Index0\",\"Index1\") \n\"{1} {0}\" -f \"Index0\",\"Index1\" \n\"{0:###-##-##}\" -f 1234567 записать число в другом формате (#) \n\"{0:0000}\" -f 123 вывести число в формате не меньше 4 знаков (0123) \n\"{0:P0}\" -f (220/1000) посчитать в процентах (P) \n\"{0:P}\" -f (512MB/1GB) сколько % составляет 512Мб от 1Гб \n\"{0:0.0%}\" -f 0.123 умножить на 100%\n\n\nУсловный оператор\n\nЕсли условие if () является истенным ($True), выполнить действие в {} \nЕсли условие if () является ложным ($False), выполнить действие не обязательного оператора else \nУсловие Elseif идёт после условия if для проверки дополнительных условий перед выполнение оператора else. Оператор, который первый вернет $True, отменит выполнение следующих дополнительных условий \nЕсли передать переменную в условие без оператора, то будет проверяться наличие значения у переменной на $True/$False \\\n\n\nЛогические операторы сравнения\n-eq равно (equal) \n-ceq учитывать регистр \n-ne не равно (not equal) \n-cne не равно учитывая регистр \n-gt больше (greater) \n-ge больше или равно \n-lt меньше (less) \n-le меньше или равно \n-in проверить на наличие (5 -in @(1,2,3,4,5)) \n-NOT логическое НЕТ !(Test-Path $path) \n-and логическое И \n-or логическое ИЛИ \\\n\n\nPipeline Operators\nWrite-Output \"First\" &amp;&amp; Write-Output \"Second\" две успешные команды выполняются \nWrite-Error \"Bad\" &amp;&amp; Write-Output \"Second\" первая команда завершается ошибкой, из-за чего вторая команда не выполняется \nWrite-Error \"Bad\" || Write-Output \"Second\" первая команда завершается ошибкой, поэтому выполняется вторая команда \nWrite-Output \"First\" || Write-Output \"Second\" первая команда выполнена успешно, поэтому вторая команда не выполняется\n\nInvocation Operator\n$addr = \"8.8.8.8\" \n$ping = \"ping\" \n&amp; $ping $addr запускает текст как команду\n&amp; $ping $addr &amp; запустить команду в фоне \n(Get-Job)[-1] | Receive-Job -Keep\n\nDataType\n$srv.GetType() узнать тип данных \n$srv -is [string] проверка на соответствие типа данных \n$srv -isnot [System.Object] проверка на несоответствие \n[Object] массив (BaseType:System.Array) \n[DateTime] формат времени (BaseType:System.ValueType) \n[Bool]/[Boolean] логическое значение ($True/$False) или 1/0 (1 бит) наличие/отсуствие напряжения \n[Byte] 8-битное (1 байт) целое число без знака (0..255) \n[Int16] 16-битное знаковое целое число от -32767 до 32767 (тип данных WORD 0..65535) \n[Int] 32-битное (4 байта) знаковое целое число от –2147483648 до 2147483647 (DWORD) \n[Int64] 64-битное от -9223372036854775808 до 9223372036854775808 (LWORD) \n[Decimal] 128-битное десятичное значение от –79228162514264337593543950335 до 79228162514264337593543950335 \n[Single] число с плавающей запятой (32-разрядное) \n[Double] число с плавающей запятой с двойной точностью (64-разрядное) \n[String] неизменяемая строка символов Юникода фиксированной длины (BaseType:System.Object)\n\nMath\n[math] | Get-Member -Static \n[math]::Pow(2,4) 2 в 4 степени \n[math]::Truncate(1.8) грубое округление, удаляет дробную часть \n[math]::Ceiling(1.8) округляет число в большую сторону до ближайшего целого значения \n[math]::Floor(-1.8) округляет число в меньшую сторону \n[math]::Min(33,22) возвращает наименьшее значение двух значений \n[math]::Max(33,22) возвращает наибольшее значение двух значений\n\nRound\n[double]::Round(87.5, 0) 88 (нечетное), в .NET по умолчанию используется округление в средней точке ToEven, где *.5 значения округляются до ближайшего четного целого числа \n[double]::Round(88.5, 0) 88 (четное) \n[double]::Round(88.5, 0, 1) 89 (округлять в большую сторону) \n[double]::Round(1234.56789, 2) округлить до 2 символов после запятой\n\nToString\n(4164539/1MB).ToString(\"0.00\") разделить на дважды на 1024/1024 и округлить до 3,97\n\nChar\n[Char] cимвол Юникода (16-разрядный) \n$char = $srv.ToCharArray() разбить строку [string] на массив [System.Array] из букв\n\nFunction\n\nSwitch function\n\n\nSwitch param\n\nfun-switch -param\n\npsm1 (module file and parameters)\n\nGet-Function -Text Text1 \nGet-Function -Text Text2 -Provider Test2 -Number 3\n\npsd1 (module description file)\n\n\nBit\n\n\nBit Convertor\n\nConvertTo-Bit 347\n\nConvertFrom-Bit 10010011\nGet-Process pwsh | fl ProcessorAffinity привязка процесса к ядрам, представляет из себя битовую маску (bitmask), где каждому биту соответствует ядро процессора. Если для ядра отмечено сходство (affinity), то бит выставляется в 1, если нет — то в 0. Например, если выбраны все 16 ядер, то это 1111 1111 1111 1111 или 65535. \n$(Get-Process pwsh).ProcessorAffinity = 15 0000000000001111 присвоить 4 первых ядра \n$(Get-Process pwsh).ProcessorAffinity = 61440 1111000000000000 присвоить 4 последних ядра \n$(Get-Process pwsh).ProcessorAffinity = (ConvertFrom-Bit 1111000000000000)\n\nCycle\n\nForeach\n$list = 100..110 создать массив из цифр от 100 до 110 \nforeach ($srv in $list) {ping 192.168.3.$srv -n 1 -w 50} $srv хранит текущий элемент из $list и повторяет команду до последнего элемента в массиве \n$foreach.Current текущий элемент в цикле \n$foreach.Reset() обнуляет итерацию, перебор начнется заново, что приводит к бесконечному циклу \n$foreach.MoveNext() переход к следующему элементу в цикле\n\nForEach-Object (%)\n\n%  передать цикл через конвеер (ForEach-Object) \n$_ переменная цикла и конвеера ($PSItem) \ngwmi Win32_QuickFixEngineering | where {$_.InstalledOn.ToString() -match \"2022\"} | %{($_.HotFixID.Substring(2))} gwmi создает массив, вывод команды передается where для поиска подходящих под критерии объектов. По конвееру передается в цикл для удаления первых (2) символов методом Substring из всех объектов HotFixID.\n\nWhile\n\n\nTry-Catch-Finally\n\n\nFiles\nGet-Content $home/desktop\\test.txt -Wait аналог tail \nTest-Path $path проверить доступность пути \nGet-FileHash -Algorithm SHA256 \"$path\" узнать хэш файла по алгоритму sha256 \nGet-ChildItem $path -Filter *.txt -Recurse отобразить содержимое каталога (Alias: ls/gci/dir) и дочерних каталогов (-Recurse) и отфильтровать вывод \nGet-Location отобразить текущие месторасположение (Alias: pwd/gl) \nSet-Location $path перемещение по каталогам (Alias: cd/sl) \nInvoke-Item $path открыть файл (Alias: ii/start) \nGet-ItemProperty $env:userprofile\\Documents\\dns-list.txt | select FullName,Directory,Name,BaseName,Extension свойтсва файла \nGet-ItemProperty -Path $path\\* | select FullName,CreationTime,LastWriteTime свойства файлов содержимого директории, дата их создания и последнего изменения \nNew-Item -Path \"C:\\test\\\" -ItemType \"Directory\" создать директорию (Alias: mkdir/md) \nNew-Item -Path \"C:\\test\\file.txt\" -ItemType \"File\" -Value \"Добавить текст в файл\" создать файл \n\"test\" &gt; \"C:\\test\\file.txt\" заменить содержимое \n\"test\" &gt;&gt; \"C:\\test\\file.txt\" добавить строку в файл \nNew-Item -Path \"C:\\test\\test\\file.txt\" -Force ключ используется для создания отсутствующих в пути директорий или перезаписи файла если он уже существует \nMove-Item перемещение объектов (Alias: mv/move) \nRemove-Item \"$path\\\" -Recurse удаление всех файлов внутри каталога, без запроса подверждения (Alias: rm/del) \nRemove-Item $path -Recurse -Include \"*.txt\",\"*.temp\" -Exclude \"log.txt\" удалить все файлы с расширением txt и temp ([Array]), кроме log.txt \nRename-Item \"C:\\test\\*.*\" \"*.jpg\" переименовать файлы по маске (Alias: ren) \nCopy-Item копирование файлов и каталогов (Alias: cp/copy) \nCopy-Item -Path \"\\\\server-01\\test\" -Destination \"C:\\\" -Recurse копировать директорию с ее содержимым (-Recurse) \nCopy-Item -Path \"C:\\*.txt\" -Destination \"C:\\test\\\" знак ’' в конце Destination используется для переноса папки внутрь указанной, отсутствие, что это новое имя директории \nCopy-Item -Path \"C:\\*\" -Destination \"C:\\test\\\" -Include '*.txt','*.jpg' копировать объекты с указанным расширением (Include) \nCopy-Item -Path \"C:\\*\" -Destination \"C:\\test\\\" -Exclude '*.jpeg' копировать объекты, за исключением файлов с расширением (Exclude) \n$log = Copy-Item \"C:\\*.txt\" \"C:\\test\\\" -PassThru вывести результат копирования (логирование) в переменную, можно забирать строки с помощью индексов $log[0].FullName \nUnblock-File \"script.ps1\" разблокирует файлы скриптов PowerShell скачанных из Интернета, чтобы их можно было запустить, даже если политика выполнения PowerShell в режиме RemoteSigned\n\nClear-env-Temp-14-days\n\n\nSystem.IO.File\n$file = [System.IO.File]::Create(\"$home\\desktop\\test.txt\") создать файл \n$file.Close() закрыть файл \n[System.IO.File]::ReadAllLines(\"$home\\desktop\\test.txt\") прочитать файл \n$file = New-Object System.IO.StreamReader(\"$home\\desktop\\test.txt\") файл будет занят процессом PowerShell \n$file | Get-Member \n$file.ReadLine() построчный вывод \n$file.ReadToEnd() прочитать файл целиком\n\nRead/Write Bytes\n$file = [io.file]::ReadAllBytes(\"$home\\desktop\\powershell.jpg\") метод открывает двоичный файл, считывает его в массив байт и закрывает файл \n[io.file]::WriteAllBytes(\"$home\\desktop\\tloztotk-2.jpg\",$file) сохранить байты в файл (можно использовать для выгрузки двоичных файлов из БД)\n\nArchive\n\nMicrosoft.PowerShell.Archive\nCompress-Archive -Path $srcPath -DestinationPath \"$($srcPath).zip\" -CompressionLevel Optimal архивировать (по исходному пути и названию с добавлением расширения) \nExpand-Archive -Path $zip разархивировать \nExpand-Archive -Path $zip -DestinationPath $dstPath указать путь извлечения \nExpand-Archive -Path $zip -OutputPath $dstPath\n\nSystem.IO.Compression.FileSystem\n\n\nWinRAR\n\ncd \"$home\\Downloads\" \nExpand-ArchivePassword archive.rar qwe123\n\nFile descriptor\n$url = \"https://download.sysinternals.com/files/Handle.zip\" \nInvoke-RestMethod $url -OutFile \"$env:TEMP\\handle.zip\" \nExpand-ArchiveFile -Path \"$env:TEMP\\handle.zip\" -DestinationPath \"$home\\Documents\" -FileName \"handle.exe\" извлекаем выбранный файл из архива \nRemove-Item \"$env:TEMP\\handle.zip\" \n$handle = \"$home\\Documents\\handle.exe\" \n$test = New-Object System.IO.StreamReader(\"$home\\desktop\\test.txt\") занять файл текущим процессом pwsh ($pid) \n$SearchProcess = &amp; $handle \"C:\\Users\\Lifailon\\Desktop\\test.txt\" -nobanner -u -v | ConvertFrom-Csv вывести список дескрипторов по пути к файлу (имя процесса, его PID и пользователь который запустил) \nStop-Process $SearchProcess.PID завершить процесс, который удерживал файл\n\nConsole-Menu\n\nПример навигации по директориям в системе используя меню:\n\nls-menu \nls-menu $home \nls-menu \"D:\\\"\n\nCredential\n$Cred = Get-Credential сохраняет креды в переменные $Cred.Username и $Cred.Password \n$Cred.GetNetworkCredential().password извлечь пароль \ncmdkey /generic:\"TERMSRV/$srv\" /user:\"$username\" /pass:\"$password\" добавить указанные креды аудентификации на на терминальный сервер для подключения без пароля \nmstsc /admin /v:$srv авторизоваться \ncmdkey /delete:\"TERMSRV/$srv\" удалить добавленные креды аудентификации из системы \nrundll32.exe keymgr.dll,KRShowKeyMgr хранилище Stored User Names and Password \nGet-Service VaultSvc служба для работы Credential Manager \nInstall-Module CredentialManager установить модуль управления Credential Manager к хранилищу PasswordVault из PowerShell \n[System.Net.ServicePointManager]::SecurityProtocol = [System.Net.SecurityProtocolType]'Tls11,Tls12' для устаноки модуля \nGet-StoredCredential получить учетные данные из хранилища Windows Vault \nGet-StrongPassword генератор пароля \nNew-StoredCredential -UserName test -Password \"123456\" добавить учетную запись \nRemove-StoredCredential удалить учетную запись \n$Cred = Get-StoredCredential | where {$_.username -match \"admin\"} \n$pass = $cred.password \n$BSTR = [System.Runtime.InteropServices.Marshal]::SecureStringToBSTR($pass) \n[System.Runtime.InteropServices.Marshal]::PtrToStringAuto($BSTR)\n\nOut-Gridview\nGet-Service -cn $srv | Out-GridView -Title \"Service $srv\" -OutputMode Single –PassThru | Restart-Service перезапустить выбранную службу\n\nOut-File\nRead-Host –AsSecureString | ConvertFrom-SecureString | Out-File \"$env:userprofile\\desktop\\password.txt\" писать в файл. Преобразовать пароль в формат SecureString с использованием шифрования Windows Data Protection API (DPAPI)\n\nGet-Content (gc/cat/type)\n$password = gc \"$env:userprofile\\desktop\\password.txt\" | ConvertTo-SecureString читать хэш пароля из файла с помощью ключей, хранящихся в профиле текущего пользователя, который невозможно прочитать на другом копьютере\n\nAES Key\n$AESKey = New-Object Byte[] 32 \n[Security.Cryptography.RNGCryptoServiceProvider]::Create().GetBytes($AESKey) \n$AESKey | Out-File \"C:\\password.key\" \n$Cred.Password | ConvertFrom-SecureString -Key (Get-Content \"C:\\password.key\") | Set-Content \"C:\\password.txt\" сохранить пароль в файл используя внешний ключ \n$pass = Get-Content \"C:\\password.txt\" | ConvertTo-SecureString -Key (Get-Content \"\\\\Server\\Share\\password.key\") расшифровать пароль на втором компьютере\n\nWinEvent\nGet-WinEvent -ListLog * отобразить все доступные журналы логов \nGet-WinEvent -ListLog * | where RecordCount -ne 0 | where RecordCount -ne $null | sort -Descending RecordCount отобразить не пустые журналы с сортировкой по кол-ву записей \nGet-WinEvent -ListProvider * | ft отобразить всех провайдеров приложений \nGet-WinEvent -ListProvider GroupPolicy найти в какой журнал LogLinks {Application} пишутся логи приложения \nGet-WinEvent -ListProvider *smb* \nGet-WinEvent -ListLog * | where logname -match SMB | sort -Descending RecordCount найти все журналы по имени \nGet-WinEvent -LogName \"Microsoft-Windows-SmbClient/Connectivity\" \nGet-WinEvent -ListProvider *firewall*\n\nFilter XPath/Hashtable\nGet-WinEvent -FilterHashtable @{LogName=\"Security\";ID=4624} найти логи по ID в журнале Security \nGet-WinEvent -FilterHashtable @{LogName=\"System\";Level=2} найти все записи ошибки (1 - критический, 3 - предупреждение, 4 - сведения) \nGet-WinEvent -FilterHashtable @{LogName=\"System\";Level=2;ProviderName=\"Service Control Manager\"} отфильтровать по имени провайдера\n([xml](Get-WinEvent -FilterHashtable @{LogName=\"Security\";ID=4688} -MaxEvents 1).ToXml()).Event.EventData.Data отобразить все свойства, хранимые в EventData (Message) \nGet-WinEvent -FilterHashtable @{logname=\"security\";ID=4688} -MaxEvents 1 | select timecreated,{$_.Properties[5].value} отфильтровать время события и имя запущенного процесса\n\n\nReboot\n\n\nLogon\n\n\nEventLog\nGet-EventLog -List отобразить все корневые журналы логов и их размер \nClear-EventLog Application очистить логи указанного журнала \nGet-EventLog -LogName Security -InstanceId 4624 найти логи по ID в журнале Security\n\nFirewall\n\nNew-NetFirewallRule -Profile Any -DisplayName \"Open Port 135 RPC\" -Direction Inbound -Protocol TCP -LocalPort 135 открыть in-порт \nGet-NetFirewallRule | where DisplayName -match kms | select * найти правило по имени \nGet-NetFirewallPortFilter | where LocalPort -like 80 найти действующие правило по номеру порта\n\n\nFirewall-Manager\nInstall-Module Firewall-Manager \nExport-FirewallRules -Name * -CSVFile $home\\documents\\fw.csv -Inbound -Outbound -Enabled -Disabled -Allow -Block (фильтр правил для экспорта) \nImport-FirewallRules -CSVFile $home\\documents\\fw.csv\n\nDefender\nImport-Module Defender \nGet-Command -Module Defender \nGet-MpComputerStatus \n(Get-MpComputerStatus).AntivirusEnabled статус работы антивируса\n$session = NewCimSession -ComputerName hostname подключиться к удаленному компьютеру, используется WinRM \nGet-MpComputerStatus -CimSession $session | fl fullscan* узнать дату последнего сканирования на удаленном компьютере\nGet-MpPreference настройки \n(Get-MpPreference).ScanPurgeItemsAfterDelay время хранения записей журнала защитника в днях \nSet-MpPreference -ScanPurgeItemsAfterDelay 30 изменить время хранения \nls \"C:\\ProgramData\\Microsoft\\Windows Defender\\Scans\\History\" \nGet-MpPreference | select disable* отобразить статус всех видов проверок/сканирований \nSet-MpPreference -DisableRealtimeMonitoring $true отключить защиту Defender в реальном времени (использовать только ручное сканирование) \nSet-MpPreference -DisableRemovableDriveScanning $false включить сканирование USB накопителей \nGet-MpPreference | select excl* отобразить список всех исключений \n(Get-MpPreference).ExclusionPath \nAdd-MpPreference -ExclusionPath C:\\install добавить директорию в исключение \nRemove-MpPreference -ExclusionPath C:\\install удалить из исключения \nNew-ItemProperty -Path \"HKLM:\\SOFTWARE\\Policies\\Microsoft\\Windows Defender\" -Name DisableAntiSpyware -Value 1 -PropertyType DWORD -Force полностью отключить Windows Defender\nSet-MpPreference -SignatureDefinitionUpdateFileSharesSources \\\\FileShare1\\Updates для обновления из сетевой папки нужно предварительно скачать файлы с сигнатурами баз с сайта https://www.microsoft.com/security/portal/definitions/adl.aspx и поместить в сетевой каталог\nUpdate-MpSignature -UpdateSource FileShares изменить источник обновлений (MicrosoftUpdateServer – сервера обновлений MS в интернете, InternalDefinitionUpdateServer — внутренний WSUS сервер) \nUpdate-MpSignature обновить сигнатуры\nStart-MpScan -ScanType QuickScan быстрая проверка или FullScan \nStart-MpScan -ScanType FullScan -AsJob \nSet-MpPreference -RemediationScheduleDay 1-7 выбрать дни, начиная с воскресенья или 0 каждый день, 8 - сбросить \nSet-MpPreference -ScanScheduleQuickScanTime 14:00:00 \nStart-MpScan -ScanType CustomScan -ScanPath \"C:\\Program Files\" сканировать выбранную директорию\nGet-MpThreat история угроз и тип угрозы (ThreatName: HackTool/Trojan) \nGet-MpThreatCatalog список известных видов угроз \nGet-MpThreatDetection история защиты (активных и прошлые) и ID угрозы \nGet-MpThreat -ThreatID 2147760253\nls \"C:\\ProgramData\\Microsoft\\Windows Defender\\Quarantine\\\" директория хранения файлов в карантине \ncd \"C:\\Program Files\\Windows Defender\\\" \n.\\MpCmdRun.exe -restore -name $ThreatName восстановить файл из карантина \n.\\MpCmdRun.exe -restore -filepath $path_file\n\nDISM\nGet-Command -Module Dism -Name *Driver* \nExport-WindowsDriver -Online -Destination C:\\Users\\Lifailon\\Documents\\Drivers\\ извлечение драйверов из текущей системы (C:\\Windows\\System32\\DriverStore\\FileRepository), выгружает список файлов, которые необходимы для установки драйвера (dll,sys,exe) в соответствии со списком файлов, указанных в секции [CopyFiles] inf-файла драйвера. \nExport-WindowsDriver -Path C:\\win_image -Destination C:\\drivers извлечь драйвера из офлайн образа Windows, смонтированного в каталог c:\\win_image \n$BackupDrivers = Export-WindowsDriver -Online -Destination C:\\Drivers \n$BackupDrivers | ft Driver,ClassName,ProviderName,Date,Version,ClassDescription список драйверов в объектном представлении \n$BackupDrivers | where classname -match printer \npnputil.exe /add-driver C:\\drivers\\*.inf /subdirs /install установить все (параметр subdirs) драйвера из указанной папки (включая вложенные)\nsfc /scannow проверить целостность системных файлов с помощью утилиты SFC (System File Checker), в случае поиска ошибок, попробует восстановить их оригинальные копии из хранилища системных компонентов Windows (каталог C:\\Windows\\WinSxS). Вывод работы логируется в C:\\Windows\\Logs\\CBS с тегом SR \nGet-ComputerInfo | select * подробная информация о системе (WindowsVersion,WindowsEditionId,Bios) \nGet-WindowsImage -ImagePath E:\\sources\\install.wim список доступных версий в образе \nRepair-WindowsImage -Online –ScanHealth \nRepair-WindowsImage -Online -RestoreHealth восстановление хранилища системных компонентов \nRepair-WindowsImage -Online -RestoreHealth -Source E:\\sources\\install.wim:3 –LimitAccess восстановление в оффлайн режиме из образа по номеру индекса\n\nScheduled\n$Trigger = New-ScheduledTaskTrigger -At 01:00am -Daily 1:00 ночи \n$Trigger = New-ScheduledTaskTrigger –AtLogon запуск при входе пользователя в систему \n$Trigger = New-ScheduledTaskTrigger -AtStartup при запуске системы \n$User = \"NT AUTHORITY\\SYSTEM\" \n$Action = New-ScheduledTaskAction -Execute \"PowerShell.exe\" -Argument \"$home\\Documents\\DNS-Change-Tray-1.3.ps1\" \n$Action = New-ScheduledTaskAction -Execute \"PowerShell.exe\" -Argument \"-NoProfile -NoLogo -NonInteractive -ExecutionPolicy Unrestricted -WindowStyle Hidden -File $home\\Documents\\DNS-Change-Tray-1.3.ps1\" \nRegister-ScheduledTask -TaskName \"DNS-Change-Tray-Startup\" -Trigger $Trigger -User $User -Action $Action -RunLevel Highest –Force\nGet-ScheduledTask | ? state -ne Disabled список всех активных заданий \nStart-ScheduledTask DNS-Change-Tray-Startup запустить задание немедленно \nGet-ScheduledTask DNS-Change-Tray-Startup | Disable-ScheduledTask отключить задание \nGet-ScheduledTask DNS-Change-Tray-Startup | Enable-ScheduledTask включить задание \nUnregister-ScheduledTask DNS-Change-Tray-Startup удалить задание \nExport-ScheduledTask DNS-Change-Tray-Startup | Out-File $home\\Desktop\\Task-Export-Startup.xml экспортировать задание в xml \nRegister-ScheduledTask -Xml (Get-Content $home\\Desktop\\Task-Export-Startup.xml | Out-String) -TaskName \"DNS-Change-Tray-Startup\"\n\nNetwork\n\nping\nTest-Connection -Count 1 $srv1, $srv2 отправить icmp-пакет двум хостам \nTest-Connection $srv -ErrorAction SilentlyContinue не выводить ошибок, если хост не отвечает \nTest-Connection -Source $srv1 -ComputerName $srv2 пинг с удаленного компьютера\n\nTest-PingNetwork -Network 192.168.3.0 \nTest-PingNetwork -Network 192.168.3.0 -Timeout 1000\nGet-CimInstance -Class Win32_PingStatus -Filter \"Address='127.0.0.1'\" \nGet-CimInstance -Class Win32_PingStatus -Filter \"Address='127.0.0.1'\" | Format-Table -Property Address,ResponseTime,StatusCode -Autosize 0 - успех \n'127.0.0.1','8.8.8.8' | ForEach-Object -Process {Get-CimInstance -Class Win32_PingStatus -Filter (\"Address='$_'\") | Select-Object -Property Address,ResponseTime,StatusCode} \n$ips = 1..254 | ForEach-Object -Process {'192.168.1.' + $_} сформировать массив из ip-адресов подсети\n\ndhcp\nGet-CimInstance -Class Win32_NetworkAdapterConfiguration -Filter \"DHCPEnabled=$true\" отобразить адаптеры с включенным DHCP \n$wql = 'SELECT * from Win32_NetworkAdapterConfiguration WHERE IPEnabled=True and DHCPEnabled=False' \nInvoke-CimMethod -MethodName ReleaseDHCPLease -Query $wql включение DHCP на всех адаптерах \nInvoke-CimMethod -ClassName Win32_NetworkAdapterConfiguration -MethodName ReleaseDHCPLeaseAll отменить аренду адресов DHCP на всех адаптерах \nInvoke-CimMethod -ClassName Win32_NetworkAdapterConfiguration -MethodName RenewDHCPLeaseAll обновить аренду адресов DHCP на всех адаптерах\n\nport\ntnc $srv -p 5985 \ntnc $srv -CommonTCPPort WINRM HTTP,RDP,SMB \ntnc ya.ru –TraceRoute -Hops 2 TTL=2 \ntnc ya.ru -DiagnoseRouting маршрутизация до хоста, куда (DestinationPrefix: 0.0.0.0/0) через (NextHop: 192.168.1.254)\n\nnetstat\nnetstat -anop tcp -n/-f/-b \nGet-NetTCPConnection -State Established,Listen | ? LocalPort -Match 3389 \nGet-NetTCPConnection -State Established,Listen | ? RemotePort -Match 22 \nGet-NetUDPEndpoint | ? LocalPort -Match 514 netstat -ap udp`\n\nnslookup\nnslookup ya.ru 1.1.1.1 с указанием DNS сервера \nnslookup -type=any ya.ru указать тип записи \nResolve-DnsName ya.ru -Type MX ALL,ANY,A,NS,SRV,CNAME,PTR,TXT(spf) \n[System.Net.Dns]::GetHostEntry(\"ya.ru\")\n\nipconfig\nGet-NetIPConfiguration \nGet-NetIPConfiguration -InterfaceIndex 14 -Detailed\n\nAdapter\nGet-NetAdapter \nSet-NetIPInterface -InterfaceIndex 14 -Dhcp Disabled отключить DHCP \nGet-NetAdapter -InterfaceIndex 14 | New-NetIPAddress –IPAddress 192.168.3.99 -DefaultGateway 192.168.3.1 -PrefixLength 24 задать/добавить статический IP-адрес \nSet-NetIPAddress -InterfaceIndex 14 -IPAddress 192.168.3.98 изменить IP-адреас на адаптере \nRemove-NetIPAddress -InterfaceIndex 14 -IPAddress 192.168.3.99 удалить IP-адрес на адаптере \nSet-NetIPInterface -InterfaceIndex 14 -Dhcp Enabled включить DHCP\n\nDNSClient\nGet-DNSClientServerAddress список интерфейсов и настроенные на них адреса DNS сервера \nSet-DNSClientServerAddress -InterfaceIndex 14 -ServerAddresses 8.8.8.8 изменить адрес DNS сервера на указанного интерфейсе\n\nDNSCache\nGet-DnsClientCache отобразить кэшированные записи клиента DNS \nClear-DnsClientCache очистить кэш\n\nBinding\nGet-NetAdapterBinding -Name Ethernet -IncludeHidden -AllBindings \nGet-NetAdapterBinding -Name \"Беспроводная сеть\" -DisplayName \"IP версии 6 (TCP/IPv6)\" | Set-NetAdapterBinding -Enabled $false отключить IPv6 на адаптере\n\nTCPSetting\nGet-NetTCPSetting \nSet-NetTCPSetting -SettingName DatacenterCustom,Datacenter -CongestionProvider DCTCP настраивает провайдера управления перегрузкой (Congestion Control Provider) на DCTCP (Data Center TCP) для профилей TCP с именами DatacenterCustom и Datacenter \nSet-NetTCPSetting -SettingName DatacenterCustom,Datacenter -CwndRestart True включает функцию перезапуска окна перегрузки (Congestion Window Restart, CwndRestart) для указанных профилей TCP. Это означает, что после периода идле (когда нет передачи данных) TCP окно перегрузки будет сбрасываться \nSet-NetTCPSetting -SettingName DatacenterCustom,Datacenter -ForceWS Disabled отключает принудительное масштабирование окна (Forced Window Scaling) для указанных профилей TCP. Масштабирование окна — это механизм, который позволяет увеличивать размер окна перегрузки TCP, чтобы улучшить производительность передачи данных по сети с высокой пропускной способностью и большой задержкой\n\nhostname\n$env:computername \nhostname.exe \n(Get-CIMInstance CIM_ComputerSystem).Name \n(New-Object -ComObject WScript.Network).ComputerName \n[System.Environment]::MachineName \n[System.Net.Dns]::GetHostName()\n\narp\nipconfig /all | Select-String \"физ\" grep \nGet-NetNeighbor -AddressFamily IPv4\n\nGet-ARP -search 192.168.3.100 \nGet-ARP -search 192.168.3.100 -proxy dc-01\n\nNetwork Adapter Statistics\nnetstat -se \nGet-NetAdapterStatistics\n\nSpeedTest\n\n\niPerf\n\nInstall\n\n&amp; \"$home\\Documents\\iperf3\\iperf3.exe\" -h\n\nEnv-Update-Exec-Path\n\niperf3 -h\n\niPerf-GUI\nInvoke-RestMethod \"https://github.com/Lifailon/iPerf-GUI/raw/rsa/iPerf-GUI-Install.exe\" -OutFile \"$home\\Downloads\\iPerf-GUI-Install.exe\" скачать установочную версию собранную с помощью WinRAR \nStart-Process -FilePath \"$home\\Downloads\\iPerf-GUI-Install.exe\" -ArgumentList \"/S\" -NoNewWindow -Wait установить в тихом режиме\n\niPerf-Docker\n\ndocker build -t iperf3-alpine-server . \ndocker run -d -p 5201:5201 --name iperf3-alpine-server iperf3-alpine-server\n\nServer\niperf3 -s запуск сервера \niperf3 -s -D запустить сервер в фоновом режиме как службу (–daemon) \nGet-NetTCPConnection -State Established,Listen | ? LocalPort -Match 5201 проверить, что порт сервера слушает \nGet-Process -Id $(Get-NetTCPConnection -State Established,Listen | ? LocalPort -Match 5201).OwningProcess получить процесс по порту \nGet-Process iperf3 | Stop-Process остановить процесс \niperf3 -s -D --logfile \"$home\\Documents\\iperf3\\iperf3.log\" перенаправить вывод в лог файл \niperf3 -s -p 5211 указать порт, на котором будет слушать сервер или отправлять запросы клиент \niperf3 -s -p 5211 -f M изменить формат выводимых данных (измерять в байтах а не в битах, доступные значения: K,M,G,T) \niperf3 -s -p 5211 -f M -J вывод в формате json \niperf3 -s -p 5211 -f M -V вывод подробной информации\n\nClient\niperf3 -c 192.168.3.100 -p 5211 подключение к серверу (по умолчанию проверяется отдача на сервер с клиента) \niperf3 -c 192.168.3.100 -p 5211 -R обратный тест, проверка скачивания с сервера (–reverse, сервер отправляет данные клиенту) \niperf3 -c 192.168.3.100 -p 5211 -R -P 2 количество одновременных потоков ([SUM] - суммарная скорость нескольки потоков) \niperf3 -c 192.168.3.100 -p 5211 -R -4 использовать только IPv4 \niperf3 -c 192.168.3.100 -p 5211 -R -u использовать UDP вместо TCP \niperf3 -c 192.168.3.100 -p 5211 -R -u -b 2mb установить битрейт в 2.00 Mbits/sec для UDP (по умолчанию 1 Мбит/сек, для TCP не ограничено) \niperf3 -c 192.168.3.100 -p 5211 -R -t 30 время одного теста в секундах (по умолчанию 10 секунд) \niperf3 -c 192.168.3.100 -p 5211 -R -n 1gb указать объем данных для проверки (применяется вместо времени -t) \niperf3 -c 192.168.3.100 -p 5211 -R --get-server-output вывести вывод сервера на клиенте\n\nOutput\nsender upload (скорость передачи на удаленный сервер) \nreceiver download (скорость скачивания с удаленного сервера) \nInterval общее время сканирования \nTransfer кол-во переданных и полученных МБайт \nBandwidth скорость передачи (измеряется в Мбит/c)\n\nPS-iPerf\nInstall-Module ps-iperf -Repository NuGet \nImport-Module PS-iPerf \nStart-iPerfServer -Port 5211 запустить сервер \nGet-iPerfServer статус работы сервера \nStop-iPerfServer остановить сервер \nConnect-iPerfServer -Server 192.168.3.100 -Port 5211 -MBytes 500 -Download подключиться к серверу и скачать 500 МБайт \n$SpeedTest = Connect-iPerfServer -Server 192.168.3.100 -Port 5211 -MBytes 500 -LogWrite передать 500 МБайт на сервер (вести запись в лог-файл) \n$SpeedTest.Intervals метрики измерений \nGet-iPerfLog прочитать лог-файл\n\nRDP\nGet-ItemProperty -Path \"HKLM:\\SYSTEM\\CurrentControlSet\\Control\\Terminal Server\\WinStations\\RDP-Tcp\" -Name \"PortNumber\" отобразить номер текущего RDP порта \nSet-ItemProperty -Path \"HKLM:\\SYSTEM\\CurrentControlSet\\Control\\Terminal Server\\WinStations\\RDP-Tcp\" -Name \"PortNumber\" -Value \"3390\" изменить RDP-порт \n$(Get-ItemProperty -Path \"HKLM:\\System\\CurrentControlSet\\Control\\Terminal Server\\\" -Name \"fDenyTSConnections\").fDenyTSConnections если 0, то включен \nSet-ItemProperty -Path \"HKLM:\\System\\CurrentControlSet\\Control\\Terminal Server\\\" -Name \"fDenyTSConnections\" -Value 0 включить RDP \nreg add \"HKLM\\SYSTEM\\CurrentControlSet\\Control\\Terminal Server\" /v fDenyTSConnections /t REG_DWORD /d 0 /f \n(gcim -Class Win32_TerminalServiceSetting -Namespace root\\CIMV2\\TerminalServices).SetAllowTSConnections(0) включить RDP (для Windows Server) \nGet-Service TermService | Restart-Service -Force перезапустить rdp-службу \nNew-NetFirewallRule -Profile Any -DisplayName \"RDP 3390\" -Direction Inbound -Protocol TCP -LocalPort 3390 открыть RDP-порт\n\nIPBan\nauditpol /get /category:* отобразить все политики аудита \nauditpol /get /category:Вход/выход отобразить локальные политики аудита для Входа и Выхода из системы \nauditpol /set /subcategory:\"Вход в систему\" /success:enable /failure:enable включить локальные политики - Аудит входа в систему \nauditpol /set /subcategory:\"Выход из системы\" /success:enable /failure:enable\n$url = $($(Invoke-RestMethod https://api.github.com/repos/DigitalRuby/IPBan/releases/latest).assets | Where-Object name -match \".+win.+x64.+\").browser_download_url получить ссылку для загрузки последней версии \n$version = $(Invoke-RestMethod https://api.github.com/repos/DigitalRuby/IPBan/releases/latest).tag_name получить номер последней версии \n$path = \"$home\\Documents\\ipban-$version\" путь для установки \nInvoke-RestMethod $url -OutFile \"$home\\Downloads\\IPBan-$version.zip\" скачать дистрибутив \nExpand-Archive \"$home\\Downloads\\ipban-$version.zip\" -DestinationPath $path разархивировать в путь для установки \nRemove-Item \"$home\\Downloads\\ipban-$version.zip\" удалить дистрибутив \nsc create IPBan type=own start=delayed-auto binPath=\"$path\\DigitalRuby.IPBan.exe\" DisplayName=IPBan создать службу \nGet-Service IPBan статус службы \n$conf = $(Get-Content \"$path\\ipban.config\") читаем конфигурацию \n$conf = $conf -replace '&lt;add key=\"Whitelist\" value=\"\"/&gt;','&lt;add key=\"Whitelist\" value=\"192.168.3.0/24\"/&gt;' добавить в белый лист домашнюю сеть для исключения \n$conf = $conf -replace '&lt;add key=\"ProcessInternalIPAddresses\" value=\"false\"/&gt;','&lt;add key=\"ProcessInternalIPAddresses\" value=\"true\"/&gt;' включить обработку локальных (внутренних) ip-адресов \n$conf = $conf -replace '&lt;add key=\"FailedLoginAttemptsBeforeBanUserNameWhitelist\" value=\"20\"/&gt;','&lt;add key=\"FailedLoginAttemptsBeforeBanUserNameWhitelist\" value=\"5\"/&gt;' указать количество попыток подключения до блокировки \n$conf = $conf -replace '&lt;add key=\"ExpireTime\" value=\"01:00:00:00\"/&gt;','&lt;add key=\"ExpireTime\" value=\"00:01:00:00\"/&gt;' задать время блокировки 1 час \n$conf &gt; \"$path\\ipban.config\" обновить конфигурацию \nGet-Service IPBan | Start-Service запустить службу\n\nGet-Content -Wait \"$path\\logfile.txt\" читать лог \nGet-Service IPBan | Stop-Service остановить службу \nsc delete IPBan удалить службу\n\nshutdown\nshutdown /r /o перезагрузка в безопасный режим \nshutdown /s /t 600 /c \"Power off after 10 minutes\" выключение \nshutdown /s /f принудительное закрытие приложений \nshutdown /a отмена \nshutdown /r /t 0 /m \\\\192.168.3.100 \nRestart-Computer -ComputerName 192.168.3.100 -Protocol WSMan через WinRM \nRestart-Computer –ComputerName 192.168.3.100 –Force через WMI \nSet-ItemProperty -Path \"HKLM:\\SOFTWARE\\Microsoft\\PolicyManager\\default\\Start\\HideShutDown\" -Name \"value\" -Value 1 скрыть кнопку выключения \nSet-ItemProperty -Path \"HKLM:\\SOFTWARE\\Microsoft\\PolicyManager\\default\\Start\\HideRestart\" -Name \"value\" -Value 1 скрыть кнопку перезагрузки\n\n\nLocalAccounts\nGet-Command -Module Microsoft.PowerShell.LocalAccounts \nGet-LocalUser список пользователей \nGet-LocalGroup список групп \nNew-LocalUser \"1C\" -Password $Password -FullName \"1C Domain\" создать пользователя \nSet-LocalUser -Password $Password 1C изменить пароль \nAdd-LocalGroupMember -Group \"Administrators\" -Member \"1C\" добавить в группу Администраторов \nGet-LocalGroupMember \"Administrators\" члены группы\n\n\nSMB\nGet-SmbServerConfiguration \nSet-SmbServerConfiguration -EnableSMB1Protocol $false -Force отключить протокол SMB v1 \nGet-WindowsFeature | Where-Object {$_.name -eq \"FS-SMB1\"} | ft Name,Installstate модуль ServerManager, проверить установлен ли компонент SMB1 \nInstall-WindowsFeature FS-SMB1 установить SMB1 \nUninstall-WindowsFeature –Name FS-SMB1 –Remove удалить SMB1 клиента (понадобится перезагрузка) \nGet-WindowsOptionalFeature -Online модуль DISM, для работы с компонентами Windows \nDisable-WindowsOptionalFeature -Online -FeatureName SMB1Protocol -Remove удалить SMB1 \nSet-SmbServerConfiguration –AuditSmb1Access $true включить аудит SMB1 \nGet-SmbConnection список активных сессий и используемая версия SMB (Dialect) \nGet-SmbOpenFile | select ClientUserName,ClientComputerName,Path,SessionID список открытых файлов \nGet-SmbShare список сетевых папок \nNew-SmbShare -Name xl-share -Path E:\\test создать новую общую сетевую папку (расшарить) \n-EncryptData $True включить шифрование SMB \n-Description имя в сетевом окружении \n-ReadAccess \"domain\\username\" доступ на чтение \n-ChangeAccess доступ на запись \n-FullAccess полный доступ \n-NoAccess ALL нет прав \n-FolderEnumerationMode [AccessBased | Unrestricted] позволяет скрыть в сетевой папке объекты, на которых у пользователя нет доступа с помощью Access-Based Enumeration (ABE) \nGet-SmbShare xl-share | Set-SmbShare -FolderEnumerationMode AccessBased ключить ABE для всех расшаренных папок \nRemove-SmbShare xl-share -force удалить сетевой доступ (шару) \nGet-SmbShareAccess xl-share вывести список доступов безопасности к шаре \nRevoke-SmbShareAccess xl-share -AccountName Everyone –Force удалить группу из списка доступов \nGrant-SmbShareAccess -Name xl-share -AccountName \"domain\\XL-Share\" -AccessRight Change –force изменить/добавить разрешения на запись (Full,Read) \nGrant-SmbShareAccess -Name xl-share -AccountName \"все\" -AccessRight Change –force \nBlock-SmbShareAccess -Name xl-share -AccountName \"domain\\noAccess\" -Force принудительный запрет \nNew-SmbMapping -LocalPath X: -RemotePath \\\\$srv\\xl-share -UserName support4 -Password password –Persistent $true подключить сетевой диск \n-Persistent восстановление соединения после отключения компьютера или сети \n-SaveCredential позволяет сохранить учетные данные пользователя для подключения в диспетчер учетных данных Windows Credential Manager \nStop-Process -Name \"explorer\" | Start-Process -FilePath \"C:\\Windows\\explorer.exe\" перезапустить процесс для отображения в проводнике \nGet-SmbMapping список подключенных сетевых дисков \nRemove-SmbMapping X: -force отмонтировать сетевой диск \n$CIMSession = New-CIMSession –Computername $srv создать сеанс CIM (аудентификация на SMB) \nGet-SmbOpenFile -CIMSession $CIMSession | select ClientUserName,ClientComputerName,Path | Out-GridView -PassThru | Close-SmbOpenFile -CIMSession $CIMSession -Confirm:$false –Force закрыть файлы (открыть к ним сетевой доступ)\n\nGet-Acl\n(Get-Acl \\\\$srv\\xl-share).access доступ ACL на уровне NTFS \nGet-Acl C:\\Drivers | Set-Acl C:\\Distr скопировать NTFS разрешения с одной папки и применить их на другую\n\nNTFSSecurity\nInstall-Module -Name NTFSSecurity -force \nGet-Item \"\\\\$srv\\xl-share\" | Get-NTFSAccess \nAdd-NTFSAccess -Path \"\\\\$srv\\xl-share\" -Account \"domain\\xl-share\" -AccessRights Fullcontrol -PassThru добавить \nRemove-NTFSAccess -Path \"\\\\$srv\\xl-share\" -Account \"domain\\xl-share\" -AccessRights FullControl -PassThru удалить \nGet-ChildItem -Path \"\\\\$srv\\xl-share\" -Recurse -Force | Clear-NTFSAccess удалить все разрешения, без удаления унаследованных разрешений \nGet-ChildItem -Path \"\\\\$srv\\xl-share\" -Recurse -Force | Enable-NTFSAccessInheritance включить NTFS наследование для всех объектов в каталоге\n\nStorage\nGet-Command -Module Storage \nGet-Disk список логических дисков \nGet-Partition отобразить разделы на всех дисках \nGet-Volume список логичких разделов \nGet-PhysicalDisk список физических дисков \nInitialize-Disk 1 –PartitionStyle MBR инициализировать диск \nNew-Partition -DriveLetter D –DiskNumber 1 -Size 500gb создать раздел (выделить все место -UseMaximumSize) \nFormat-Volume -DriveLetter D -FileSystem NTFS -NewFileSystemLabel Disk-D форматировать раздел \nSet-Partition -DriveLetter D -IsActive $True сделать активным \nRemove-Partition -DriveLetter D –DiskNumber 1 удалить раздел \nClear-Disk -Number 1 -RemoveData очистить диск \nRepair-Volume –driveletter C –Scan Check disk \nRepair-Volume –driveletter C –SpotFix \nRepair-Volume –driverletter C -Scan –Cimsession $CIMSession\n\niSCSI\nNew-IscsiVirtualDisk -Path D:\\iSCSIVirtualDisks\\iSCSI2.vhdx -Size 20GB создать динамический vhdx-диск (для фиксированного размера -UseFixed) \nNew-IscsiServerTarget -TargetName iscsi-target-2 -InitiatorIds \"IQN:iqn.1991-05.com.microsoft:srv3.contoso.com\" создать Target \nGet-IscsiServerTarget | fl TargetName, LunMappings \nConnect-IscsiTarget -NodeAddress \"iqn.1995-05.com.microsoft:srv2-iscsi-target-2-target\" -IsPersistent $true подключиться инициатором к таргету \nGet-IscsiTarget | fl \nDisconnect-IscsiTarget -NodeAddress \"iqn.1995-05.com.microsoft:srv2-iscsi-target-2-target\" -Confirm:$false отключиться\n\nWSUS\nGet-Hotfix | Sort-Object -Descending  InstalledOn список установленных обновлений (информация из cimv2) \nGet-Hotfix -Description \"Security update\" \nGet-CimInstance Win32_QuickFixEngineering \nGet-Service uhssvc служба Microsoft Health Update Tools, которая отвечает за предоставление обновлений\n\nWindowsUpdate\nGet-Command -Module WindowsUpdate \nGet-WindowsUpdateLog формирует отчет в $home\\AppData\\Local\\Temp\\WindowsUpdateLog в формате csv\n\nPSWindowsUpdate\nInstall-Module -Name PSWindowsUpdate -Scope CurrentUser \nImport-Module PSWindowsUpdate \nGet-Command -Module PSWindowsUpdate \nGet-WindowsUpdate список обновлений для скачать и установить с сервера WSUS или Microsoft Update \nGet-WindowsUpdate -Download загрузить все обновления \nGet-WindowsUpdate –Install установить все обновления \nInstall-WindowsUpdate -MicrosoftUpdate -AcceptAll -IgnoreReboot установить все обновления без перезагрузки \nGet-WindowsUpdate -KBArticleID KB2267602, KB4533002 -Install \nGet-WindowsUpdate -KBArticleID KB2538243 -Hide скрыть обновления, что бы они никогда не устанавливались \nGet-WindowsUpdate –IsHidden отобразить скрытые обновления (Hide-WindowsUpdate) \nRemove-WindowsUpdate -KBArticleID KB4011634 -NoRestart удалить обновление \nUninstall-WindowsUpdate удалить обновление \nAdd-WUServiceManager регистрация сервера обновления (Windows Update Service Manager) \nEnable-WURemoting включить правила Windows Defender, разрешающие удаленное использование командлета PSWindowsUpdate \nGet-WUApiVersion версия Windows Update Agent \nGet-WUHistory список всех установленных обновлений (история обновлений) \nGet-WUHistory | Where-Object {$_.Title -match \"KB4517389\"} поиск обновления \nGet-WULastResults даты последнего поиска и установки обновлений \nGet-WURebootStatus проверить, нужна ли перезагрузка для применения конкретного обновления \nGet-WUServiceManager выводит источники обновлений \nGet-WUInstallerStatus статус службы Windows Installer \nRemove-WUServiceManager отключить Windows Update Service Manager\n\nUpdateServices\nInstall-WindowsFeature -Name UpdateServices-RSAT установить роль UpdateServices \n$UpdateScope = New-Object Microsoft.UpdateServices.Administration.UpdateScope \n[enum]::GetValues([Microsoft.UpdateServices.Administration.ApprovedStates]) список утвержденных состояний \n[enum]::GetValues([Microsoft.UpdateServices.Administration.UpdateInstallationStates]) статус установки (неизвестный, непригодный, не установлен, скачено, установлен, неуспешный, установлен и ожидает перезагрузки, все) \n$UpdateScope.ApprovedStates = [Microsoft.UpdateServices.Administration.ApprovedStates]\"NotApproved\" выставляем статус не утвержденных обновлений на сервере WSUS \n$UpdateScope.IncludedInstallationStates = [Microsoft.UpdateServices.Administration.UpdateInstallationStates]\"NotInstalled\" выставляем статус не установленных обновлений \n$UpdateScope.IncludedInstallationStates = [Microsoft.UpdateServices.Administration.UpdateInstallationStates]\"NotInstalled,Downloaded\" обновления загружены, но не установлены\n\nPoshWSUS\nInstall-Module -Name PoshWSUS \nGet-Command -Module PoshWSUS нужны права администратора \nAdd-PSWSUSClientToGroup добавление клиента в группу \nApprove-PSWSUSUpdate утверждение обновления \nConnect-PSWSUSDatabaseServer подключение к серверу базы данных WSUS \nConnect-PSWSUSServer подключение к серверу WSUS \nDeny-PSWSUSUpdate отклонение обновления \nDisconnect-PSWSUSServer отключение от сервера WSUS \nExport-PSWSUSMetaData экспорт метаданных WSUS \nGet-PoshWSUSSyncUpdateCategories получение категорий обновлений для синхронизации \nGet-PoshWSUSSyncUpdateClassifications получение классификаций обновлений для синхронизации \nGet-PSWSUSCategory получение категории WSUS \nGet-PSWSUSChildServer получение дочернего сервера WSUS \nGet-PSWSUSClassification получение классификации WSUS \nGet-PSWSUSClient получение информации о клиенте \nGet-PSWSUSClientGroupMembership получение групповой принадлежности клиента \nGet-PSWSUSClientPerUpdate получение информации о клиентах по обновлениям \nGet-PSWSUSClientsInGroup получение клиентов в группе \nGet-PSWSUSCommand получение информации о командах WSUS \nGet-PSWSUSConfig получение конфигурации WSUS \nGet-PSWSUSConfigEnabledUpdateLanguages получение включенных языков обновлений \nGet-PSWSUSConfigProxyServer получение конфигурации прокси-сервера \nGet-PSWSUSConfigSupportedUpdateLanguages получение поддерживаемых языков обновлений \nGet-PSWSUSConfigSyncSchedule получение расписания синхронизации \nGet-PSWSUSConfigSyncUpdateCategories получение категорий обновлений для синхронизации \nGet-PSWSUSConfigSyncUpdateClassifications получение классификаций обновлений для синхронизации \nGet-PSWSUSConfigUpdateFiles получение конфигурации файлов обновлений \nGet-PSWSUSConfigUpdateSource получение источника обновлений \nGet-PSWSUSConfiguration получение полной конфигурации WSUS \nGet-PSWSUSContentDownloadProgress получение прогресса загрузки контента \nGet-PSWSUSCurrentUserRole получение роли текущего пользователя \nGet-PSWSUSDatabaseConfig получение конфигурации базы данных \nGet-PSWSUSDownstreamServer получение конфигурации нижестоящего сервера \nGet-PSWSUSEmailConfig получение конфигурации электронной почты \nGet-PSWSUSEnabledUpdateLanguages получение включенных языков обновлений \nGet-PSWSUSEvent получение событий WSUS \nGet-PSWSUSGroup получение информации о группе \nGet-PSWSUSInstallableItem получение информации об установленных элементах \nGet-PSWSUSInstallApprovalRule получение правил утверждения установки \nGet-PSWSUSProxyServer получение информации о прокси-сервере \nGet-PSWSUSServer получение информации о сервере WSUS \nGet-PSWSUSStatus получение статуса WSUS \nGet-PSWSUSSubscription получение подписки WSUS \nGet-PSWSUSSupportedUpdateLanguages получение поддерживаемых языков обновлений \nGet-PSWSUSSyncEvent получение событий синхронизации \nGet-PSWSUSSyncHistory получение истории синхронизаций \nGet-PSWSUSSyncProgress получение прогресса синхронизации \nGet-PSWSUSSyncSchedule получение расписания синхронизации \nGet-PSWSUSUpdate получение информации об обновлении \nGet-PSWSUSUpdateApproval получение информации об утверждении обновлений \nGet-PSWSUSUpdateCategory получение категории обновлений \nGet-PSWSUSUpdateClassification получение классификации обновлений \nGet-PSWSUSUpdateFile получение файлов обновлений \nGet-PSWSUSUpdateFiles получение списка файлов обновлений \nGet-PSWSUSUpdatePerClient получение информации об обновлениях по клиентам \nGet-PSWSUSUpdateSource получение источника обновлений \nGet-PSWSUSUpdateSummary получение сводки по обновлениям \nGet-PSWSUSUpdateSummaryPerClient получение сводки по обновлениям для каждого клиента \nGet-PSWSUSUpdateSummaryPerGroup получение сводки по обновлениям для каждой группы \nImport-PSWSUSMetaData импорт метаданных WSUS \nNew-PSWSUSComputerScope создание области охвата компьютеров \nNew-PSWSUSGroup создание новой группы \nNew-PSWSUSInstallApprovalRule создание правила утверждения установки \nNew-PSWSUSUpdateScope создание области охвата обновлений \nRemove-PSWSUSClient удаление клиента \nRemove-PSWSUSClientFromGroup удаление клиента из группы \nRemove-PSWSUSGroup удаление группы \nRemove-PSWSUSInstallApprovalRule удаление правила утверждения установки \nRemove-PSWSUSUpdate удаление обновления \nReset-PSWSUSContent сброс контента WSUS \nResume-PSWSUSDownload возобновление загрузки \nResume-PSWSUSUpdateDownload возобновление загрузки обновлений \nSet-PoshWsusClassification установка классификации WSUS \nSet-PoshWSUSProduct установка продукта WSUS \nSet-PSWSUSConfigEnabledUpdateLanguages установка включенных языков обновлений \nSet-PSWSUSConfigProduct установка продукта конфигурации WSUS \nSet-PSWsusConfigProxyServer установка прокси-сервера конфигурации WSUS \nSet-PSWSUSConfigSyncSchedule установка расписания синхронизации \nSet-PSWSUSConfigTargetingMode установка режима таргетирования \nSet-PSWSUSConfigUpdateClassification установка классификации обновлений \nSet-PSWSUSConfigUpdateFiles установка файлов обновлений \nSet-PSWSUSConfigUpdateSource установка источника обновлений \nSet-PSWSUSEmailConfig установка конфигурации электронной почты \nSet-PSWSUSEnabledUpdateLanguages установка включенных языков обновлений \nSet-PSWSUSInstallApprovalRule установка правила утверждения установки \nSet-PSWSUSProxyServer установка прокси-сервера \nSet-PSWSUSSyncSchedule установка расписания синхронизации \nSet-PSWSUSTargetingMode установка режима таргетирования \nSet-PSWSUSUpdateFiles установка файлов обновлений \nSet-PSWSUSUpdateSource установка источника обновлений \nStart-PSWSUSCleanup запуск очистки WSUS \nStart-PSWSUSInstallApprovalRule запуск правила утверждения установки \nStart-PSWSUSSync запуск синхронизации \nStop-PSWSUSDownload остановка загрузки \nStop-PSWSUSSync остановка синхронизации \nStop-PSWSUSUpdateDownload остановка загрузки обновлений \nTest-PSWSUSDatabaseServerConnection тестирование подключения к серверу базы данных\n\nActiveDirectory\n\nRSAT\n\nRemote Server Administration Tools\n\nDISM.exe /Online /add-capability /CapabilityName:Rsat.ActiveDirectory.DS-LDS.Tools~~~~0.0.1.0 /CapabilityName:Rsat.GroupPolicy.Management.Tools~~~~0.0.1.0 \nAdd-WindowsCapability –online –Name Rsat.Dns.Tools~~~~0.0.1.0 \nAdd-WindowsCapability -Online -Name Rsat.DHCP.Tools~~~~0.0.1.0 \nAdd-WindowsCapability –online –Name Rsat.FileServices.Tools~~~~0.0.1.0 \nAdd-WindowsCapability -Online -Name Rsat.WSUS.Tools~~~~0.0.1.0 \nAdd-WindowsCapability -Online -Name Rsat.CertificateServices.Tools~~~~0.0.1.0 \nAdd-WindowsCapability -Online -Name Rsat.RemoteDesktop.Services.Tools~~~~0.0.1.0 \nGet-WindowsCapability -Name RSAT* -Online | Select-Object -Property DisplayName, State отобразить список установленных компанентов\n\nImport-Module AD\n$Session = New-PSSession -ComputerName $srv -Credential $cred \nExport-PSsession -Session $Session -Module ActiveDirectory -OutputModule ActiveDirectory экспортировать модуль из удаленной сесси (например, с DC) \nRemove-PSSession -Session $Session \nImport-Module ActiveDirectory \nGet-Command -Module ActiveDirectory\n\nADSI\n\nActive Directory Service Interface\n\n$d0 = $env:userdnsdomain \n$d0 = $d0 -split \"\\.\" \n$d1 = $d0[0] \n$d2 = $d0[1] \n$group = [ADSI]\"LDAP://OU=Domain Controllers,DC=$d1,DC=$d2\" \n$group | select *\n$Local_User = [ADSI]\"WinNT://./Администратор,user\" \n$Local_User | Get-Member \n$Local_User.Description \n$Local_User.LastLogin время последней авторизации локального пользователя\n\nLDAP\n\nLightweight Directory Access Protocol\n\n$ldapsearcher = New-Object System.DirectoryServices.DirectorySearcher \n$ldapsearcher.SearchRoot = \"LDAP://OU=Domain Controllers,DC=$d1,DC=$d2\" \n$ldapsearcher.Filter = \"(objectclass=computer)\" \n$dc = $ldapsearcher.FindAll().path\n$usr = $env:username cписок групп текущего пользователя \n$ldapsearcher = New-Object System.DirectoryServices.DirectorySearcher \n$ldapsearcher.Filter = \"(&amp;(objectCategory=User)(samAccountName=$usr))\" \n$usrfind = $ldapsearcher.FindOne() \n$groups = $usrfind.properties.memberof -replace \"(,OU=.+)\" \n$groups = $groups -replace \"(CN=)\"\nDC (Domain Component) - компонент доменного имени \nOU (Organizational Unit) - организационные подразделения (type), используются для упорядочения объектов \nContainer - так же используется для упорядочения объектов, контейнеры в отличии от подраделений не могут быть переименованы, удалены, созданы или связаны с объектом групповой политики (Computers, Domain Controllers, Users) \nDN (Distinguished Name) — уникальное имя объекта и местоположение в лесу AD. В DN описывается содержимое атрибутов в дереве (путь навигации), требуемое для доступа к конкретной записи или ее поиска \nCN (Common Name) - общее имя\n(Get-ADObject (Get-ADRootDSE).DefaultNamingContext -Properties wellKnownObjects).wellKnownObjects отобразить отобразить контейнеры по умолчанию \nredircmp OU=Client Computers,DC=root,DC=domain,DC=local изменить контейнер компьютеров по умолчанию \nredirusr изменить контейнер пользователей по умолчанию\n\nLAPS\n\nLocal Admin Password Management\n\nImport-module AdmPwd.ps импортировать модуль \nGet-AdmPwdPassword -ComputerName NAME посмотреть пароль \nReset-AdmPwdPassword -ComputerName NAME изменить пароль \nGet-ADComputer -Filter * -SearchBase \"DC=$d1,DC=$d2\" | Get-AdmPwdPassword -ComputerName {$_.Name} | select ComputerName,Password,ExpirationTimestamp | Out-GridView \nGet-ADComputer -Identity $srv | Get-AdmPwdPassword -ComputerName {$_.Name} | select ComputerName,Password,ExpirationTimestamp\n\nRecycle Bin\nУдаленные объекты хранятся в корзине AD в течении времени захоронения (определяется в атрибуте домена msDS-deletedObjectLifetime), заданном для леса. По умолчанию это 180 дней. Если данный срок прошел, объект все еще остается в контейнере Deleted Objects, но большинство его атрибутов и связей очищаются (Recycled Object). После истечения периода tombstoneLifetime (по умолчанию также 180 дней, но можно увеличить) объект полностью удаляется из AD автоматическим процессом очистки. \nGet-ADForest domain.local отобразить уровень работы леса \nSet-ADForestMode -Identity domain.local -ForestMode Windows2008R2Forest -force увеличить уровень работы леса \nEnable-ADOptionalFeature –Identity \"CN=Recycle Bin Feature,CN=Optional Features,CN=Directory Service,CN=Windows NT,CN=Services,CN=Configuration,DC=domain,DC=local\" –Scope ForestOrConfigurationSet –Target \"domain.local\" включить корзину \nGet-ADOptionalFeature \"Recycle Bin Feature\" | select-object name,EnabledScopes если значение EnabledScopes не пустое, значит в домене корзина Active Directory включена \nGet-ADObject -Filter 'Name -like \"*tnas*\"' -IncludeDeletedObjects найти удаленную (Deleted: True) УЗ (ObjectClass: user) в AD \nGet-ADObject -Filter 'Name -like \"*tnas*\"' –IncludeDeletedObjects -Properties *| select-object Name, sAMAccountName, LastKnownParent, memberOf, IsDeleted | fl проверить значение атрибута IsDeleted, контейнер, в котором находился пользователе перед удалением (LastKnownParent) и список групп, в которых он состоял \nGet-ADObject –filter {Deleted -eq $True -and ObjectClass -eq \"user\"} –includeDeletedObjects вывести список удаленных пользователей \nRestore-ADObject -Identity \"3dc33c7c-b912-4a19-b1b7-415c1395a34e\" восстановить по значению атрибута ObjectGUID \nGet-ADObject -Filter 'SAMAccountName -eq \"tnas-01\"' –IncludeDeletedObjects | Restore-ADObject восстановить по SAMAccountName \nGet-ADObject -Filter {Deleted -eq $True -and ObjectClass -eq 'group' -and Name -like '*Allow*'} –IncludeDeletedObjects | Restore-ADObject –Verbose восстановить группу или компьютер\n\nthumbnailPhoto\n$photo = [byte[]](Get-Content C:\\Install\\adm.jpg -Encoding byte) преобразовать файл картинки в массив байтов (jpeg/bmp файл, размером фото до 100 Кб и разрешением 96?96) \nSet-ADUser support4 -Replace @{thumbnailPhoto=$photo} задать значение атрибута thumbnailPhoto\n\nADDomainController\nGet-ADDomainController выводит информацию о текущем контроллере домена (LogonServer), который используется данным компьютером для аутентификации (DC выбирается при загрузке в соответствии с топологией сайтов AD) \nGet-ADDomainController -Discover -Service PrimaryDC найти контроллер с ролью PDC в домене \nGet-ADDomainController -Filter * | ft HostName,IPv4Address,Name,Site,OperatingSystem,IsGlobalCatalog список все DC, принадлежность к сайту, версии ОС и GC\nПри загрузке ОС служба NetLogon делает DNS запрос со списком контроллеров домена (к SRV записи _ldap._tcp.dc.msdcs.domain), DNS возвращает список DC в домене с записью Service Location (SRV). Клиент делает LDAP запрос к DC для определения сайта AD по своему IP адресу. Клиент через DNS запрашивает список контроллеров домена в сайте (в разделе _tcp.sitename._sites…).\nUSN (Update Sequence Numbers) - счетчик номера последовательного обновления, который существует у каждого объекта AD. При репликации контроллеры обмениваются значениями USN, объект с более низким USN будет при репликации перезаписан объектом с более высоким USN. Находится в свойствах - Object (включить View - Advanced Features). Каждый контроллер домена содержит отдельный счетчик USN, который начинает отсчет в момент запуска процесса Dcpromo и продолжает увеличивать значения в течение всего времени существования контроллера домена. Значение счетчика USN увеличивается каждый раз, когда на контроллере домена происходит транзакция, это операции создания, обновления или удаления объекта.\nGet-ADDomainController -Filter * | % { отобразить USN объекта на всех DC в домене\\Get-ADUser -Server $_.HostName -Identity support4 -Properties uSNChanged | select SamAccountName,uSNChanged\\}`\ndcpromo /forceremoval принудительно выполнит понижение в роли контроллера домена до уровня рядового сервера. После понижения роли выполняется удаление всех ссылок в домене на этот контроллер. Далее производит включение сервера в состав домена, и выполнение обратного процесса, т.е. повышение сервера до уровня контроллера домена.\n\nADComputer\nnltest /DSGETDC:$env:userdnsdomain узнать на каком DC аудентифицирован хост (Logon Server) \nnltest /SC_RESET:$env:userdnsdomain\\srv-dc2.$env:userdnsdomain переключить компьютер на другой контроллер домена AD вручную (The command completed successfully) \nGet-ADComputer –Identity $env:computername -Properties PasswordLastSet время последней смены пароля на сервере \nTest-ComputerSecureChannel –verbose проверить доверительные отношения с доменом (соответствует ли локальный пароль компьютера паролю, хранящемуся в AD) \nReset-ComputerMachinePassword -Credential domain\\admin принудительно обновить пароль \nNetdom ResetPWD /Server:dc-01 /UserD:domain\\admin /PasswordD:* сбросить хэш пароля компьютера в домене (перезагрузка не требуется) \nSearch-ADAccount -AccountDisabled -ComputersOnly | select Name,LastLogonDate,Enabled отобразить все отключенные компьютеры\nGet-ADComputer -Filter * -Properties * | select name список всех компьютеров в домене (Filter), вывести все свойства (Properties) \nGet-ADComputer -Identity $srv -Properties * | ft Name,LastLogonDate,PasswordLastSet,ms-Mcs-AdmPwd -Autosize конкретного компьютера в AD (Identity) \nGet-ADComputer -SearchBase \"OU=Domain Controllers,DC=$d1,DC=$d2\" -Filter * -Properties * | ft Name, LastLogonDate, distinguishedName -Autosize поиск в базе по DN (SearchBase)\n(Get-ADComputer -Filter {enabled -eq \"true\"}).count получить общее количество активных (незаблокированных) компьютеров \n(Get-ADComputer -Filter {enabled -eq \"true\" -and OperatingSystem -like \"*Windows Server 2016*\"}).count кол-во активных копьютеров с ОС WS 2016\nGet-ADComputer -Filter * -Properties * | select @{Label=\"Ping Status\"; Expression={ \n$ping = ping -n 1 -w 50 $_.Name \nif ($ping -match \"TTL\") {\"Online\"} else {\"Offline\"} \n}}, \n@{Label=\"Status\"; Expression={ \nif ($_.Enabled -eq \"True\") {$_.Enabled -replace \"True\",\"Active\"} else {$_.Enabled -replace \"False\",\"Blocked\"} \n}}, Name, IPv4Address, OperatingSystem, @{Label=\"UserOwner\"; Expression={$_.ManagedBy -replace \"(CN=|,.+)\"} \n},Created | Out-GridView\n\nADUser\nGet-ADUser -Identity support4 -Properties * список всех атрибутов \nGet-ADUser -Identity support4 -Properties DistinguishedName, EmailAddress, Description путь DN, email и описание \nGet-ADUser -Filter {(Enabled -eq \"True\") -and (mail -ne \"null\")} -Properties mail | ft Name,mail список активных пользователей и есть почтовый ящик \nGet-ADUser -Filter {SamAccountName -like \"*\"} | Measure-Object посчитать кол-во всех аккаунтов (Count) \nGet-ADUser -Filter * -Properties WhenCreated | sort WhenCreated | ft Name, whenCreated дата создания \nGet-ADUser -Identity support4 -property LockedOut | select samaccountName,Name,Enabled,Lockedout \nEnabled=True учетная запись включена - да \nLockedout=False учетная запись заблокирована (например, политикой паролей) - нет \nGet-ADUser -Identity support4 | Unlock-ADAccount разблокировать учетную запись \nDisable-ADAccount -Identity support4 отключить учетную запись \nEnable-ADAccount -Identity support4 включить учетную запись \nSearch-ADAccount -LockedOut найти все заблокированные учетные записи \nSearch-ADAccount -AccountDisabled | select Name,LastLogonDate,Enabled отобразить все отключенные учетные записи с временем последнего входа\nGet-ADUser -Identity support4 -Properties PasswordLastSet,PasswordExpired,PasswordNeverExpires \nPasswordLastSet время последней смены пароля \nPasswordExpired=False пароль истек - нет \nPasswordNeverExpires=True срок действия пароля не истекает - да \nSet-ADAccountPassword support4 -Reset -NewPassword (ConvertTo-SecureString -AsPlainText \"password\" -Force -Verbose) изменить пароль учетной записи \nSet-ADUser -Identity support4 -ChangePasswordAtLogon $True смена пароля при следующем входе в систему\n$day = (Get-Date).adddays(-90) \nGet-ADUser -filter {(passwordlastset -le $day)} | ft пользователи, которые не меняли свой пароль больше 90 дней\n$day = (Get-Date).adddays(-30) \nGet-ADUser -filter {(Created -ge $day)} -Property Created | select Name,Created Новые пользователи за 30 дней\n$day = (Get-Date).adddays(-360) \nGet-ADUser -Filter {(LastLogonTimestamp -le $day)} -Property LastLogonTimestamp | select Name,SamAccountName,@{n='LastLogonTimestamp';e={[DateTime]::FromFileTime($_.LastLogonTimestamp)}} | sort -Descending LastLogonTimestamp пользователи, которые не логинились больше 360 дней. Репликация атрибута LastLogonTimestamp составляет от 9 до 14 дней. \n| Disable-ADAccount $_.SamAccountName заблокировать \n-WhatIf отобразить вывод без применения изменений\n\nADGroupMember\n(Get-ADUser -Identity support4 -Properties MemberOf).memberof список групп в которых состоит пользователь \nGet-ADGroupMember -Identity \"Domain Admins\" | Select Name,SamAccountName список пользователей в группе \nAdd-ADGroupMember -Identity \"Domain Admins\" -Members support5 добавить в группу \nRemove-ADGroupMember -Identity \"Domain Admins\" -Members support5 -force удалить из группы \nGet-ADGroup -filter * | where {!($_ | Get-ADGroupMember)} | Select Name отобразить список пустых групп (-Not)\n\nADReplication\nGet-Command -Module ActiveDirectory -Name *Replication* список всех командлетов модуля \nGet-ADReplicationFailure -Target dc-01 список ошибок репликации с партнерами \nGet-ADReplicationFailure -Target $env:userdnsdomain -Scope Domain \nGet-ADReplicationPartnerMetadata -Target dc-01 | select Partner,LastReplicationAttempt,LastReplicationSuccess,LastReplicationResult,LastChangeUsn время последней и время успешной репликации с партнерами \nGet-ADReplicationUpToDatenessVectorTable -Target dc-01 Update Sequence Number (USN) увеличивается каждый раз, когда на контроллере домена происходит транзакция (операции создания, обновления или удаления объекта), при репликации DC обмениваются значениями USN, объект с более низким USN при репликации будет перезаписан высоким USN.\n\nrepadmin\nrepadmin /replsummary отображает время последней репликации на всех DC по направлению (Source и Destination) и их состояние с учетом партнеров \nrepadmin /showrepl $srv отображает всех партнеров по реплкации и их статус для всех разделов Naming Contexts (DC=ForestDnsZones, DC=DomainDnsZones, CN=Schema, CN=Configuration) \nrepadmin /replicate $srv2 $srv1 DC=domain,DC=local  выполнить репликацию с $srv1 на $srv2 только указанный раздела домена \nrepadmin /SyncAll /AdeP запустить межсайтовую исходящую репликацию всех разделов от текущего сервера со всеми партнерами по репликации \n/A выполнить для всех разделов NC \n/d в сообщениях идентифицировать серверы по DN (вместо GUID DNS - глобальным уникальным идентификаторам) \n/e межсайтовая синхронизация (по умолчанию синхронизирует только с DC текущего сайта) \n/P извещать об изменениях с этого сервера (по умолчанию: опрашивать об изменениях) \nrepadmin /Queue $srv отображает кол-во запросов входящей репликации (очередь), которое необходимо обработать (причиной может быть большое кол-во партнеров или формирование 1000 объектов скриптом) \nrepadmin /showbackup * узнать дату последнего Backup\nError: 1722 сервер rpc недоступен (ошибка отката репликации). Проверить имя домена в настройках сетевого адаптера, первым должен идти адрес DNS-сервера другого контроллера домена, вторым свой адрес. \nGet-Service -ComputerName $srv | select name,status | ? name -like \"RpcSs\" \nGet-Service -ComputerName $srv -Name RpcSs -RequiredServices зависимые службы \nЗависимые службы RPC: \n“Служба сведений о подключенных сетях” - должен быть включен отложенный запуск. Если служба срабатывает до “службы списка сетей”, может падать связь с доменом (netlogon) \n“Центр распространения ключей Kerberos” \n“DNS-сервер” \nnslookup $srv \ntnc $srv -p 135 \nrepadmin /retry повторить попытку привязки к целевому DC, если была ошибка 1722 или 1753 (RPC недоступен)\nrepadmin /showrepl $srv \nLast attempt @ 2022-07-15 10:46:01 завершена с ошибкой, результат 8456 (0x2108) при проверки showrepl этого партнера, его ошибка: 8457 (0x2109) \nLast success @ 2022-07-11 02:29:46 последний успех \nКогда репликация автоматически отключена, ОС записывает в DSA - not writable одно из четырех значений: \nPath: HKEY_LOCAL_MACHINE\\System\\CurrentControlSet\\Services\\NTDS\\Parameters \nDsa Not Writable \n#define DSA_WRITABLE_GEN 1 версия леса несовместима с ОС \n#define DSA_WRITABLE_NO_SPACE 2 на диске, где размещена база данных Active Directory или файлы журналов (логи), недостаточно свободного места \n#define DSA_WRITABLE_USNROLLBCK 4 откат USN произошел из-за неправильного отката базы данных Active Directory во времени (восстановление из снапшота) \n#define DSA_WRITABLE_CORRUPT_UTDV 8 вектор актуальности поврежден на локальном контроллере домена\n\ndcdiag\ndcdiag /s:&lt;DomainController&gt; [/n:&lt;NamingContext&gt;] [[/u:&lt;domain\\user&gt;] [/p:&lt;password&gt;]] [{/a|/e}{/q|/v}] [/f:&lt;LogFile&gt;] [/ferr:&lt;ErrorLog&gt;] [/test:&lt;test&gt;] [/fix] \ndcdiag /Test:replications /s:dc-01 отображает ошибки репликации \ndcdiag /Test:DNS /e /v /q тест DNS \n/a проверка всех серверов данного сайта \n/e проверка всех серверов предприятия \n/q выводить только сообщения об ошибках \n/v выводить подробную информацию \n/fix автоматически исправляет ошибки \n/test: \nNetLogons проверка наличие прав на выполнение репликации \nConnectivity проверяет регистрацию DNS для каждого контроллера домена, отправляет тестовый эхо-пакет на каждый контроллер домена и проверяет подключение по протоколам LDAP и RPC к каждому контроллеру домена \nServices проверяет работоспособность всех служб, необходимых для работы контроллера домена, на указанном контроллере домена \nSystemlog проверяет наличие ошибок в журналах контроллера домена \nFRSEvent проверяет ошибки репликации в работе службы репликации файлов, что может означать наличие проблем в репликации SYSVOL и, таким образом, целостности копий объектов групповых политик \nFSMOCheck не проверяет роли хозяев операций, а вместо этого запрашивает сервер глобального каталога, первичный контроллер домена, предпочтительный сервер времени, сервер времени и центр распространения ключей (контроллер домена может подключиться к KDC, PDC, серверу глобального каталога) \nKnowsOfRoleHolders пgроверяет возможность подключения контроллеров домена ко всем пяти хозяевам операций (ролями FSMO) \nMachineAccount проверяет правильность регистрации учетной записи целевого компьютера и правильность объявлений служб этого компьютера (корректность доверительных отношения с доменом). Если обнаружена ошибка, ее можно исправить с помощью утилиты dcdiag, указав параметры /fixmachineaccount или /recreatemachineaccount \nAdvertising проверяет, правильно ли контроллер домена сообщает о себе и о своей роли хозяина операций. Этот тест завершиться неудачно, если служба NetLogon не запущена \nCheckSDRefDom проверяет правильность доменов ссылок дескрипторов безопасности для каждого раздела каталогов программ \nCrossRefValidation проверяет правильность перекрестных ссылок для доменов \nRRSSysvol проверяет состояние готовности для FRS SYSVOL \nIntersite проверяет наличие ошибок, которые могут помешать нормальной репликации между сайтами. Компания Microsoft предупреждает, что иногда результаты этого теста могут оказаться неточными \nKCCEvent проверяет безошибочность создания объектов соединений для репликации между сайтами \nNCSecDesc проверяет правильность разрешений для репликации в дескрипторах безопасности для заголовков контекста именования \nObjectsReplicated проверяет правильность репликации агента сервера каталогов и объектов учетных записей компьютеров \nOutboundSecureChannels проверяется наличие безопасных каналов между всеми контроллерами домена в интересующем домене \nReplications проверяет возможность репликации между контроллерами домена и сообщает обо всех ошибках при репликации \nRidManager проверяет работоспособность и доступность хозяина относительных идентификаторов \nVerifyEnterpriseReferences проверяет действительность системных ссылок службы репликации файлов для всех объектов на всех контроллерах домена в лесу \nVerifyReferences проверяет действительность системных ссылок службы репликации файлов для всех объектов на указанном контроллере домена \nVerifyReplicas проверяет действительность всех разделов каталога приложения на всех серверах, принимающих участие в репликации\n\nntdsutil\nПеренос БД AD (ntds.dit): \nGet-Acl C:\\Windows\\NTDS | Set-Acl D:\\AD-DB скопировать NTFS разрешения на новый каталог \nStop-Service -ComputerName dc -name NTDS остановить службу Active Directory Domain Services \nntdsutil запустить утилиту ntdsutil \nactivate instance NTDS выбрать активный экземпляр базы AD \nfiles перейдем в контекст files, в котором возможно выполнение операция с файлами базы ntds.dit \nmove DB to D:\\AD-DB\\ перенести базу AD в новый каталог (предварительно нужно его создать) \ninfo проверить, что БД находится в новом каталоге \nmove logs to D:\\AD-DB\\ переместим в тот же каталог файлы с журналами транзакций \nquit \nStart-Service -ComputerName dc -name NTDS\nСброс пароля DSRM (режим восстановления служб каталогов):  \nntdsutil \nset dsrm password \nreset password on server NULL \nновый пароль \nподтверждение пароля \nquit \nquit\nСинхронизировать с паролем УЗ в AD: \nntdsutil \nset dsrm password \nsync from domain account dsrmadmin \nquit \nquit\nОшибка 0x00002e2 при загрузке ОС. \nЗагрузиться в режиме восстанавления WinRE (Windows Recovery Environment) - Startup Settings - Restart - DSRM (Directory Services Restore Mode) \nreagentc /boottore shutdown /f /r /o /t 0 перезагрузка в режиме WinRE - ОС на базе WinPE (Windows Preinstallation Environment), образ winre.wim находится на скрытом разделе System Restore \nНа контроллере домена единственная локальная учетная запись — администратор DSRM. Пароль создается при установке роли контроллера домена ADDS на сервере (SafeModeAdministratorPassword). \nntdsutil \nactivate instance ntds \nFiles \nInfo \nintegrity проверить целостность БД \nОшибка: Failed to open DIT for AD DS/LDS instance NTDS. Error -2147418113 \nmkdir c:\\ntds_bak \nxcopy c:\\Windows\\NTDS\\*.* c:\\ntds_bak backup содержимого каталога с БД \nesentutl /g c:\\windows\\ntds\\ntds.dit проверим целостность файла \nВывод: Integrity check completed. Database is CORRUPTED ошибка, база AD повреждена \nesentutl /p c:\\windows\\ntds\\ntds.dit исправить ошибки \nВывод: Operation completed successfully in xx seconds. нет ошибок \nesentutl /g c:\\windows\\ntds\\ntds.dit проверим целостность файла \nВыполнить анализ семантики базы с помощью ntdsutil: \nntdsutil \nactivate instance ntds \nsemantic database analysis \ngo \ngo fixup исправить семантические ошибки \nСжать файл БД: \nactivate instance ntds \nfiles \ncompact to C:\\Windows\\NTDS\\TEMP \ncopy C:\\Windows\\NTDS\\TEMP\\ntds.dit C:\\Windows\\NTDS\\ntds.dit заменить оригинальный файл ntds.dit \nDel C:\\Windows\\NTDS\\*.log удалить все лог файлы из каталога NTDS\n\nGPO\nGet-Command -Module GroupPolicy \nGet-GPO -Domain domain.local -All | ft \nGet-GPO -Name LAPS \n[xml](Get-GPOReport LAPS -ReportType Xml) \nGet-GPPermission -Name LAPS -All \nGet-GPO LAPS | New-GPLink -Target \"ou=servers,dc=domain,dc=local\" \nSet-GPLink -Name LAPS -Target \"ou=servers,dc=domain,dc=local\" -LinkEnabled No \nBackup-GPO -Name LAPS -Path \"$home\\Desktop\" \nBackup-GPO -All -Path \"$home\\Desktop\" \nRestore-GPO -Name LAPS -Path C:\\Backup\\GPOs\\\n\nServerManager\nGet-Command *WindowsFeature* source module ServerManager \nGet-WindowsFeature -ComputerName \"localhost\" \nGet-WindowsFeature | where Installed -eq $True список установленных ролей и компонентов \nGet-WindowsFeature | where FeatureType -eq \"Role\" отсортировать по списку ролей \nInstall-WindowsFeature -Name DNS установить роль \nGet-Command *DNS* \nGet-DnsServerSetting -ALL \nUninstall-WindowsFeature -Name DNS удалить роль\n\nPSWA\nInstall-WindowsFeature -Name WindowsPowerShellWebAccess -IncludeManagementTools \nInstall-PswaWebApplication -UseTestCertificate Создать веб-приложение /pswa \nAdd-PswaAuthorizationRule -UserGroupName \"$domain\\Domain Admins\" -ComputerName * -ConfigurationName * -RuleName \"For Admins\" добавить права авторизации\n\nWSB (Windows Server Backup)\nПри создании backup DC через WSB, создается копия состояния системы (System State), куда попадает база AD (NTDS.DIT), объекты групповых политик, содержимое каталога SYSVOL, реестр, метаданные IIS, база AD CS, и другие системные файлы и ресурсы. Резервная копия создается через службу теневого копирования VSS. \nGet-WindowsFeature Windows-Server-Backup проверить установлена ли роль \nAdd-Windowsfeature Windows-Server-Backup –Includeallsubfeature установить роль\n\n\nRDS\nGet-Command -Module RemoteDesktop \nGet-RDServer -ConnectionBroker $broker список всех серверов в фермеы, указывается полное доменное имя при обращение к серверу с ролью RDCB \nGet-RDRemoteDesktop -ConnectionBroker $broker список коллекций \n(Get-RDLicenseConfiguration -ConnectionBroker $broker | select *).LicenseServer список серверов с ролью RDL \nGet-RDUserSession -ConnectionBroker $broker список всех активных пользователей \nDisconnect-RDUser -HostServer $srv -UnifiedSessionID $id -Force отключить сессию пользователя \nGet-RDAvailableApp -ConnectionBroker $broker -CollectionName C03 список установленного ПО на серверах в коллекции \n(Get-RDSessionCollectionConfiguration -ConnectionBroker $broker -CollectionName C03 | select *).CustomRdpProperty use redirection server name:i:1 \nGet-RDConnectionBrokerHighAvailability\n\nDNSServer\nGet-Command -Module DnsServer \nShow-DnsServerCache отобразить весь кэш DNS-сервера \nShow-DnsServerCache | where HostName -match ru \nClear-DnsServerCache \nGet-DnsServerCache \nGet-DnsServerDiagnostics\n\nSync-DnsServerZone –passthru синхронизировать зоны с другими DC в домене \nRemove-DnsServerZone -Name domain.local удалить зону \nGet-DnsServerResourceRecord -ZoneName domain.local -RRType A вывести все А-записи в указанной зоне \nAdd-DnsServerResourceRecordA -Name new-host-name -IPv4Address 192.168.1.100 -ZoneName domain.local -TimeToLive 01:00:00 -CreatePtr создать А-запись и PTR для нее \nRemove-DnsServerResourceRecord -ZoneName domain.local -RRType A -Name new-host-name –Force удалить А-запись\n\n\nDHCPServer\nGet-Command -Module DhcpServer\n\nAdd-DhcpServerv4Reservation -ScopeId 192.168.1.0 -IPAddress 192.168.1.10 -ClientId 00-50-56-C0-00-08 -Description \"new reservation\"\n\nDFS\ndfsutil /root:\\\\domain.sys\\public /export:C:\\export-dfs.txt экспорт конфигурации namespace root \ndfsutil /AddFtRoot /Server:\\\\$srv /Share:public на новой машине предварительно создать корень на основе домена \ndfsutil /root:\\\\domain.sys\\public /import:C:\\export-dfs.txt /&lt;verify /set Import (перед импортом данных в существующий корень DFS, утилита создает резервную копию конфигурации корня в текущем каталоге, из которого запускается утилита dfsutil) \n/verify выводит изменения, которые будут внесены в процессе импорта, без применения \n/set меняет целевое пространство имен путем полной перезаписи и замены на конфигурацию пространства имен из импортируемого файла \n/merge импортирует конфигурацию пространства имен в дополнение к существующей конфигурации для слияния, параметры из файла конфигурации будут иметь больший приоритет, чем существующие параметры пространства имен\nExport-DfsrClone экспортирует клонированную базу данных репликации DFS и параметры конфигурации тома \nGet-DfsrCloneState получает состояние операции клонирования базы данных \nImport-DfsrClone импортирует клонированную базу данных репликации DFS и параметры конфигурации тома\nnet use x: \\\\$srv1\\public\\* примонтировать диск \nGet-DfsrFileHash x:\\* | Out-File C:\\$srv1.txt забрать hash всех файлов диска в файл (файлы с одинаковыми хешами всегда являются точными копиями друг друга) \nnet use x: /d отмонтировать \nnet use x: \\\\$srv2\\public\\* \nGet-DfsrFileHash x:\\* | Out-File C:\\$srv2.txt \nnet use x: /d \nCompare-Object -ReferenceObject (Get-Content C:\\$srv1.txt) -DifferenceObject (Get-Content C:\\$srv2.txt) -IncludeEqual сравнить содержимое файлов\nGet-DfsrBacklog -DestinationComputerName \"fs-06\" -SourceComputerName \"fs-05\" -GroupName \"folder-rep\" -FolderName \"folder\" -Verbose получает список ожидающих обновлений файлов между двумя партнерами репликации DFS \nGet-DfsrConnection отображает группы репликации, участников и статус \nGet-DfsReplicatedFolder отображает имя и полный путь к папкам реликации в системе DFS \nGet-DfsrState -ComputerName fs-06 -Verbose состояние репликации DFS для члена группы \nGet-DfsReplicationGroup отображает группы репликации и их статус \nAdd-DfsrConnection создает соединение между членами группы репликации \nAdd-DfsrMember добавляет компьютеры в группу репликации \nConvertFrom-DfsrGuid преобразует идентификаторы GUID в понятные имена в заданной группы репликации \nGet-DfsrConnectionSchedule получает расписание соединений между членами группы репликации \nGet-DfsrGroupSchedule извлекает расписание группы репликации \nGet-DfsrIdRecord получает записи ID для реплицированных файлов или папок из базы данных репликации DFS \nGet-DfsrMember получает компьютеры в группе репликации \nGet-DfsrMembership получает параметры членства для членов групп репликации \nGet-DfsrPreservedFiles получает список файлов и папок, ранее сохраненных репликацией DFS \nGet-DfsrServiceConfiguration получает параметры службы репликации DFS для членов группы \nGrant-DfsrDelegation предоставляет разрешения участникам безопасности для группы репликации \nRevoke-DfsrDelegation отменяет разрешения участников безопасности для группы репликации \nNew-DfsReplicationGroup создает группу репликации \nNew-DfsReplicatedFolder создает реплицированную папку в группе репликации \nRemove-DfsrConnection удаляет соединение между членами группы репликации \nRemove-DfsReplicatedFolder удаляет реплицированную папку из группы репликации \nRemove-DfsReplicationGroup удаляет группу репликации \nRemove-DfsrMember удаляет компьютеры из группы репликации \nRestore-DfsrPreservedFiles восстанавливает файлы и папки, ранее сохраненные репликацией DFS \nSet-DfsrConnection изменяет параметры соединения между членами группы репликации \nSet-DfsrConnectionSchedule изменяет параметры расписания соединений между членами группы репликации \nSet-DfsReplicatedFolder изменяет настройки реплицированной папки \nSet-DfsReplicationGroup изменяет группу репликации \nSet-DfsrGroupSchedule изменяет расписание группы репликации \nSet-DfsrMember изменяет информацию о компьютере-участнике в группе репликации \nSet-DfsrMembership настраивает параметры членства для членов группы репликации \nSet-DfsrServiceConfiguration изменяет параметры службы репликации DFS \nSync-DfsReplicationGroup синхронизирует репликацию между компьютерами независимо от расписания \nSuspend-DfsReplicationGroup приостанавливает репликацию между компьютерами независимо от расписания \nUpdate-DfsrConfigurationFromAD инициирует обновление службы репликации DFS \nWrite-DfsrHealthReport создает отчет о работоспособности репликации DFS \nWrite-DfsrPropagationReport создает отчеты для тестовых файлов распространения в группе репликации \nStart-DfsrPropagationTest создает тестовый файл распространения в реплицированной папке\n\nStorageReplica\nInstall-WindowsFeature Storage-Replica –IncludeManagementTools -Restart \nGet-Command -Module StorageReplica \nTest-SRTopology проверить соответствует ли сервер и канал связи технологии Storage Replica \nNew-SRPartnership -SourceComputerName srv-01 -SourceRGName srv-01-rep-group-01 -SourceVolumeName D: -SourceLogVolumeName L: -DestinationComputerName srv-02 -DestinationRGName srv-02-rep-group-01 -DestinationVolumeName D: -DestinationLogVolumeName L: -LogSizeInBytes 1GB \nGet-Counter -Counter \"\\Storage Replica Statistics(*)\" \nGet-WinEvent -ProviderName Microsoft-Windows-StorageReplica -max 10 \nSet-SRPartnership -ReplicationMode Asynchronous переключить режим репликации на асинхронный \nSet-SRPartnership -NewSourceComputerName srv-02 -SourceRGName srv-02-rep-group-01 -DestinationComputerName srv-01 -DestinationRGName srv-01-rep-group-01 изменить вручную направление репликации данных, переведя вторичную копию в онлайн режим (при выходе из строя основного сервера) \nGet-SRGroup информация о состояние группы реплизации \nGet-SRPartnerShip информация о направлении репликации \n(Get-SRGroup).Replicas | Select-Object numofbytesremaining проверить длину очереди копирования \nGet-SRPartnership | Remove-SRPartnership удалить реплизацию на основном сервере \nGet-SRGroup | Remove-SRGroup удалить реплизацию на обоих серверах\n\nPS2EXE\nInstall-Module ps2exe -Repository PSGallery \nGet-Module -ListAvailable список всех модулей \n-noConsole использовать GUI, без окна консоли powershell \n-noOutput выполнение в фоне \n-noError без вывода ошибок \n-requireAdmin при запуске запросить права администратора \n-credentialGUI вывод диалогового окна для ввода учетных данных \nInvoke-ps2exe -inputFile \"$home\\Desktop\\WinEvent-Viewer-1.1.ps1\" -outputFile \"$home\\Desktop\\WEV-1.1.exe\" -iconFile \"$home\\Desktop\\log_48px.ico\" -title \"WinEvent-Viewer\" -noConsole -noOutput -noError\n\nNSSM\n$powershell_Path = (Get-Command powershell).Source \n$NSSM_Path = (Get-Command \"C:\\WinPerf-Agent\\NSSM-2.24.exe\").Source \n$Script_Path = \"C:\\WinPerf-Agent\\WinPerf-Agent-1.1.ps1\" \n$Service_Name = \"WinPerf-Agent\" \n&amp; $NSSM_Path install $Service_Name $powershell_Path -ExecutionPolicy Bypass -NoProfile -f $Script_Path создать Service \n&amp; $NSSM_Path start $Service_Name запустить \n&amp; $NSSM_Path status $Service_Name статус \n$Service_Name | Restart-Service перезапустить \n$Service_Name | Get-Service статус \n$Service_Name | Stop-Service остановить \n&amp; $NSSM_Path set $Service_Name description \"Check performance CPU and report email\" изменить описание \n&amp; $NSSM_Path remove $Service_Name удалить\n\nJobs\nGet-Job получение списка задач \nStart-Job запуск процесса \nStop-Job остановка процесса \nSuspend-Job приостановка работы процесса \nResume-Job восстановление работы процесса \nWait-Job ожидание вывода команды \nReceive-Job получение результатов выполненного процесса \nRemove-Job удалить задачу\n\nStart-PingJob -Network 192.168.3.0 \n$(Measure-Command {Start-PingJob -Network 192.168.3.0}).TotalSeconds 60 Seconds\n\nThreadJob\nInstall-Module -Name ThreadJob \nGet-Module ThreadJob -list \nStart-ThreadJob {ping ya.ru} | Out-Null создать фоновую задачу \nGet-Job | Receive-Job -Keep отобразить и не удалять вывод \n(Get-Job).HasMoreData если False, то вывод команы удален \n(Get-Job)[-1].Output отобразить вывод последней задачи\n\nStart-PingThreadJob -Network 192.168.3.0 \n$(Measure-Command {Start-PingThread -Network 192.168.3.0}).TotalSeconds 24 Seconds\n\nPoshRSJob\nInstall-Module -Name PoshRSJob\n\nStart-PingRSJob -Network 192.168.3.0 \n$(Measure-Command {Start-PingRSJob -Network 192.168.3.0}).TotalSeconds 10 Seconds\n\nInvoke-Parallel\n\nGet-Help Invoke-Parallel -Full\n\nStart-PingInvokeParallel -Network 192.168.3.0 \n$(Get-History)[-1].Duration.TotalSeconds 7 seconds\n\n\nForEach-Object-Parallel\n\nStart-PingParallel -Network 192.168.3.0 \n$(Get-History)[-1].Duration.TotalSeconds 2 seconds\n\nStart-TestConnectParallel -Network 192.168.3.0 -Csv | ConvertFrom-Csv \n$(Get-History)[-1].Duration.TotalSeconds 3 seconds\n\n\nSMTP\n\nNet.Mail\n\nSend-SMTP \"This is a test email from PowerShell\"\n\nSMTP over OpenSSL\n\n\nSwaks\nSwaks - SMTP клиент на Perl\n\n\nVMWare/PowerCLI\nInstall-Module -Name VMware.PowerCLI # -AllowClobber установить модуль (PackageProvider: nuget) \nGet-Module -ListAvailable VMware* | Select Name,Version \nImport-Module VMware.VimAutomation.Core импортировать в сессию \nGet-PSProvider | format-list Name,PSSnapIn,ModuleName список оснасток Windows PowerShell\nGet-PowerCLIConfiguration конфигурация подключения \nSet-PowerCLIConfiguration -Scope AllUsers -InvalidCertificateAction ignore -confirm:$false eсли используется самоподписанный сертификат, изменить значение параметра InvalidCertificateAction с Unset на Ignore/Warn \nSet-PowerCLIConfiguration -Scope AllUsers -ParticipateInCeip $false отключить уведомление сбора данных через VMware Customer Experience Improvement Program (CEIP)\nRead-Host –AsSecureString | ConvertFrom-SecureString | Out-File \"$home\\Documents\\vcsa_password.txt\" зашифровать пароль и сохранить в файл \n$esxi = \"vcsa.domain.local\" \n$user = \"administrator@vsphere.local\" \n$pass = Get-Content \"$home\\Documents\\vcsa_password.txt\" | ConvertTo-SecureString прочитать пароль \n$pass = \"password\" \n$Cred = New-Object -TypeName System.Management.Automation.PSCredential -ArgumentList $user ,$pass \nConnect-VIServer $esxi -User $Cred.Username -Password $Cred.GetNetworkCredential().password подключиться, используя PSCredential ($Cred) \nConnect-VIServer $esxi -User $user -Password $pass подключиться, используя логин и пароль\nGet-Command –Module *vmware* отобразить список команд модуля VMware \nGet-Command –Module *vmware* -name *get*iscsi* найти команды модуля VMware, связанные с iSCSI \nGet-IScsiHbaTarget получить цели iSCSI HBA (Host Bus Adapter) \nGet-Datacenter получить список датацентров в инфраструктуре VMware \nGet-Cluster список кластеров \nGet-VMHost список хостов виртуальных машин (ESXi хостов) \nGet-VMHost | Select-Object Name,Model,ProcessorType,MaxEVCMode,NumCpu,CpuTotalMhz,CpuUsageMhz,MemoryTotalGB,MemoryUsageGB получить информацию о хостах виртуальных машин, включая имя, модель, тип процессора и использование ресурсов \nGet-VMHostDisk | Select-Object VMHost,ScsiLun,TotalSectors получить информацию о дисках хостов виртуальных машин, включая хост, SCSI LUN и общее количество секторов\nGet-Datastore список всех хранилищ данных \nGet-Datastore TNAS-vmfs-4tb-01 получить информацию о хранилище данных с именем TNAS-vmfs-4tb-01 \nGet-Datastore TNAS-vmfs-4tb-01 | get-vm получить список виртуальных машин, которые используют хранилище данных \nGet-Datastore -RelatedObject vm-01 получить информацию о хранилищах данных, связанных с виртуальной машиной \n$(Get-Datastore TNAS-vmfs-4tb-01).ExtensionData.Info.GetType() получить тип информации о хранилище данных \n$(Get-Datastore TNAS-vmfs-4tb-01).ExtensionData.Info.Vmfs.Extent получить информацию о том, на каких дисках находится хранилище данных\nGet-Command –Module *vmware* -name *disk* найти команды модуля VMware, связанные с дисками \nGet-VM vm-01 | Get-Datastore получить информацию о хранилищах данных, используемых виртуальной машиной \nGet-VM vm-01 | Get-HardDisk получить информацию о подключенных дисках к виртуальной машины \nGet-VM | Get-HardDisk | select Parent,Name,CapacityGB,StorageFormat,FileName | ft получить информацию о дисках всех виртуальных машин, включая родительскую ВМ, имя, емкость, формат и имя файла \nCopy-HardDisk скопировать жесткий диск виртуальной машины \nGet-VM | Get-Snapshot список всех снимков виртуальных машин \nGet-VM | where {$_.Powerstate -eq \"PoweredOn\"} список всех включенных виртуальных машин \nGet-VMHost esxi-05 | Get-VM | where {$_.Powerstate -eq \"PoweredOff\"} | Move-VM –Destination (Get-VMHost esxi-06) переместить все выключенные виртуальные машины с хоста esxi-05 на хост esxi-06\n\nGet-VMGuest vm-01 | Update-Tools обновить VMware Tools на виртуальной машине vm-01 \nGet-VMGuest vm-01 | select OSFullName,IPAddress,HostName,State,Disks,Nics,ToolsVersion получить информацию о гостевой операционной системе виртуальной машины vm-01 (имя ОС, IP-адрес, имя хоста, состояние, диски, сетевые адаптеры и версию VMware Tools) \nGet-VMGuest * | select -ExpandProperty IPAddress получить IP-адреса всех гостевых ОС виртуальных машин \nRestart-VMGuest -vm vm-01 -Confirm:$False перезагрузить гостевую ОС виртуальной машины без запроса подтверждения \nStart-VM -vm vm-01 -Confirm:$False включить виртуальную машину без запроса подтверждения \nShutdown-VMGuest -vm vm-01 -Confirm:$false выключить\nNew-VM –Name vm-01 -VMHost esxi-06 –ResourcePool Production –DiskGB 60 –DiskStorageFormat Thin –Datastore TNAS-vmfs-4tb-01 создать новую виртуальную машину vm-01 на хосте esxi-06 в пуле ресурсов Production с диском 60 ГБ в формате Thin и размещением на хранилище данных TNAS-vmfs-4tb-01\nGet-VM vm-01 | Copy-VMGuestFile -Source \"\\\\$srv\\Install\\Soft\\Btest.exe\" -Destination \"C:\\Install\\\" -LocalToGuest -GuestUser USER -GuestPassword PASS -force Скопировать файл с хоста на гостевую ОС виртуальной машины vm-01 с принудительным выполнением\nGet-VM -name vm-01 | Export-VApp -Destination C:\\Install -Format OVF экспортировать виртуальную машину vm-01 в шаблон OVF (.ovf, .vmdk, .mf) \nGet-VM -name vm-01 | Export-VApp -Destination C:\\Install -Format OVA экспортировать виртуальную машину vm-01 в шаблон OVA\nGet-VMHostNetworkAdapter | select VMHost,Name,Mac,IP,@{Label=\"Port Group\"; Expression={$_.ExtensionData.Portgroup}} | ft получить информацию о сетевых адаптерах хостов виртуальных машин, включая хост, имя, MAC-адрес, IP-адрес и портовую группу \nGet-VM | Get-NetworkAdapter | select Parent,Name,Id,Type,MacAddress,ConnectionState,WakeOnLanEnabled | ft получить информацию о сетевых адаптерах виртуальных машин, включая родительскую ВМ, имя, идентификатор, тип, MAC-адрес, состояние подключения и поддержку Wake-on-LAN\nGet-Command –Module *vmware* -name *event* \nGet-VIEvent -MaxSamples 1000 | where {($_.FullFormattedMessage -match \"power\")} | select username,CreatedTime,FullFormattedMessage получить последние 1000 событий, связанных с питанием, включая имя пользователя, время создания и полное сообщение \nGet-logtype | select Key,SourceEntityId,Filename,Creator,Info получить информацию о типах логов \n$(Get-Log vpxd:vpxd.log).Entries | select -Last 50 получить последние 50 записей из лога vpxd\nGet-Command –Module *vmware* -name *syslog* \nSet-VMHostSysLogServer -VMHost esxi-05 -SysLogServer \"tcp://192.168.3.100\" -SysLogServerPort 3515 установить сервер syslog сервер для хранения системных логов для хоста esxi-05 \nGet-VMHostSysLogServer -VMHost esxi-05\n\nHyper-V\nInstall-WindowsFeature -Name Hyper-V -IncludeManagementTools -Restart установить роль на Windows Server \nEnable-WindowsOptionalFeature -Online -FeatureName Microsoft-Hyper-V –All установить роль на Windows Desktop \nGet-Command -Module hyper-v \nGet-VMHost\n\nGet-NetNatStaticMapping отобразить пробросы (NAT) \nGet-NetNat список сетей \nRemove-NetNatStaticMapping -StaticMappingID 0 удалить проброс \nRemove-NetNat -Name LocalNat удалить сеть\nNew-VMSwitch -Name Local -AllowManagementOS $True -NetAdapterName \"Ethernet 4\" -SwitchType External создать вшений (External) виртуальный коммутатор\n\nNew-VM @VM создать виртуальную машину с параметрами\nSet-VMDvdDrive -VMName $VMName -Path \"C:\\Users\\Lifailon\\Documents\\WS-2016.iso\" примонтировать образ \nNew-VHD -Path \"D:\\VM\\$VMName\\disk_d.vhdx\" -SizeBytes 10GB создать VHDX диск \nAdd-VMHardDiskDrive -VMName $VMName -Path \"D:\\VM\\$VMName\\disk_d.vhdx\" примонтировать диск \nGet-VM –VMname $VMName | Set-VM –AutomaticStartAction Start автозапуск \nGet-VM -Name $VMName | Set-VMMemory -StartupBytes 8Gb назначить стартовый размер оперативной памяти при запуске \nSet-VMProcessor $VMName -Count 2 количество виртуальных процессоров (vCPU: ядер/потоков) \nSet-VMProcessor $VMName -Count 2 -Maximum 4 -Reserve 50 -RelativeWeight 200 указать максимальное количество выделяемых процессоров, резервируется 50% ресурсов процессора хоста и установить относительный вес 200 для приоритизации распределения ресурсов процессора относительно других виртуальных машин \nGet-VM -Name $VMName | Checkpoint-VM -SnapshotName \"Snapshot-1\" создать снапшот \nRestore-VMCheckpoint -Name \"Snapshot-1\" -VMName $VMName -Confirm:$false восстановление из снапшота \nGet-VM | Select -ExpandProperty NetworkAdapters | Select VMName,IPAddresses,Status получить IP адрес всех ВМ\n\nVMConnect via RDCMan\nvmconnect.exe localhost $VMHost подключиться к виртуальной машине через VMConnect (используется в диспетчере Hyper-V) \nGet-NetTCPConnection -State Established,Listen | Where-Object LocalPort -Match 2179 найти порт слушателя  \nGet-Process -Id (Get-NetTCPConnection -State Established,Listen | Where-Object LocalPort -Match 2179).OwningProcess найти процесс по ID (vmms/VMConnect) \nNew-NetFirewallRule -Name \"Hyper-V\" -DisplayName \"Hyper-V\" -Group \"Hyper-V\" -Direction Inbound -Protocol TCP -LocalPort 2179 -Action Allow -Profile Public открыть порт в локальном Firewall \nGet-LocalGroupMember -Group \"Администраторы Hyper-V\" \nGet-LocalGroupMember -Group \"Hyper-V Administrators\" \nAdd-LocalGroupMember -Group \"Администраторы Hyper-V\" -Member \"lifailon\" добавить пользователя в группу администраторов (для возможности подключения) \nGet-VM * | Select-Object Name,Id добавить id в RDCMan для подключения \nGrant-VMConnectAccess -ComputerName plex-01 -VMName hv-devops-01 -UserName lifailon дать доступ на подключение не администратору \nGet-VMConnectAccess \nRevoke-VMConnectAccess -VMName hv-devops-01 -UserName lifailon забрать доступ\nError: Unknown disconnection reason 3848 - добавить ключи реестра на стороне клиента\n\n\nExchange/EMShell\n$srv_cas = \"exchange-cas\" \n$session_exchange = New-PSSession -ConfigurationName Microsoft.Exchange -ConnectionUri http://$srv_cas/PowerShell/ -Credential $Cred -Authentication Kerberos \nGet-PSSession \nImport-PSSession $session_exchange -DisableNameChecking импортировать в текущую сессию\nGet-ExchangeServer | select name,serverrole,admindisplayversion,Edition,OriginatingServer,WhenCreated,WhenChanged,DataPath | ft список всех серверов\nGet-ImapSettings настройки IMAP \nGet-ExchangeCertificate список сертификатов \nGet-ExchangeCertificate -Thumbprint \"5CEC8544D4743BC279E5FEA1679F79F5BD0C2B3A\" | Enable-ExchangeCertificate -Services  IMAP, POP, IIS, SMTP \niisreset \nGet-ClientAccessService | fl identity, *uri* настройки службы автообнаружения в Exchange 2016 \nGet-ClientAccessService -Identity $srv | Set-ClientAccessService -AutoDiscoverServiceInternalUri https://mail.domain.ru/Autodiscover/Autodiscover.xml изменить на внешний адрес \nGet-OutlookAnywhere OA позволяет клиентам Outlook подключаться к своим почтовым ящикам за пределами локальной сети (без использования VPN) \nGet-WebServicesVirtualDirectory \nGet-OwaVirtualDirectory \nGet-ActiveSyncVirtualDirectory \nGet-OabVirtualDirectory виртуальная директория автономной адресной книги \nGet-OabVirtualDirectory -Server $srv | Set-OabVirtualDirectory -InternalUrl \"https://mail.domain.ru/OAB\" -ExternalUrl \"https://mail.domain.ru/OAB\"\n\nRoles\nMS (Mailbox) - сервер с БД почтовых ящиков и общих папок, отвечает только за их размещение и не выполняет маршрутизацию никаких сообщений. \nCAS (Client Access Server) - обработка клиентских подключений к почтовым ящикам, которые создаются клиентами Outlook Web Access (HTTP для Outlook Web App), Outlook Anywhere, ActiveSync (для мобильных устройств), интернет протоколы POP3 и IMAP4, MAPI для клиентов Microsoft Outlook. \nHub Transort - ответвечает за маршрутизацию сообщений интернета и инфраструктурой Exchange, а также между серверами Exchange. Сообщения всегда маршрутизируются с помощью роли транспортного сервера-концентратора, даже если почтовые ящики источника и назначения находятся в одной базе данных почтовых ящиков. \nRelay - роль пограничного транспортного сервера (шлюз SMTP в периметре сети).\nSCP (Service Connection Point) - запись прописывается в AD, при создание сервера CAS. Outlook запрашивает SCP, выбирает те, которые находятся в одном сайте с ним и по параметру WhenCreated – по дате создания, выбирая самый старый. \nAutodiscover. Outlook выбирает в качестве сервера Client Access тот, который прописан в атрибуте RPCClientAccessServer базы данных пользователя. Сведения о базе данных и сервере mailbox, на котором она лежит, берутся из AD.\n\nMessageTrackingLog\nGet-MessageTrackingLog -ResultSize Unlimited | select Timestamp,Sender,Recipients,RecipientCount,MessageSubject,Source,EventID,ClientHostname,ServerHostname,ConnectorId, @{Name=\"MessageSize\"; Expression={[string]([int]($_.TotalBytes / 1024))+\" KB\"}},@{Name=\"MessageLatency\"; Expression={$_.MessageLatency -replace \"\\.\\d+$\"}} \nGet-MessageTrackingLog -Start (Get-Date).AddHours(-24) -ResultSize Unlimited | where {[string]$_.recipients -like \"*@yandex.ru\"} вывести сообщения за последние 24 часа, где получателем был указанный домен \n-Start “04/01/2023 09:00:00” -End “04/01/2023 18:00:00” - поиск по указанному промежутку времени \n-MessageSubject “Тест” - поиск по теме письма \n-Recipients “support4@domain.ru” - поиск по получателю \n-Sender - поиск по отправителю \n-EventID – поиск по коду события сервера (RECEIVE, SEND, FAIL, DSN, DELIVER, BADMAIL, RESOLVE, EXPAND, REDIRECT, TRANSFER, SUBMIT, POISONMESSAGE, DEFER) \n-Server – поиск на определенном транспортном сервере \n-messageID – трекинг письма по его ID\n\nMailbox\nGet-Mailbox -Database \"it2\" список почтовых серверов в базе данных \nGet-Mailbox -resultsize unlimited | ? Emailaddresses -like \"support4\" | format-list name,emailaddresses,database,servername какую БД, сервер и smtp-адреса использует почтовый ящик \nGet-Mailbox -Database $db_name -Archive отобразить архивные почтовые ящики\nGet-MailboxFolderStatistics -Identity \"support4\" -FolderScope All | select Name,ItemsInFolder,FolderSize отобразить кол-во писем и размер в каждой папке \nGet-MailboxStatistics \"support4\" | select DisplayName,LastLoggedOnUserAccount,LastLogonTime,LastLogoffTime,ItemCount,TotalItemSize,DeletedItemCount,TotalDeletedItemSize,Database,ServerName общее кол-во писем, их размер, время последнего входа и выхода, имя сервера и БД \nGet-Mailbox -Server s2 | Get-MailboxStatistics | where {$_.Lastlogontime -lt (get-date).AddDays(-30)} | Sort Lastlogontime -desc | ft displayname,Lastlogontime,totalitemsize ящики, которые не использовались 30 и более дней\nEnable-Mailbox -Identity support9 -Database test_base создать почтовый ящик для существующего пользователя в AD \nNew-Mailbox -Name $login -UserPrincipalName \"$login@$domain\" -Database $select_db -OrganizationalUnit $path -Password (ConvertTo-SecureString -String \"$password\" -AsPlainText -Force) создать новый почтовый ящик без привязки к пользователю AD \nGet-MailboxDatabase -Database $db_name | Remove-MailboxDatabase удалить БД\nSet-MailBox \"support4\" -PrimarySmtpAddress support24@domain.ru -EmailAddressPolicyEnabled $false добавить и изменить основной SMTP-адрес электронной почты для пользователя \nSet-Mailbox -Identity \"support4\" -DeliverToMailboxAndForward $true -ForwardingSMTPAddress \"username@outlook.com\" включить переадресацию почты (электронная почта попадает в почтовый ящик пользователя support4 и одновременно пересылается по адресу username@outlook.com)\n\nMoveRequest\nGet-Mailbox -Database $db_in | New-MoveRequest -TargetDatabase $db_out переместить все почтовые ящики из одной БД в другую \nNew-MoveRequest -Identity $db_in -TargetDatabase $db_out переместить один почтовый ящик \nGet-MoveRequest | Suspend-MoveRequest остановить запросы перемещения \nGet-MoveRequest | Remove-MoveRequest удалить запросы на перемещение \nGet-MoveRequest | Get-MoveRequestStatistics статус перемещения\nStatus: \nCleanup - нужно подождать \nQueued - в очереди \nInProgress - в процессе \nPercent Complete - процент выполнения \nCompletionInProgress - завершение процесса \nCompleted - завершено\nRemove-MoveRequest -Identity $db_name завершить процесс перемещения (убрать статус перемещения с почтового ящика и очистить список перемещений) \nGet-MailboxDatabase | Select Name, MailboxRetention после перемещения ящиков, размер базы не изменится, полное удаление из базы произойдет, как пройдет количество дней, выставленное в параметре MailboxRetention \nSet-MailboxDatabase -MailboxRetention '0.00:00:00' -Identity $db_name изменить значение\n\nArchive\nEnable-Mailbox -Identity $name -Archive включить архив для пользователя \nGet-Mailbox $name | New-MoveReques –ArchiveOnly –ArchiveTargetDatabase DBArch переместить архивный почтовый ящик в другую БД \nGet-Mailbox $name | fl Name,Database,ArchiveDatabase место расположения БД пользователя и БД его архива \nDisable-Mailbox -Identity $name -Archive отключить архив \nConnect-Mailbox -Identity \"8734c04e-981e-4ccf-a547-1c1ac7ebf3e2\" -Archive -User $name -Database it2 подключение архива пользователя к указанному почтовому ящику \nGet-Mailbox $name | Set-Mailbox -ArchiveQuota 20GB -ArchiveWarningQuota 19GB настроить квоты хранения архива\n\nQuota\nGet-Mailbox -Identity $mailbox | fl IssueWarningQuota, ProhibitSendQuota, ProhibitSendReceiveQuota, UseDatabaseQuotaDefaults отобразить квоты почтового ящика \nIssueWarningQuota — квота, при достижении которой Exchange отправит уведомление \nProhibitSendQuota — при достижении будет запрещена отправка \nProhibitSendReceiveQuota — при достижении будет запрещена отправка и получение \nUseDatabaseQuotaDefaults — используется ли квота БД или false - индвидиуальные \nSet-Mailbox -Identity $mailbox -UseDatabaseQuotaDefaults $false -IssueWarningQuota \"3 GB\" -ProhibitSendQuota \"4 GB\" -ProhibitSendReceiveQuota \"5 GB\" задать квоту для пользователя\nGet-MailboxDatabase $db_name | fl Name, *Quota отобразить квоты наложенные на БД \nSet-MailboxDatabase $db -ProhibitSendReceiveQuota \"5 GB\" -ProhibitSendQuota \"4 GB\" -IssueWarningQuota \"3 GB\" настроить квоты на БД\n\nMailboxDatabase\nGet-MailboxDatabase -Status | select ServerName,Name,DatabaseSize список и размер всех БД на всех MX-серверах \nNew-MailboxDatabase -Name it_2022 -EdbFilePath E:\\Bases\\it_2022\\it_2022.edb -LogFolderPath G:\\Logs\\it_2022 -OfflineAddressBook \"Default Offline Address List\" -server exch-mx-01 создать БД \nRestart-Service MSExchangeIS \nGet-Service | Where {$_ -match \"exchange\"} | Restart-Service \nGet-MailboxDatabase -Server exch-01 список баз данных на MX-сервере \nNew-MoveRequest -Identity \"support4\" -TargetDatabase it_2022 переместить почтовый ящик в новую БД \nMove-Databasepath $db_name –EdbFilepath \"F:\\DB\\$db_name\\$db_name.edb\" –LogFolderpath \"E:\\DB\\$db_name\\logs\\\" переместить БД и транзакционные логи на другой диск \nSet-MailboxDatabase -CircularLoggingEnabled $true -Identity $db_name включить циклическое ведение журнала (Circular Logging), где последовательно пишутся 4 файла логов по 5 МБ, после чего первый лог-файл перезаписывается \nSet-MailboxDatabase -CircularLoggingEnabled $false -Identity $db_name отключить циклическое ведение журнала \nGet-MailboxDatabase -Server \"exch-mx-01\" -Status | select EdbFilePath,LogFolderPath,LogFilePrefix путь к БД, логам, имя текущего актуального лог-файла\n\nMailboxRepairRequest\nNew-MailboxRepairRequest -Database it2 -CorruptionType ProvisionedFolder, SearchFolder, AggregateCounts, Folderview запустить последовательный тест (в конкретный момент времени не доступен один почтовый ящик) и исправление ошибок на прикладном уровне \nGet-MailboxRepairRequest -Database it2 прогресс выполнения \nПозволяет исправить: \nProvisionedFolder – нарушения логической структуры папок \nSearchFolder – ошибки в папках поиска \nAggregateCounts – проверка и исправление информации о количестве элементов в папках и их размере \nFolderView – неверное содержимое, отображаемое представлениями папок\n\neseutil\nПри отправке/получении любого письма Exchange сначала вносит информацию в транзакционный лог, и только потом сохраняет элемент непосредственно в базу данных. Размер одного лог файла - 1 Мб. Есть три способа урезания логов: DAG, Backup на базе Volume Shadow Copy, Circular Logging.\nРучное удаление журналов транзакций: \ncd E:\\MS_Exchange_2010\\MailBox\\Reg_v1_MailBoxes\\ перейти в каталог с логами \nls E*.chk узнать имя файла, в котором находится информация из контрольной точки фиксации журналов \neseutil /mk .\\E18.chk узнать последний файл журнала, действия из которого были занесены в БД Exchange \nCheckpoint: (0x561299,8,16) 561299 имя файла, который был последним зафиксирован (его информация уже в базе данных) \nНаходим в проводнике файл E0500561299.txt, можно удалять все файлы журналов, которые старше найденного файла\nВосстановление БД (если две копии БД с ошибкой): \nGet-MailboxDatabaseCopyStatus -Identity db_name\\* | Format-List Name,Status,ContentIndexState \nStatus            : FailedAndSuspended \nContentIndexState : Failed \nStatus            : Dismounted \nContentIndexState : Failed\nGet-MailboxDatabase -Server exch-mx-01 -Status | fl Name,EdbFilePath,LogFolderPath проверить расположение базы и транзакционных логов \nLogFolderPath - директория логов \nE18 - имя транкзакционного лога (из него читаются остальные логи) \ndismount-Database db_name отмантировать БД \neseutil /mh D:\\MS_Exchange_2010\\Mailbox\\db_name\\db_name.edb проверить базу \nState: Dirty Shutdown - несогласованное состояние, означает, что часть транзакций не перенесена в базу, например, после того, как была осуществлена аварийная перезагрузка сервера. \neseutil /ml E:\\MS_Exchange_2010\\MailBox\\db_name\\E18 проверка целостности транзакционных логи, если есть логи транзакций и они не испорчены, то можно восстановить из них, из файла E18 считываются все логи, должен быть статус - ОК\nSoft Recovery (мягкое восстановление) - необходимо перевести базу в состояние корректного отключения (Clear shutdown) путем записи недостающих файлов журналов транзакций в БД. \neseutil /R E18 /l E:\\MS_Exchange_2010\\MailBox\\db_name\\ /d D:\\MS_Exchange_2010\\Mailbox\\db_name\\db_name.edb \neseutil /R E18 /a /i /l E:\\MS_Exchange_2010\\MailBox\\db_name\\ /d D:\\MS_Exchange_2010\\Mailbox\\db_name\\db_name.edb если с логами что-то не так, можно попробовать восстановить базу игнорируя ошибку в логах \neseutil /mk D:\\MS_Exchange_2010\\Mailbox\\db_name\\db_name.edb cостоянии файла контрольных точек \neseutil /g D:\\MS_Exchange_2010\\Mailbox\\db_name\\db_name.edb проверка целостности БД \neseutil /k D:\\MS_Exchange_2010\\Mailbox\\db_name\\db_name.edb проверка контрольных сумм базы (CRC)\nHard Recovery - если логи содержат ошибки и база не восстанавливается, то восстанавливаем базу без логов. \neseutil /p D:\\MS_Exchange_2010\\Mailbox\\db_name\\db_name.edb \n/p - удалит поврежденные страницы, эта информация будет удалена из БД и восстановит целостность \nesetuil /d D:\\MS_Exchange_2010\\Mailbox\\db_name\\db_name.edb выполнить дефрагментацию (если был потерян большой объем данных, то может сильно снизиться производительность) \nПосле выполнения команд необходимо вручную удалить все файлы с расширением log в папке MDBDATA, перед попыткой смонтировать базу данных. \nisinteg -s \"db_name.edb\" -test alltests проверьте целостность базы данных \nisinteg -s \"server_name\" -fix -test -alltests если проверка будет провалена. Выполнять команду до тех пор, пока у всех ошибок не станет статус 0 или статус не перестанет меняться, иногда необходимо 3 прохода для достижения результата. \neseutil /mh D:\\MS_Exchange_2010\\Mailbox\\db_name\\db_name.edb | Select-String -Pattern \"State:\",\"Log Required:\" проверить статус \nState: Clear shutdown - успешный статус \nLog Required требуются ли файлы журналов, необходимые базе, чтобы перейти в согласованное состояние. Если база размонтирована корректно, то это значение будет равняться 0. \nmount-Database -force db_name примонтировать БД \nGet-MailboxDatabase –Status db_name | fl Mounted статус БД \nNew-MailboxRepairRequest -Database db_name -CorruptionType SearchFolder,AggregateCounts,ProvisionedFolder,FolderView восстановление логической целостности данных \nПосле этого восстановить Index. \nЕсли индексы не восстанавливаются, но БД монтируется, то перенести почтовые ящики в новую БД.\nВосстановление БД из Backup:\n1-й вариант:\n\nОтмантировать текущую БД и удалить или переименовать директорию с файлами текущей БД.\nВосстановить в ту же директорию из Backup базу с логами.\nЗапустить мягкое восстановление БД (Soft Recovery).\nПримониторвать.\n\n2-й вариант:\n\nОтмантировать и удалить текущую БД.\nВосстановить БД с логами из Backup в любое место.\nЗапустить мягкое восстановление БД (Soft Recovery).\nСоздать новую БД.\nСоздать Recovery Database и смонтировать в нее восстановленную из бэкапа БД, скопировать из неё почтовые ящики в новую БД и переключить на них пользователей.\nЕсли использовать Dial Tone Recovery, то так же перенести из временной БД промежуточные данные почтовых ящиков.\n\n3-й вариант:\n\nВосстановить целостность Soft Repair или Hard Recovery.\nСоздать новую БД. Указывать в свойствах: «база может быть перезаписана при восстановлении».\nЕсли база была только что оздана и еще не была подмонтирована, то эта папка будет пуста, туда перемещаем базу из Backup, которая была обработана ESEUTIL вместе со всеми файлами. Указать имя .edb такое же, которое было при создании новой базы.\nМонтируем базу.\nПеренацеливаем ящики со старой (Mailbox_DB_02), неисправной базы, на новую базу (Mailbox_DB_02_02):\nGet-Mailbox -Database Mailbox_DB_02 | where {$_.ObjectClass -NotMatch '(SystemAttendantMailbox|ExOleDbSystemMailbox)'} | Set-Mailbox -Database Mailbox_DB_02_02\nВосстановление логической целостности данных:\nNew-MailboxRepairRequest -Database \"Mailbox_DB_02_02\" -CorruptionType ProvisionedFolder, SearchFolder, AggregateCounts, Folderview\n\n\nDial Tone Recovery\nGet-Mailbox -Database \"MailboxDB\" | Set-Mailbox -Database \"TempDB\" перенацелить ящики с одной БД (нерабочей) на другую (пустую) \nGet-Mailbox -Database TempDB отобразить почтовые ящики в БД TempDB \nRestart-Service MSExchangeIS перезапустить службу Mailbox Information Store (банка данных), иначе пользователи будут по-прежнему пытаться подключиться к старой БД \niisreset \nGet-Mailbox -Database \"TempDB\" | Set-Mailbox -Database \"MailboxDB\" после восстановления старой БД, нужно переключить пользователей с временной БД обратно \nПосле этого сделать слияние с временной БД с помощью Recovery.\n\nRecovery database (RDB)\nNew-MailboxDatabase –Recovery –Name RecoveryDB –Server $exch_mx –EdbFilePath \"D:\\TempDB\\TempDB.edb\" -LogFolderPath \"D:\\TempDB\" для переноса новых писем из временной БД в основную необходим только сам файл TempDB.edb со статусом Clean Shutdown, из нее необходимо создать служебную БД (ключ -Recovery) \nMount-Database \"D:\\TempDB\\TempDB.edb\" примонтировать БД \nGet-MailboxStatistics -Database RecoveryDB \nNew-MailboxRestoreRequest –SourceDatabase RecoveryDB –SourceStoreMailbox support –TargetMailbox support скопировать данные почтового ящика с DisplayName: support из RecoveryDB в почтовый ящик с псевдонимом support существующей базы. По умолчанию ищет в почтовой базе совпадающие LegacyExchangeDN либо проверяет совпадение адреса X500, если нужно восстановить данные в другой ящик, нужно указывать ключ -AllowLegacyDNMisMatch \nNew-MailboxRestoreRequest –SourceDatabase RecoveryDB –SourceStoreMailbox support –TargetMailbox support –TargetRootFolder \"Restore\" скопировать письма в отдельную папку в ящике назначения (создается автоматически), возможно восстановить содержимое конкретной папки -IncludeFolders “#Inbox#” \nGet-MailboxRestoreRequest | Get-MailboxRestoreRequestStatistics статус запроса восстановления \nGet-MailboxRestoreRequestStatistics -Identity support \nGet-MailboxRestoreRequest -Status Completed | Remove-MailboxRestoreRequest удалить все успешные запросы\n\nTransport\nGet-TransportServer $srv_cas | select MaxConcurrentMailboxDeliveries,MaxConcurrentMailboxSubmissions,MaxConnectionRatePerMinute,MaxOutboundConnections,MaxPerDomainOutboundConnections,PickupDirectoryMaxMessagesPerMinute настройки пропускной способности транспортного сервера \nMaxConcurrentMailboxDeliveries — максимальное количество одновременных потоков, которое может открыть сервер для отправки писем. \nMaxConcurrentMailboxSubmissions — максимальное количество одновременных потоков, которое может открыть сервер для получения писем. \nMaxConnectionRatePerMinute — максимальное возможная скорость открытия входящих соединений в минуту. \nMaxOutboundConnections — максимальное возможное количество соединений, которое может открыть Exchange для отправки. \nMaxPerDomainOutboundConnections — максимальное возможное количество исходящих соединений, которое может открыть Exchange для одного удаленного домена. \nPickupDirectoryMaxMessagesPerMinute — скорость внутренней обработки сообщений в минуту (распределение писем по папкам). \nSet-TransportServer exchange-cas -MaxConcurrentMailboxDeliveries 21 -MaxConcurrentMailboxSubmissions 21 -MaxConnectionRatePerMinute 1201 -MaxOutboundConnections 1001 -MaxPerDomainOutboundConnections 21 -PickupDirectoryMaxMessagesPerMinute 101 изменить значения\nGet-TransportConfig | select MaxSendSize, MaxReceiveSize ограничение размера сообщения на уровне траспорта (наименьший приоритет, после коннектора и почтового ящика). \nNew-TransportRule -Name AttachmentLimit -AttachmentSizeOver 15MB -RejectMessageReasonText \"Sorry, messages with attachments over 15 MB are not accepted\" создать транспортное правило для проверки размера вложения\n\nConnector\nGet-ReceiveConnector | select Name,MaxMessageSize,RemoteIPRanges,WhenChanged ограничения размера сообщения на уровне коннектора (приоритет ниже, чем у почтового ящика) \nSet-ReceiveConnector ((Get-ReceiveConnector).Identity)[-1] -MaxMessageSize 30Mb изменить размер у последнего коннектора в списке (приоритет выше, чем у траспорта) \nGet-Mailbox \"support4\" | select MaxSendSize, MaxReceiveSize наивысший приоритет \nSet-Mailbox \"support4\" -MaxSendSize 30MB -MaxReceiveSize 30MB изменить размер\nSet-SendConnector -Identity \"ConnectorName\" -Port 26 изменить порт коннектора отправки \nGet-SendConnector \"proxmox\" | select port\nGet-ReceiveConnector | select Name,MaxRecipientsPerMessage по умолчанию Exchange принимает ограниченное количество адресатов в одном письме (200) \nSet-ReceiveConnector ((Get-ReceiveConnector).Identity)[-1] -MaxRecipientsPerMessage 50 изменить значение \nSet-ReceiveConnector ((Get-ReceiveConnector).Identity)[-1] -MessageRateLimit 1000 задать лимит обработки сообщений в минуту для коннектора\nGet-OfflineAddressbook | Update-OfflineAddressbook обновить OAB \nGet-ClientAccessServer | Update-FileDistributionService\n\nPST\nNew-MailboxExportRequest -Mailbox $name -filepath \"\\\\$srv\\pst\\$name.PST\" # -ContentFilter {(Received -lt \"01/01/2021\")} -Priority Highest/Lower # -IsArchive выполнить экспорт из архива пользователя \nNew-MailboxExportRequest -Mailbox $name -IncludeFolders \"#Inbox#\" -FilePath \"\\\\$srv\\pst\\$name.PST\" только папку входящие \nNew-MailboxImportRequest -Mailbox $name \"\\\\$srv\\pst\\$name.PST\" импорт из PST \nGet-MailboxExportRequest статус запросов \nGet-MailboxExportRequest -Status Completed | Remove-MailboxExportRequest удалить успешно завершенные запросы \nRemove-MailboxExportRequest -RequestQueue MBXDB01 -RequestGuid 25e0eaf2-6cc2-4353-b83e-5cb7b72d441f отменить экспорт\n\nDistributionGroup\nGet-DistributionGroup список групп рассылки \nGet-DistributionGroupMember \"!_Офис\" список пользователей в группе \nAdd-DistributionGroupMember -Identity \"!_Офис\" -Member \"$name@$domain\" добавить в группу рассылки \nRemove-DistributionGroupMember -Identity \"!_Офис\" -Member \"$name@$domain\" \nNew-DistributionGroup -Name \"!_Тест\" -Members \"$name@$domain\" создать группу \nSet-DistributionGroup -Identity \"support4\" -HiddenFromAddressListsEnabled $true (или Set-Mailbox) скрыть из списка адресов Exchange\n\nSearch\nSearch-Mailbox -Identity \"support4\" -SearchQuery 'Тема:\"Mikrotik DOWN\"' поиск писем по теме \nSearch-Mailbox -Identity \"support4\" -SearchQuery 'Subject:\"Mikrotik DOWN\"'\nSearch-Mailbox -Identity \"support4\" -SearchQuery 'attachment -like:\"*.rar\"'\nSearch-Mailbox -Identity \"support4\" -SearchQuery \"отправлено: &lt; 01/01/2020\" -DeleteContent -Force удаление писем по дате\nФормат даты в зависимости от региональных настроек сервера: \n20/07/2018 \n07/20/2018 \n20-Jul-2018 \n20/July/2018\n\nAuditLog\nGet-AdminAuditLogConfig настройки аудита \nSet-Mailbox -Identity \"support4\" -AuditOwner HardDelete добавить логирование HardDelete писем \nSet-mailbox -identity \"support4\" -AuditlogAgelimit 120 указать время хранения \nGet-mailbox -identity \"support4\" | Format-list Audit* данные аудита \nSearch-MailboxAuditLog -Identity \"support4\" -LogonTypes Delegate -ShowDetails -Start \"2022-02-22 18:00\" -End \"2022-03-22 18:00\" просмотр логов \nSearch-AdminAuditLog -StartDate \"02/20/2022\" | ft CmdLetName,Caller,RunDate,ObjectModified -Autosize поиск событий истории выполненых команд в журнале аудита Exchange\n\nTest\nTest-ServiceHealth проверить доступность ролей сервера: почтовых ящиков, клиентского доступа, единой системы обмена сообщениями, траспортного сервера \n$mx_srv_list | %{Test-MapiConnectivity -Server $_} проверка подключения MX-серверов к БД \nTest-MAPIConnectivity -Database $db проверка возможности логина в базу \nTest-MAPIConnectivity –Identity $user@$domain проверка возможности логина в почтовый ящик \nTest-ComputerSecureChannel проверка работы службы AD \nTest-MailFlow результат тестового потока почты\n\nQueue\nGet-TransportServer | %{Get-Queue -Server $_.Name} отобразить очереди на всех транспортных серверах \nGet-Queue -Identity EXCHANGE-CAS\\155530 | Format-List подробная информация об очереди \nGet-Queue -Identity EXCHANGE-CAS\\155530 | Get-Message -ResultSize Unlimited | Select FromAddress,Recipients отобразить список отправителей (FromAddress) и список получателей в очереди (Recipients) \nGet-Message -Queue EXCHANGE-CAS\\155530 отобразить индентификатор сообщений в конкретной очереди (сервер\\очередь\\идентификатор письма) \nResume-Message EXCHANGE-CAS\\155530\\444010 повторить отправку письма из очереди \nRetry-Queue -Filter {Status -eq \"Retry\"} принудительно повторить отправку всех сообщений c статусом “Повторить” \nGet-Queue -Identity EXCHANGE-CAS\\155530 | Get-Message -ResultSize unlimited | Remove-Message -WithNDR $False очистить очередь \nGet-transportserver EXCHANGE-CAS | Select MessageExpirationTimeout отобразить время жизни сообщений в очереди (по умолчанию, 2 дня)\nError Exchange 452 4.3.1 Insufficient system resources - окончание свободного места на диске, на котором находятся очереди службы Exchange Hub Transport, за мониторинг отвечает компонент доступных ресурсов Back Pressure, который в том числе отслеживает свободное место на диске \nПорог Medium (90%) — перестать принимать по SMTP почту от внешних отправителей (почта от MAPI клиентов при этом обрабатывается) \nПорог High (99%) — обработка потока почты полностью прекращается \nРешение: очистить, например логи IIS (C:\\inetpub\\logs\\LogFiles\\W3SVC1), увеличить размер диска, отключить мониторинг Back Pressure (плохой вариант) или перенести транспортные очередь на другой диск достаточного объёма.\nGet-Service | ? name -like \"MSExchangeTransport\" | Stop-Service остановить служу очереди \nRename-Item \"C:\\Program Files\\Microsoft\\Exchange Server\\V15\\TransportRoles\\data\\Queue\" \"C:\\Program Files\\Microsoft\\Exchange Server\\V15\\TransportRoles\\data\\Queue_old\" очистить базу очереди \nC:\\Program Files\\Microsoft\\Exchange Server\\V15\\Bin\\EdgeTransport.exe.config конфигурационный файл, который содержит путь к бд с очередью (блок  ключи  и QueueDatabaseLoggingPath) \nДля переноса БД, необходимо переместить существующие файлы базы данных Mail.que и Trn.chk (контрольные точки для отслеживания записи в логах) из исходного местоположения в новое. Переместите существующие файлы журнала транзакций Trn.log, Trntmp.log, Trn nnnn.log , Trnres00001.jrs, Trnres00002.jrs и Temp.edb из старого расположения в новое. tmp.edb — временный файл для проверки схемы самой базы, перености не нужно. \nПосле запуска службы транспорта удалить старую базу данных очереди и файлы журнала транзакций из старого расположения.\n\nDefrag\nGet-MailboxDatabase -Status | ft Name, DatabaseSize, AvailableNewMailboxSpace \nDatabaseSize - текущий размер базы \nAvailableNewMailboxSpace - объём пустых страниц, пространство, которое можно освободить при дефрагментации \n(DatabaseSize — AvailableNewMailboxSpace) x 1,1 - необходимо дополнительно иметь свободного места не менее 110% от текущего размера базы (без учета пустых страниц) \ncd $path \nDismount-Database \"$path\\$db_name\" отмонтировать БД \neseutil /d \"$path\\$db_name.edb\" \nMount-Database \"$path\\$db\" примонтировать БД\n\nDAG\n\nDatabase Availability Group\n\nInstall-WindowsFeature -Name Failover-Clustering -ComputerName EXCH-MX-01 основывается на технологии Windows Server Failover Cluster \nNew-DatabaseAvailabilityGroup -Name dag-01 -WitnessServer fs-05 -WitnessDirectory C:\\witness_exchange1 создать группу с указанием файлового свидетеля для кворума \nQuorum - это процесс голосования, в котором для принятия решения нужно иметь большинство голосов, что бы сделать текущую копию базы данных активной. \nWitnessDirectory — используется для хранения данных файлового ресурса-свидетеля. \nSet-DatabaseAvailabilityGroup dag-01 –DatabaseAvailabilityGroupIPAdress $ip изменить ip-адрес группы \nGet-DatabaseAvailabilityGroup список всех групп \nGet-DatabaseAvailabilityGroup -Identity dag-01 \nAdd-DatabaseAvailabilityGroupServer -Identity dag-01 -MailboxServer EXCH-MX-01 добавить первый сервер (все БД на серверах в DAG должны храниться по одинаковому пути) \nAdd-MailboxDatabaseCopy -Identity db_name -MailboxServer EXCH-MX-04 добавить копию БД \nGet-MailboxDatabaseCopyStatus -Identity db_name\\* | select Name,Status,LastInspectedLogTime статус и время последнего копирования журнала транзакий\nStatus: \nMounted - рабочая база \nSuspended - приостановлено копирование \nHealthy - рабочая пассивная копия \nServiceDown - недоступна (выключен сервер) \nDismounted - отмонтирована \nFailedAndSuspended - ошибка и приостановка копирования \nResynchronizing - процесс синхронизация, где будет постепенно уменьшаться длина очереди \nCopyQueue Length - длина репликационной очереди копирования (0 - значит все изменения из активной базы реплицированы в пассивную копию)\nResume-MailboxDatabaseCopy -Identity db_name\\EXCH-MX-04 возобновить (Resume) или запустить копирование бд на EXCH-MX-04 (из статуса Suspended в Healthy) \nSuspend-MailboxDatabaseCopy -Identity db_name\\EXCH-MX-04 остановить копирование (в статус Suspended) \nUpdate-MailboxDatabaseCopy -Identity db_name\\EXCH-MX-04 -DeleteExistingFiles обновить копию БД (сделать Full Backup) \nSet-MailboxDatabaseCopy -Identity db_name\\EXCH-MX-04 -ActivationPreference 1 изменить приоритет для активации копий БД (какую использовать, 1 – самое высокое значение) \nMove-ActiveMailboxDatabase db_name -ActivateOnServer EXCH-MX-04 -MountDialOverride:None -Confirm:$false включить копию БД в DAG (переключиться на активную копию) \nRemove-MailboxDatabaseCopy -Identity db_name\\EXCH-MX-04 -Confirm:$False удалить копии пассивной базы в DAG-группе (у БД должно быть отключено ведение циклического журнала) \nRemove-DatabaseAvailabilityGroupServer -Identity dag-01 -MailboxServer EXCH-MX-04 -ConfigurationOnly удалить MX сервер из группы DAG \nImport-Module FailoverClusters \nGet-ClusterNode EXCH-MX-04 | Remove-ClusterNode -Force удалить отказавший узел из Windows Failover Cluster\nGet-DatabaseAvailabilityGroup | Get-DatabaseAvailabilityGroupHealth мониторинг\n\nIndex\nGet-MailboxDatabaseCopyStatus * | select name,status,ContentIndexState,ContentIndexErrorMessage,ActiveDatabaseCopy,LatestCopyBackupTime,CopyQueueLength узнать состояние работы индксов БД и текст ошибки, на каком сервере активная копия БД, дата последней копии и текущая очередь \nGet-MailboxDatabaseCopyStatus -Identity $db_name\\* | Format-List Name,ContentIndexState отобразить список всех копий конкретной БД на всех серверах, и статус их индексов, если у второго сервера статус Healthy, можно восстановить из него \nGet-MailboxDatabaseCopyStatus -Identity $db_name\\EXCH-MX-04 | Update-MailboxDatabaseCopy -SourceServer EXCH-MX-01 -CatalogOnly восстановить БД из копии \ncd %PROGRAMFILES%\\Microsoft\\Exchange Server\\V14\\Scripts или v15 для Exchange 2016 \n.\\ResetSearchIndex.ps1 $db_name скрипт восстановления индекса\nGet-MailboxDatabaseCopyStatus * | where {$_.ContentIndexState -eq \"Failed\" -or $_.ContentIndexState -eq \"FailedAndSuspended\"} отобразить у какой БД произошел сбой работы (FailedAndSuspended) или индекса (ContentIndexState)\n\nNAS\n\nTrueNAS\nPowerTrueNas\nInstall-Module TrueNas \nImport-Module TrueNas \n$(Get-Module TrueNas).ExportedCommands \nConnect-TrueNasServer -Server tnas-01 -SkipCertificateCheck \nGet-TrueNasCertificate настройки сертификата \nGet-TrueNasSetting настройки языка, time zone, syslog level и server, https port \nGet-TrueNasUser список пользователей \nGet-TrueNasSystemVersion характеристики (Physical Memory, Model, Cores) и Uptime \nGet-TrueNasSystemAlert snmp для оповещений \nGet-TrueNasSystemNTP список используемых NTP серверов \nGet-TrueNasDisk список разделов физического диска \nGet-TrueNasInterface сетевые интерфейсы \nGet-TrueNasGlobalConfig сетевые настройки \nGet-TrueNasDnsServer настроенные DNS-сервера \nGet-TrueNasIscsiTarget отобразить ID группы инициаторов использующих таргет, используемый portal, authentification и authen-method \nGet-TrueNasIscsiInitiator отобразить группы инициаторов \nGet-TrueNasIscsiPortal слушатель (Listen) и порт \nGet-TrueNasIscsiExtent список ISCSi Target (статус работы, путь) \nGet-TrueNasPool список pool (Id, Path, Status, Healthy) \nGet-TrueNasVolume -Type FILESYSTEM список pool файловых систем \nGet-TrueNasVolume -Type VOLUME список разделов в pool и их размер \nGet-TrueNasService | ft список служб и их статус \nStart-TrueNasService ssh запустить службу \nStop-TrueNasService ssh остановить службу\n\nSynology\npSynology\nNew-SYNOSession аутентификация на Synology Diskstation и запуск нового сеанса API \nClose-SYNOSession выход из сеанса API \nGet-SYNOInfo получить информацию об API DiskStation \nAdd-SYNOFSFAvorite добавить папку в избранное пользователя \nAdd-SYNOFSFile загрузить файл \nClear-SYNOFSBackgroundTask удалить все завершенные фоновые задачи \nClear-SYNOFSFavoriteStatus удалить все избранное с неработающим статусом \nClear-SYNOFSSharingLink удалить все просроченные и неработающие ссылки для обмена \nGet-SYNOFSArchiveCompress получить статус задачи сжатия \nGet-SYNOFSArchiveContent вывести содержимое архива \nGet-SYNOFSArchiveExtract получить статус задачи извлечения \nGet-SYNOFSBackgroundTask список всех фоновых задач, включая копирование \nGet-SYNOFSCopy получить статус операции копирования \nGet-SYNOFSDeleteItem получить статус задачи удаления \nGet-SYNOFSDirSize получить статус задачи расчета размера \nGet-SYNOFSFavorite список избранного пользователя \nGet-SYNOFSFile перечислить файлы в заданной папке \nGet-SYNOFSFileInfo получить информацию о файлах или файле \nGet-SYNOFSInfo получить информацию о файловой станции \nGet-SYNOFSMD5 получить статус вычислительной задачи MD5 \nGet-SYNOFSSearch перечислить совпадающие файлы во временной базе данных поиска \nGet-SYNOFSShare список всех общих папок \nGet-SYNOFSSharingLink список ссылок пользователя на общий доступ к файлам \nGet-SYNOFSSharingLinkInfo получить информацию о ссылке общего доступа по идентификатору ссылки общего доступа \nGet-SYNOFSThumbnail получить миниатюру файла \nGet-SYNOFSVirtualFolder список всех папок точек монтирования заданного типа виртуальной файловой системы \nNew-SYNOFSFolder создать папку \nNew-SYNOFSSharingLink создать одну или несколько ссылок для общего доступа по пути к файл или папку \nRemove-SYNOFSFAvorite удаление избранного из избранного пользователя \nRemove-SYNOFSItem удалить файл или папку \nRemove-SYNOFSSearch удалить временные базы данных поиска \nRemove-SYNOFSSharingLink удалить одну или несколько ссылок общего доступа \nRename-SYNOFSItem переименовываем файл или папку \nSave-SYNOFSFile загрузить файл или папку \nSet-SYNOFSFAvorite редактировать избранное имя \nSet-SYNOFSSharingLink изменить ссылку для общего доступа \nStart-SYNOFSArchiveCompress запустить задание сжатия файла или папки \nStart-SYNOFSArchiveExtract запустить задание распаковки архива \nStart-SYNOFSCopy запустить задание копирования файлов \nStart-SYNOFSDeleteItem запустить задание удаления файлов или папок \nStart-SYNOFSDirSize расчитать размер для одного или нескольких путей к файлам или папкам \nStart-SYNOFSMD5 получить MD5 файла \nStart-SYNOFSSearch поиск файлов по заданным критериям \nStop-SYNOFSArchiveCompress остановить задачу сжатия \nStop-SYNOFSArchiveExtract остановить задачу извлечения \nStop-SYNOFSCopy остановить задачу копирования \nStop-SYNOFSDeleteItem остановить задачу удаления \nStop-SYNOFSDirSize остановить расчет размера \nStop-SYNOFSMD5 остановить вычисление MD5 файла \nStop-SYNOFSSearch остановить задачу поиска \nTest-SYNOFSPermission проверить, имеет ли вошедший в систему пользователь разрешение на запись в данную папку \nUpdate-SYNOFSFAvorite заменить несколько избранных папок в избранном пользователя\n\nVeeam\nVeeamHub (https://github.com/VeeamHub/powershell)\n\nGet-VBRCommand\nSet-ExecutionPolicy AllSigned \nSet-ExecutionPolicy Bypass -Scope Process -Force; [System.Net.ServicePointManager]::SecurityProtocol = [System.Net.ServicePointManager]::SecurityProtocol -bor 3072; iex ((New-Object System.Net.WebClient).DownloadString('https://community.chocolatey.org/install.ps1')) установить choco \nchoco install veeam-backup-and-replication-console установить консоль управления (https://community.chocolatey.org/packages/veeam-backup-and-replication-console) \nGet-Module Veeam.Backup.PowerShell модуль, который устанавливается вместе с клиентской консолью по умолчанию \nGet-Command -Module Veeam.Backup.PowerShell \nGet-Command -Module Get-VBRCommand \nConnect-VBRServer -Server $srv -Credential $cred -Port 9392 \nGet-VBRJob \nGet-VBRCommand *get*backup* \nGet-VBRComputerBackupJob \nGet-VBRBackup \nGet-VBRBackupRepository \nGet-VBRBackupSession \nGet-VBRBackupServerCertificate \nGet-VBRRestorePoint \nGet-VBRViProxy\n\nVeeam-REStat\n\nVeeam-REStat -Server srv-veeam-11 -Port 9419 при первом запуске необходимо заполнить Credential для подключения к экземпляру сервера VBR, которые сохраняются в файл с именем сервера в формате xml с применением шифрования PSCredential для последующего подключения \nVeeam-REStat -Reset сброс учетных данных для подключения к серверу VBR \nVeeam-REStat -Statistic статистика всех заданий с сортировкой по дате (выводит время начала, завершения и статус работы, процент прогресса, результат выполнений и сообщение с причиной в случае ошибки: Warning или Failed) \nVeeam-REStat -Jobs подробная статистика по всем настроенным заданиям резеврного копирования: статус работы (In Active/disabled), результат последнего задания (LastResult), тип аутентификации (Standard/Linux), имя и размер виртуальной машины, тип резервного копирования (например, Incremental), дату и время последнего и следущего выполнения \nVeeam-REStat -ConfigBackup отображает статус состояния работы резервного копирования конфигурации сервера VBR, кол-во точек восстановления, дату и время последней копии \nVeeam-REStat -Repositories статистика по инвентарным данным репозиториев: тип хранилища, путь на сервере до директории хранения, общий (capacityGB), свободный (freeGB) и используемый (usedSpaceGB) размер диска под данные \nVeeam-REStat -Backup список заданий резервного копирования, тип копирования (VM/Directory) и кол-во точек восстановления \nVeeam-REStat -Points история статистики всех точек восстановления с датой создания \nVeeam-REStat -Hosts список физически (в ручную) добавленных хостов в инфраструктуру VBR \nVeeam-REStat -Proxy список серверов с ролью Proxy \nVeeam-REStat -Users список УЗ, добавленных для подключения к серверам \nVeeam-REStat -Service выводит информацию о связанных внутренних службах, подключение к этим службам может потребоваться только для интеграции с VBR\n\nREST API\n$url = \"https://habr.com/ru/rss/users/Lifailon/publications/articles/?fl=ru\" RSS лента публикаций на Habr \nInvoke-RestMethod $url \n$iwr = Invoke-WebRequest -Uri $url \n$iwr | Get-Member \n$iwr.Content \n$iwr.StatusCode -eq 200 \n$iwr.Headers \n$iwr.ParsedHtml | Select lastModified \n$iwr.Links | fl title,innerText,href \n$iwr.Images.src\n\nMethods\nGET - Read \nPOST - Create \nPATCH - Partial update/modify \nPUT - Update/replace \nDELETE - Remove\n\nDownload Image\n\nDownload-Image -url https://losst.pro/\n\nToken\n\n\nGET\n\n\nCookie\nПолучить hash торрент файла на сайте Кинозал\n\n$id = 1656552 \n$cookies = \"uid=...\" получить cookie в браузере на вкладке сеть из загловка запросов после авторизации на сайте \nGet-KinozalTorrentHash $id $cookies\n\nPode\nPowerShell Web framework для создания REST API, Веб-сайтов, TCP и SMTP серверов.\n\nirm http://localhost:8080/api/service -Method Get \nirm http://localhost:8080/api/process -Method Get \nhttp://localhost:8080/api/process-html использовать браузер \nirm http://localhost:8080/api/service -Method Post -Body @{\"ServiceName\" = \"AnyDesk\"}\n\nSelenium\nInvoke-Expression(New-Object Net.WebClient).DownloadString(\"https://raw.githubusercontent.com/Lifailon/Deploy-Selenium/rsa/Deploy-Selenium-Drivers.ps1\") установка всех драйверов и Chromium соответствующий версии для драйвера\n\n\nSelenium modules\n\nGet-GPT \"Исполняй роль калькулятора. Посчитай сумму чисел: 22+33\"\n\nGet-Translation -Provider DeepL -Text \"I translating the text\" \nGet-Translation -Provider DeepL -Text \"Я перевожу текст\" \nGet-Translation -Provider Google -Text \"I translating the text\" \nGet-Translation -Provider Google -Text \"Я перевожу текст\" -Language en\n\nGet-SpeedTest -Provider Libre \nGet-SpeedTest -Provider Open \nGet-SpeedTest -Provider Ookla\n\nIE\n$ie.document.IHTMLDocument3_getElementsByTagName(\"input\")  | select name получить имена всех Input Box \n$ie.document.IHTMLDocument3_getElementsByTagName(\"button\") | select innerText получить имена всех Button \n$ie.Document.documentElement.innerHTML прочитать сырой Web Content (&lt;input name=“login” tabindex=“100” class=“input__control input__input” id=“uniq32005644019429136” spellcheck=“false” placeholder=“Логин”) \n$All_Elements = $ie.document.IHTMLDocument3_getElementsByTagName(\"*\") забрать все элементы \n$Go_Button = $All_Elements | ? innerText -like \"go\" поиск элемента по имени \n$Go_Button | select ie9_tagName получить TagName (SPAN) для быстрого дальнейшего поиска \n$SPAN_Elements = $ie.document.IHTMLDocument3_getElementsByTagName(\"SPAN\")\n\n\nCOM\n$wshell = New-Object -ComObject Wscript.Shell \n$wshell | Get-Member \n$link = $wshell.CreateShortcut(\"$Home\\Desktop\\Yandex.lnk\") создать ярлык \n$link | Get-Member \n$link.TargetPath = \"https://yandex.ru\" куда ссылается (метод TargetPath объекта $link где хранится объект CreateShortcut) \n$link.Save() сохранить\nSet-WinUserLanguageList -LanguageList en-us,ru -Force изменить языковую раскладку клавиатуры\n\nWscript.Shell.SendKeys\n(New-Object -ComObject Wscript.shell).SendKeys([char]173) включить/выключить звук \n$wshell.Exec(\"notepad.exe\") запустить приложение \n$wshell.AppActivate(\"Блокнот\") развернуть запущенное приложение\n$wshell.SendKeys(\"Login\") текст \n$wshell.SendKeys(\"{A 5}\") напечатать букву 5 раз подряд \n$wshell.SendKeys(\"%{TAB}\") ALT+TAB \n$wshell.SendKeys(\"^\") CTRL \n$wshell.SendKeys(\"%\") ALT \n$wshell.SendKeys(\"+\") SHIFT \n$wshell.SendKeys(\"{DOWN}\") вниз \n$wshell.SendKeys(\"{UP}\") вверх \n$wshell.SendKeys(\"{LEFT}\") влево \n$wshell.SendKeys(\"{RIGHT}\") вправо \n$wshell.SendKeys(\"{PGUP}\") PAGE UP \n$wshell.SendKeys(\"{PGDN}\") PAGE DOWN \n$wshell.SendKeys(\"{BACKSPACE}\") BACKSPACE/BKSP/BS \n$wshell.SendKeys(\"{DEL}\") DEL/DELETE \n$wshell.SendKeys(\"{INS}\") INS/INSERT \n$wshell.SendKeys(\"{PRTSC}\") PRINT SCREEN \n$wshell.SendKeys(\"{ENTER}\") \n$wshell.SendKeys(\"{ESC}\") \n$wshell.SendKeys(\"{TAB}\") \n$wshell.SendKeys(\"{END}\") \n$wshell.SendKeys(\"{HOME}\") \n$wshell.SendKeys(\"{BREAK}\") \n$wshell.SendKeys(\"{SCROLLLOCK}\") \n$wshell.SendKeys(\"{CAPSLOCK}\") \n$wshell.SendKeys(\"{NUMLOCK}\") \n$wshell.SendKeys(\"{F1}\") \n$wshell.SendKeys(\"{F12}\") \n$wshell.SendKeys(\"{+}{^}{%}{~}{(}{)}{[}{]}{{}{}}\")\n\nGet-AltTab\n\nWscript.Shell.Popup\n$wshell = New-Object -ComObject Wscript.Shell \n$output = $wshell.Popup(\"Выберите действие?\",0,\"Заголовок\",4) \nif ($output -eq 6) {\"yes\"} elseif ($output -eq 7) {\"no\"} else {\"no good\"}\n\n\nWScript.Network\n$wshell = New-Object -ComObject WScript.Network \n$wshell | Get-Member \n$wshell.UserName \n$wshell.ComputerName \n$wshell.UserDomain\n\nShell.Application\n$wshell = New-Object -ComObject Shell.Application \n$wshell | Get-Member \n$wshell.Explore(\"C:\\\") \n$wshell.Windows() | Get-Member получить доступ к открытым в проводнике или браузере Internet Explorer окон\n$shell = New-Object -Com Shell.Application \n$RecycleBin = $shell.Namespace(10) \n$RecycleBin.Items()\n\nOutlook\n$Outlook = New-Object -ComObject Outlook.Application \n$Outlook | Get-Member \n$Outlook.Version\n\n\nMicrosoft.Update\n(New-Object -com 'Microsoft.Update.AutoUpdate').Settings \n(New-Object -com 'Microsoft.Update.AutoUpdate').Results \n(New-Timespan -Start ((New-Object -com 'Microsoft.Update.AutoUpdate').Results|Select -ExpandProperty LastInstallationSuccessDate) -End (Get-Date)).hours кол-во часов, прошедших с последней даты установки обновления безопасности в Windows.\n\n.NET\n[System.Diagnostics.EventLog] | select Assembly,Module \n$EventLog = [System.Diagnostics.EventLog]::new(\"Application\") \n$EventLog = New-Object -TypeName System.Diagnostics.EventLog -ArgumentList Application,192.168.3.100 \n$EventLog | Get-Member -MemberType Method \n$EventLog.MaximumKilobytes максимальный размер журнала \n$EventLog.Entries просмотреть журнал \n$EventLog.Clear() очистить журнал\nJoin-Path C: Install Test \n[System.IO.Path]::Combine(\"C:\", \"Install\", \"Test\")\n\nMatch\n[System.Math] | Get-Member -Static -MemberType Methods \n[System.Math]::Max(2,7) \n[System.Math]::Min(2,7) \n[System.Math]::Floor(3.9) \n[System.Math]::Truncate(3.9)\n\nGeneratePassword\nAdd-Type -AssemblyName System.Web \n[System.Web.Security.Membership]::GeneratePassword(10,2)\n\nSoundPlayer\n\n\nStatic Class\n[System.Environment] | Get-Member -Static \n[System.Environment]::OSVersion \n[System.Environment]::Version \n[System.Environment]::MachineName \n[System.Environment]::UserName\n[System.Diagnostics.Process] | Get-Member -Static \n[System.Diagnostics.Process]::Start('notepad.exe')\n\nClicker\n\nAdd-Type -TypeDefinition $cSource -ReferencedAssemblies System.Windows.Forms,System.Drawing \n[Clicker]::LeftClickAtPoint(1900,1070)\n\nAudio\n\n[Audio]::Volume = 0.50 \n[Audio]::Mute = $true\n\nNetSessionEnum\nФункцияя (методы)\nОригинальный источник\n\nInvoke-NetSessionEnum localhost\n\nCopyFile\nФункции\nОригинальный источник\n\n\nShowWindowAsync\nФункции\n\n\nGetAsyncKeyState\nFunction\nAdd-Type -AssemblyName System.Windows.Forms \n[int][System.Windows.Forms.Keys]::F1 определить номер [Int] клавиши по ее названию \n65..90 | % {\"{0} = {1}\" -f $_, [System.Windows.Forms.Keys]$_} порядковый номер букв (A..Z)\n\n\nConsole API\nОригинальный источник\n[Console] | Get-Member -Static \n[Console]::BackgroundColor = \"Blue\" \n[Console]::OutputEncoding используемая кодировка в текущей сессии \n[Console]::OutputEncoding = [System.Text.Encoding]::GetEncoding(\"utf-8\") изменить кодировку для отображения кириллицы \n[Console]::outputEncoding = [System.Text.Encoding]::GetEncoding(\"cp866\") для ISE \n[Console]::OutputEncoding = [System.Text.Encoding]::GetEncoding(\"windows-1251\") для ps2exe \nGet-Service | Out-File $home\\Desktop\\Service.txt -Encoding oem &gt; \nGet-Service | Out-File $home\\Desktop\\Service.txt -Append &gt;&gt;\n\n\nDrawing\nAPI\n\n$path = \"$home\\desktop\\powershell_image.bmp\" \nInvoke-Item $path\n\n\nObjectEvent\n\n$Timer.Enabled = $False остановить \n$Timer | Get-Member -MemberType Event отобразить список всех событий объекта \nGet-EventSubscriber список зарегистрированных подписок на события в текущей сессии \nUnregister-Event -SourceIdentifier Timer.Output удаляет регистрацию подписки на событие по имени события (EventName) или все * \n-Forward перенаправляет события из удаленного сеанса (New-PSSession) в локальный сеанс \n-SupportEvent не выводит результат регистрации события на экран (и Get-EventSubscriber и Get-Job)\n\n\nSockets\n\nUDP-Socket\nОригинальный источник\n\nStart-UDPServer -Port 5201\n\nTest-NetUDPConnection\n\nTest-NetUDPConnection -ComputerName 127.0.0.1 -PortServer 5201 \nTest-NetUDPConnection -ComputerName 127.0.0.1 -PortServer 514 -Message \"&lt;30&gt;May 31 00:00:00 HostName multipathd[784]: Test message\"\n\nTCP-Socket\n\nStart-TCPServer -Port 5201 \nTest-NetConnection -ComputerName 127.0.0.1 -Port 5201\n\nWakeOnLan\nBroadcast package consisting of 6 byte filled “0xFF” and then 96 byte where the mac address is repeated 16 times\n\nSend-WOL -Mac \"D8-BB-C1-70-A3-4E\" \nSend-WOL -Mac \"D8-BB-C1-70-A3-4E\" -IP 192.168.3.100\n\nHTTPListener\n\n\nHttpClient\n\n\nCertificate\n\nGet-WebCertificate https://google.com\n\nBase64\n\nUTF8\n$loginPassword = \"login:password\" \n$Base64 = [Convert]::ToBase64String([System.Text.Encoding]::UTF8.GetBytes($loginPassword)) закодировать логин и пароль в строку Base64 \n[System.Text.Encoding]::UTF8.GetString([System.Convert]::FromBase64String($Base64)) преобразовать в байты и обратно декодировать в исходную строку с помощью UTF-8 кодировки\n\nUnicode\n\n\nImage\n\n\nExcel\n\n\nExcel.Application.Open\n\n\nImportExcel\nInstall-Module -Name ImportExcel \n$data | Export-Excel .\\Data.xlsx \n$data = Import-Excel .\\Data.xlsx\n$data = ps \n$Chart = New-ExcelChartDefinition -XRange CPU -YRange WS -Title \"Process\" -NoLegend \n$data | Export-Excel .\\ps.xlsx -AutoNameRange -ExcelChartDefinition $Chart -Show\n\nCSV\nGet-Service | Select Name,DisplayName,Status,StartType | Export-Csv -path \"$home\\Desktop\\Get-Service.csv\" -Append -Encoding Default экспортировать в csv (-Encoding UTF8) \nImport-Csv \"$home\\Desktop\\Get-Service.csv\" -Delimiter \",\" импортировать массив\n\n$systeminfo = systeminfo /FO csv | ConvertFrom-Csv вывод работы программы в CSV и конвертация в объект \n$systeminfo.\"Полный объем физической памяти\" \n$systeminfo.\"Доступная физическая память\"\n\nConvertFrom-String\n\n\nConvertFrom-StringData\n\n\nXML\n\nGet-Service | Export-Clixml -path $home\\desktop\\test.xml экспортировать объект PowerShell в XML \nImport-Clixml -Path $home\\desktop\\test.xml импортировать объект XML в PowerShell \nConvertTo-Xml (Get-Service)\n\nGet-CredToXML\n\n$Cred = Get-CredToXML \n$Login = $Cred.UserName \n$PasswordText = $Cred.GetNetworkCredential().password получить пароль в текстовом виде\n\nXmlWriter\nExtensible Markup Language\n\n\nCreateElement\n\n\nJSON\n\n\nYAML\n\nPSYaml\nPSYaml - модуль для конвертации данных из и в формат YAML.\n\n\nPowerShell-YAML\nPowerShell-YAML - модуль PowerShell для обертки YamlDotNet для сериализации и десериализации простых объектов PowerShell в формат YAML и обратно.\n\n\nTOML\nInstall-Module -Name PSToml -Scope CurrentUser Устанавливаем модуль для чтения toml (PSToml) \n$toml = Get-Content \"$home\\Documents\\Git\\lifailon.github.io\\hugo.toml\" Читаем содержимое конфигурации Hugo в формате toml \n$json = ConvertFrom-Toml $toml | ConvertTo-Json -Depth 3 Конвертируем TOML в JSON \n$json | Out-File \"$home\\Documents\\Git\\lifailon.github.io\\hugo.json\" Сохраняем конфигурационный файл в формате JSON\n\nMarkdown\n\nPSMarkdown\nPSMarkdown - модуль PowerShell, позволяющий преобразовывать объекты PowerShell в таблицы Markdown и обратно.\n\n\nConvert Markdown to HTML\n\nGet-Content index.md -Raw | ConvertFrom-MarkdownToHtml | Out-File index.html\n\nConvertFrom-MarkdownV2\n\n\nConvertTo-Markdown\n\n\nHTML\n\nConvertFrom-Html\n\n\nConvertTo-Html\nGet-Process | select Name, CPU | ConvertTo-Html -As Table &gt; \"$home\\desktop\\proc-table.html\" вывод в формате List (Format-List) или Table (Format-Table)\n\n\nPSWriteHTML\n\n\nHtmlReport\n\n\nHtmlAgilityPack\nПакет в менеджере пакетов NuGet\n\n$torrents\n\n\nKeePass\n\n\nSQLite\n\n(Get-MySQLiteDB $path).Tables список таблиц в базе \nInvoke-MySQLiteQuery -Path $path -Query \"SELECT name FROM sqlite_master WHERE type='table';\" список таблиц в базе \nInvoke-MySQLiteQuery -Path $path -Query \"DROP TABLE Service;\" удалить таблицу\n\nGet-Service | select  Name,DisplayName,Status | ConvertTo-MySQLiteDB -Path $path -TableName Service -force конвертировать объект в таблицу\nУстановка и передача пароль:\n\n\nMySQL\napt -y install mysql-server mysql-client \nmysql -V \nsystemctl status mysql \nmysqladmin -u root password задать пароль root\nnano /etc/mysql/mysql.conf.d/mysqld.cnf\n\nsystemctl restart mysql \nss -tulnp | grep 3306 \nufw allow 3306/tcp \nnc -zv 192.168.1.253 3306 \ntnc 192.168.1.253 -p 3306\nmysql -u root -p \nSELECT user(), now(), version(); \nquit;\nmysql -u root -p -e 'SHOW TABLES FROM db_aduser;' отобразить список таблиц без подключения к консоли MySQL\nCREATE создать БД, пользователя, таблицу \nALTER  управление столбцами таблице \nDROP удалить БД, пользователя, таблицу \nUSE выбрать БД \nSHOW вывесли список БД, прав доступа пользователя (GRANTS), названия столбцов и их свойства \nGRANT дать доступ пользователю к БД \nREVOKE  удалить доступ пользователя к БД \nUPDATE изменить права доступа, значения с таблице \nFLUSH обновить права доступа \nSELECT отобразить выбранную БД, вывести список пользователей, выборка данных в таблице \nINSERT внести данные \nDELETE удалить данные в (FROM) таблице\n\nDATA TYPE\nVARCHAR(N) строка переменной длины, в формате ASCII, где один символ занимает 1 байт, числом N указывается максимальная возможная длина строки \nNVARCHAR(N) строка переменной длины, в формате Unicode, где один символ занимает 2 байта \nCHAR(N)/nchar(N) строка фиксированной длины, которая всегда дополняется справа пробелами до длины N и в базе данных она занимает ровно N символов \nINT целое число, от -2147483648 до 2147483647, занимает 4 байта \nFLOAT число, в котором может присутствовать десятичная точка (запятая) \nBIT флаг, Да - 1 или Нет - 0 \nDATE формат даты, например 25.05.2023 \nTIME 23:30:55.1234567 \nDATETIME 25.05.2023 23:30:55.1234567\n\nDATABASES\n\n\nUSER\n\n\nTABLE\n\n\nCOLUMN\n\n\nINSERT\n\n\nSELECT\n\n\nWHERE\n\n\nDELETE\n\n\nUPDATE\n\n\nCHECK\n\n\nDUMP\n\n\ninnodb_force_recovery\n\n\nMySQL Connector NET\n\nAdd-ADUser\n\n\nGet-ADUser\n\n\nMSSQL\nwget -qO- https://packages.microsoft.com/keys/microsoft.asc | apt-key add - импортировать GPG-ключ для репозитория \nhttps://packages.microsoft.com/config/ubuntu/ выбрать репозиторий и скопировать URL \nadd-apt-repository \"$(wget -qO- https://packages.microsoft.com/config/ubuntu/20.04/mssql-server-2019.list)\" \napt-get update обновить список пакетов \napt-get install mssql-server \n/opt/mssql/bin/mssql-conf setup скрипт начальной конфигурации (выбрать редакцию, 3 - express и русский язык 9 из 11) \nsystemctl status mssql-server \ncurl https://packages.microsoft.com/keys/microsoft.asc | apt-key add - установить клиент \ncurl https://packages.microsoft.com/config/ubuntu/20.04/prod.list | tee /etc/apt/sources.list.d/msprod.list \napt-get update \napt-get install mssql-tools \necho 'export PATH=\"$PATH:/opt/mssql-tools/bin\"' &gt;&gt; ~/.bashrc добавить в домашний каталог файла bashrc, что бы не писать путь к исполняемому файлу \nexport PATH=\"$PATH:/opt/mssql-tools/bin\" \niptables -I INPUT 1 -p tcp --dport 1433 -j ACCEPT\n\n\nSystem.Data.SqlClient\n\n\nSqlClient INSERT\n\n\nSSMS INSERT\n\n\nT-SQL\n\n\nDDL (Data Definition Language / Язык определения данных). К этому типу относятся команды, которые создают базу данных, таблицы, индексы, хранимые процедуры. \nCREATE создает объекты базы данных (саму базу даных, таблицы, индексы и т.д.) \nALTER изменяет объекты базы данных \nDROP удаляет объекты базы данных \nTRUNCATE удаляет все данные из таблиц\n\n\nDML (Data Manipulation Language / Язык манипуляции данными). К этому типу относят команды по выбору, обновлению, добавлению и удалению данных. \nSELECT извлекает данные из БД \nUPDATE обновляет данные \nINSERT добавляет новые данные \nDELETE удаляет данные\n\n\nDCL (Data Control Language / Язык управления доступа к данным). К этому типу относят команды, которые управляют правами по доступу к данным. \nGRANT предоставляет права для доступа к данным \nREVOKE отзывает права на доступ к данным\n\n\n\n\nТип резервной копии\n\nFull (Полная копия). Когда стартует полное резервирование, записывается Log Sequence Number (LSN - последовательный номер журнала), а так же LSN записывается и при завершении полного резервирования. Этот LSN является механизмом, используемым SQL Server, чтобы знать, в каком порядке выполнялись операторы INSERT, UPDATE или DELETE. При этом наличие записанных LSN начала и окончания, как части полного бэкапа, обеспечивает согласованное с точки зрения транзакций резервное копирование, поскольку при полном резервном копировании учитываются изменения, произошедшие во время резервного копирования. Это обеспечивает обработку таких транзакций в процессе восстановления бэкапа.\nDifferential (дифференциальная/разностная копия). Хранит данных, изменившиеся с момента последней Полной резервной копии. При восстановлении нужно сначала восстановить Полную резервную копию в режиме NORECOVERY, потом можно применить любую из последующих Разностных копий, без предыдущей Полной резервной копии Разностная копия бесполезна. Каждая последующая Разностная копия будет хранить все данные, входящие в предыдущую Разностную резервную копию, сделанную после предыдущей Полной копии.\nIncremental (инкрементальная/копия журналов транзакций). Резервное копирования журнала транзакций копирует все транзакции, которые произошли с момента последнего резервного копирования, а затем урезает журнал транзакций для освобождения дискового пространства. Транзакции происходят в определенном порядке (LSN), бэкап журнала поддерживает этот порядок транзакций. Бэкапы журналов транзакций должны восстанавливаться по порядку. Для восстановления базы данных потребуется вся цепочка резервных копий: полная и все последующие инкрементальные журнала транзакций.\n\n\nМодели восстановления\n\nSimple (Простая). Хранится только необходимый для жизни остаток журнала транзакций. Журнал транзакций (лог) автоматически очищается. Создание резервных копий журнала транзакций невозможна, поэтому остается самое ограниченное число опций по восстановлению. Недоступен функционал: Always On, Point-In-Time восстановление, Резервные копии журнала транзакций.\nFull (Полная). Хранится журнал транзакций всех изменений в БД с момента последнего резервного копирования журнала транзакций. Журнал транзакций не будет очищаться до тех пор, пока не будет сделана резервная копия журнала транзакций.\nBulk logged (С неполным протоколированием). Идентична Full, за исключение: SELECT INTO, BULK INSERT и BCP, INSERT INTO SELECT, операции с индексами (CREATE INDEX, ALTER INDEX REBUILD, DROP INDEX)\n\n\nСистемные БД\n\nmaster. Хранятся все данные системного уровня (конфигурация системы, сведенья об учетных записях входа, информация обо всех других базах данных) для экземпляра SQL Server.\ntempdb. Рабочее пространство для временных объектов, таких как глобальные или локальные временные таблицы, временные хранимые процедуры, табличные переменные и курсоры. Пересоздаётся при каждом запуске SQL Server.\nmodel. Используется в качестве шаблона для всех баз данных, создаваемых в экземпляре SQL Server, все содержимое базы данных model, включая параметры базы данных, копируется в создаваемую базу данных. Так как база данных tempdb создается каждый раз при запуске SQL Server, база данных model всегда должна существовать в системе SQL Server.\nmsdb. Используется агентом SQL Server для создания расписания предупреждений (оператор) и выполнение заданий, а также другими компонентами. SQL Server хранит полный журнал резервного копирования и восстановления в базе данных msdb. Для отправки почты оператору используется: USE [msdb].\nresource. Доступная только для чтения база данных, которая содержит все системные объекты, например sys.objects, физически хранятся в базе данных resource, но логически присутствуют в схеме sys каждой базы данных.\n\n\nРегламентные операции\n\nПроверка целостности базы данных\n\nDBCC CHECKDB\n\n\nИндексы. Индексы используются для быстрого поиска данных без необходимости поиска/просмотра всех строк в таблице базы данных при каждом обращении к таблице базы данных. Индекс ускоряет процесс запроса, предоставляя быстрый доступ к строкам данных в таблице, аналогично тому, как указатель в книге помогает вам быстро найти необходимую информацию. Индексы предоставляют путь для быстрого поиска данных на основе значений в этих столбцах. Для каждого индекса обязательно хранится его статистика. MS SQL Server самостоятельно создает и изменяет индексы при работе с базой. С течением времени данные в индексе становятся фрагментированными, т.е. разбросанными по базе данных, что серьезно снижает производительность запросов. Если фрагментация составляет от 5 до 30% (стандартно в задании 15%), то рекомендуется ее устранить с помощью реорганизации, при фрагментации выше 30% (по умолчанию в задаче &gt; 30% фрагментации и число страниц &gt; 1000) необходимо полное перестроение индексов. После перестроения планово используется только реорганизация.\n\n\nРеорганизация (Reorganize) или дефрагментация индекса — это серия небольших локальных перемещений страниц так, чтобы индекс не был фрагментирован. После реорганизации статистика не обновляется. Во время выполнения почти все данные доступны, пользователи смогут работать.\n\n\nsp_msforeachtable N'DBCC INDEXDEFRAG (&lt;имя базы данных&gt;, ''?'')'\n\nПерестроение (Rebuild) индексов (или задача в мастере планов обслуживания: Восстановить индекс) запускает процесс полного построения индексов. В версии MS SQL Server Standard происходит отключение всех клиентов от базы на время выполнения операции. После перестроения обязательно обновляется статистика.\n\nsp_msforeachtable N'DBCC DBREINDEX (''?'')'\n\nОбновление статистики. Статистика — небольшая таблица (обычно до 200 строк), в которой хранится обобщенная информация о том, какие значения и как часто встречаются в таблице. На основании статистики сервер принимает решение, как лучше построить запрос. Когда происходят запросы к БД (например, SELECT) вы получаете данные, но не описываете то, как эти данные должны быть извлечены. В получении и обработке данных помогает статистика. Во время выполнения процедуры обновления статистики данные не блокируются.\n\nexec sp_msforeachtable N'UPDATE STATISTICS ? WITH FULLSCAN'\n\nОчистка процедурного кэша, выполняется после обновления статистики. Оптимизатор MS SQL Server кэширует планы запросов для их повторного выполнения. Это делается для того, чтобы экономить время, затрачиваемое на компиляцию запроса в том случае, если такой же запрос уже выполнялся и его план известен. После обновия статистики, не будет очищен процедурный кэш, то SQL Server может выбрать старый (неоптимальный) план запроса из кэша вместо того, чтобы построить новый (более оптимальный) план.\n\nDBCC FREEPROCCACHE\n\nInfluxDB\nDownload InfluxDB 1.x Open Source\nInfluxDB Studio 1.x\n\nSSL\nВыпуск самоподписанного сертификата в Linux:\n\nИмпорт сертификата в Windows для OhmGraphite:\n\nИмпорт сертификата в контейнер Grafana для подключения нового источника данных через https:\n\n\nInstall Docker\n\n\nInstall Windows\n\n\nInstall Ubuntu\n\n\nAPI\n\n\nChronograf\n\n\nGrafana\nDownload\ninvoke-RestMethod https://dl.grafana.com/enterprise/release/grafana-enterprise-10.3.1.windows-amd64.msi -OutFile \"$home\\Download\\grafana.msi\"\n\n\nCLI Client\napt install influxdb-client \ninflux \ninflux --host 192.168.3.102 --username admin --password password\n\n\nUSERS\nSHOW USERS отобразить пользователей и их права доступа \nCREATE USER admin WITH PASSWORD 'password' WITH ALL PRIVILEGES создать пользователя \nGRANT ALL PRIVILEGES TO \"admin\" предоставить права доступа \nGRANT READ ON \"database\" TO \"admin\" доступ на чтение для БД или запись (WRITE) \nREVOKE ALL PRIVILEGES FROM \"admin\" отозвать права доступа \nSHOW GRANTS FOR \"admin\" БД и привелегии доступа для указанного пользователя \nSET PASSWORD FOR \"admin\" = 'new_password' изменить пароль \nDROP USER \"admin\" удалить пользователя\n\nDATABASES\nCREATE DATABASE powershell создать БД \nSHOW DATABASES отобразить список БД \nDROP DATABASE powershell удалить БД \nUSE powershell \nSHOW measurements отобразить все таблицы \nINSERT performance,host=console,counter=CPU value=0.88 записать данные в таблицу performance\n\nMEASUREMENT\nSHOW TAG KEYS FROM \"HardwareMonitor\" отобразить все тэги в таблице \nSHOW TAG VALUES FROM \"HardwareMonitor\" WITH KEY = \"HardwareName\" отобразить все значения указанного тэга \nSHOW FIELD KEYS FROM \"HardwareMonitor\" отобразить все Field Tags и их тип данных \nSHOW SERIES FROM \"HardwareMonitor\" отобразить список всех уникальных серий в указанной таблице. Серия - это набор точек данных, которые имеют одинаковые значения для всех тегов, за исключением времени. \nDROP SERIES FROM \"HardwareMonitor\" очистить все данные в таблице \nDROP MEASUREMENT \"HardwareMonitor\" удалить таблицу\n\nSELECT/WHERE\nSELECT * FROM performance отобразить все данные в таблице \nSELECT value FROM performance отфильтровать по столбцу value (только Field Keys) \nSELECT * FROM performance limit 10 отобразить 10 единиц данных \nSELECT * FROM performance WHERE time &gt; now() -2d отобразить данные за последние 2 дня \nSELECT * FROM performance WHERE time &gt; now() +3h -5m данные за последние 5 минут (+3 часа от текущего времени по UTC 0 -5 минут) \nSELECT * FROM performance WHERE counter = 'CPU' выборка по тэгу \nSELECT upload/1000 FROM speedtest WHERE upload/1000 &lt;= 250 выборка по столбцу upload и разделить вывод на 1000, вывести upload меньше 250 \nDELETE FROM performance WHERE time &gt; now() -1h удалить данные за последние 1/4 часа \nDELETE FROM performance WHERE time &lt; now() -24h удалить данные старше 24 часов\n\nREGEX\nSELECT * FROM \"win_pdisk\" WHERE instance =~/.*C:/ and time &gt; now() - 5m и \nSELECT * FROM \"win_pdisk\" WHERE instance =~/.*E:/ or instance =~ /.*F:/ или \nSELECT * FROM \"win_pdisk\" WHERE instance !~ /.*Total/ не равно (исключить) \nSELECT * FROM \"HardwareMonitor\" WHERE time &gt; now() - 5m and HardwareName =~ /Intel/ приблизительно равно \nSELECT * FROM \"HardwareMonitor\" WHERE time &gt; now() - 5m and HardwareName =~ /Intel.+i7/ эквивалент 12th_Gen_Intel_Core_i7-1260P \nSELECT * FROM \"HardwareMonitor\" WHERE time &gt; now() - 5m and HardwareName =~ /^Intel/ начинается на Intel \nSELECT * FROM \"HardwareMonitor\" WHERE time &gt; now() - 5m and HardwareName =~ /00$/ заканчивается на 00\n\nGROUP BY tag_key\nSELECT * FROM \"HardwareMonitor\" WHERE time &gt; now() - 5m and SensorName = 'Temperature' GROUP BY HardwareName создать уникальные группы по тэгу HardwareName \nSELECT * FROM \"HardwareMonitor\" WHERE time &gt; now() - 5m and SensorName = 'Temperature' GROUP BY Host,HardwareName больше групп по двум тэгаам\n\nFunctions(field_key)\nFunctions\nSELECT instance,LAST(Avg._Disk_Read_Queue_Length) FROM \"win_pdisk\" GROUP BY instance отфильтровать вывод по последнему/текущему значению \nSELECT instance,FIRST(Avg._Disk_Read_Queue_Length) FROM \"win_pdisk\" GROUP BY instance отфильтровать вывод по первому значению за весь или указанный отрезок времени \nSELECT instance,MIN(Avg._Disk_Read_Queue_Length) FROM \"win_pdisk\" GROUP BY instance отфильтровать вывод с отображением минимального значения \nSELECT instance,MAX(Avg._Disk_Read_Queue_Length) FROM \"win_pdisk\" GROUP BY instance отфильтровать вывод с отображением максимального значения \nSELECT SUM(Bytes_Received_persec) FROM \"win_net\" GROUP BY instance суммах всех значений \nSELECT COUNT(Bytes_Received_persec) FROM \"win_net\" WHERE Bytes_Received_persec &gt;= 0 GROUP BY instance кол-во данных, где значение выше или равно 0 \nSELECT MEAN(Bytes_Received_persec) FROM \"win_net\" WHERE Bytes_Received_persec &lt; 1000 GROUP BY instance среднее значение данных с показателем от 0 до 1000 (509)\nSELECT *,MAX(Value) FROM \"HardwareMonitor\" WHERE time &gt; now() -1h GROUP BY SensorName,Host создать группы для выявления максимального значения значения стобца Value каждого тэга SensorName и хоста за последний час \nSELECT *,MAX(Value) FROM \"HardwareMonitor\" WHERE time &gt; now() -1h and SensorName = 'CPU_Package' GROUP BY Host масимальное значение CPU_Package за последний час для каждого хоста \nSELECT MEAN(Value) FROM \"HardwareMonitor\" WHERE time &gt; now() -1h and SensorName = 'CPU_Package' GROUP BY Host среднее значение CPU_Package за последний час\n\nPOLICY\nCREATE DATABASE powershell WITH DURATION 48h REPLICATION 1 NAME \"del2d\" создать БД с политикой хранения 2 дня \nCREATE RETENTION POLICY del2h ON powershell DURATION 2h REPLICATION 1 создать новую политику хранения для БД \nCREATE RETENTION POLICY del6h ON powershell DURATION 6h REPLICATION 1 SHARD DURATION 2h указать период хранения 6 часов + 2 часа до очистки (по умолчанию 1ч или больше) \nALTER RETENTION POLICY del6h ON powershell DEFAULT изменить (ALTER) политику хранения для БД на del6h (DEFAULT) \nDROP RETENTION POLICY del2d ON powershell удаление политики хранения приводит к безвозвратному удалению всех измерений (таблиц) и данных, хранящихся в политике хранения \nSHOW RETENTION POLICIES ON PowerShell отобразить действующие политики базы данных PowerShell\n\nInfluxDB-api\n\n\nAPI POST\nВместо таблиц в InfluxDB имеются измерения. Вместо столбцов в ней есть теги и поля.\n\n\nAPI GET\ncurl http://192.168.3.104:8086/query --data-urlencode \"q=SHOW DATABASES\" pwsh7 (ConvertFrom-Json) and bash\n$dbs = irm \"http://192.168.3.104:8086/query?q=SHOW DATABASES\" \n$dbs = irm \"http://192.168.3.104:8086/query?epoch=ms&amp;u=admin&amp;p=password&amp;q=SHOW DATABASES\" \n$dbs.results.series.values\n\n\nEndpoints\nAPI doc\n\nhttp://192.168.3.104:8086/debug/requests кол-во клиентских HTTP-запросов к конечным точкам /writeи /query \nhttp://192.168.3.104:8086/debug/pprof \nhttp://192.168.3.104:8086/ping \nhttp://192.168.3.104:8086/query \nhttp://192.168.3.104:8086/write\nhttp://192.168.3.99:8086/api/v2/setup \nhttp://192.168.3.99:8086/api/v2/config \nhttp://192.168.3.99:8086/api/v2/write\n\nPingTo-InfluxDB\n\nSELECT * FROM ping WHERE status = false\n\nPerformanceTo-InfluxDB\n\n\nService\n\n\nPSInfluxDB\nInstall-Module psinfluxdb -Repository NuGet \nGet-InfluxUsers -server 192.168.3.102 список пользователей на сенвере InfluxDB и права доступа \nGet-InfluxDatabases -server 192.168.3.102 список баз данных \nGet-InfluxDatabases -server 192.168.3.102 -creat -database test создать базу данных \nGet-InfluxDatabases -server 192.168.3.102 -delete -database test удалить базу данных \nGet-InfluxPolicy -server 192.168.3.102 -database PowerShell список политик хранения указанной базы данных \nGet-InfluxPolicy -server 192.168.3.102 -database PowerShell -creat -policyName del2d -hours 48 создать политику хранения \nGet-InfluxPolicy -server 192.168.3.102 -database PowerShell -policyName del2d -default применить политику хранения к базе данных по умолчанию \nGet-InfluxTables -server 192.168.3.102 -database PowerShell список таблиц/измерений в базе данных \n$Data = Get-InfluxData -server 192.168.3.102 -database PowerShell -table ping | Format-Table отобразить данные в таблице \n$Data | Where-Object {$_.SensorName -match \"CPU_Package\" -and $_.Value -gt 90} | Format-Table отфильтровать данные по двум параметрам (сенсоры процессора с показателем выше 90) \n$influx = Get-InfluxData -server 192.168.3.104 -database PowerShell -table speedtest \nGet-InfluxChart -time ($influx.time) -data ($influx.download) -title \"SpeedTest Download\" -path \"C:\\Users\\Lifailon\\Desktop\" создать график (WinForms Chart) измерений и сохранить в jpeg-файл\n\nTelegraf\nPlugins\niwr https://dl.influxdata.com/telegraf/releases/telegraf-1.27.1_windows_amd64.zip -UseBasicParsing -OutFile telegraf-1.27.1_windows_amd64.zip \nExpand-Archive .\\telegraf-1.27.1_windows_amd64.zip -DestinationPath \"C:\\Telegraf\" \nrm telegraf-1.27.1_windows_amd64.zip \ncd C:\\Telegraf \n.\\telegraf.exe -sample-config --input-filter cpu:mem:dns_query --output-filter influxdb &gt; telegraf_nt.conf создать конфигурацию с выбарнными плагинами для сбора метрик \nStart-Process notepad++ C:\\Telegraf\\telegraf_nt.conf\n\n.\\telegraf.exe --test -config C:\\Telegraf\\telegraf_nt.conf тест конфигурации (получения метрик с выводом в консоль) \nC:\\Telegraf\\telegraf.exe -config C:\\Telegraf\\telegraf_nt.conf запустить telegraf (тест отправки данных) \n.\\telegraf.exe --config \"C:\\Telegraf\\telegraf_nt.conf\" --service install создать службу \nGet-Service telegraf | Start-Service \n.\\telegraf.exe --service uninstall\nUSE telegraf \nSELECT usage_idle,usage_system,usage_user FROM cpu\n\nGraphite\nGraphite - это система хранения метрик временных рядов.\nГрафит состоит из трех основных компонентов:\n\nGraphite Web - django приложение для визуализации метрик на графиках.\nCarbon и StatsD - прием метрик по сети (кэширует и записывает данные в БД).\nWhisper - файловая БД для временных рядов (хранит данные в .wsp файлах) на python.\n\nЗапустить стек Graphite с веб-интерфейсом для визуализации метрик:\n\nПримеры отправки данных в Linux:\n\nПример отправки данных в Windows:\n\nПример отправки random-данных через Pickle Protocol на 2004 порт в Python (формат списка кортежей: [(path, (timestamp, value)), ...]):\n\n\nElasticsearch\nИсходник на GitHub.\nInstall-Module -Name Elastic.Console -AllowPrerelease установить модуль \nGet-Command -Module Elastic.Console вывести список команд \nGet-ElasticsearchVersion отобразить версию \nSet-ElasticsearchVersion 7.3.0 сменить версию \nInvoke-Elasticsearch REST API запросы\n\nCData\nPowerShell Gallery CData \nAutomate Elasticsearch Integration Tasks from PowerShell\nInstall-Module ElasticsearchCmdlets пакет драйвера в psgallery \nImport-Module ElasticsearchCmdlets \nGet-Command -Module ElasticsearchCmdlets\n\n\nADO.NET Assembly\nInstall-Package CData.Elasticsearch пакет драйвера в nuget \n[Reflection.Assembly]::LoadFile(\"C:\\Program Files\\PackageManagement\\NuGet\\Packages\\CData.Elasticsearch.23.0.8565\\lib\\net40\\System.Data.CData.Elasticsearch.dll\")\n\n\nUPDATE\n\n\nINSERT\n\n\nDELETE\n\n\nODBC\nGet-Command -Module Wdac \nGet-OdbcDriver | ft список установленных драйверов\n\nElasticsearch\nODBC драйвер для доступа к данным Elasticsearch из PowerShell.\n\n\nClickHouse\nПоследняя версия ODBC драйвера доступна на GitHub.\nОригинальный источник.\n\n\nPostgreSQL\nЗагрузить и установить драйвер\n\n\nnpgsql\nИсходный код\nPackage\n\n\nWMI\n\nWMI/CIM\n\nWindows Management Instrumentation/Common Information Model\n\nGet-WmiObjec -ComputerName localhost -Namespace root -class \"__NAMESPACE\" | select name,__namespace отобразить дочернии Namespace (логические иерархические группы) \nGet-WmiObject -List отобразить все классы пространства имен “root\\cimv2” (по умолчанию), свойства (описывают конфигурацию и текущее состояние управляемого ресурса) и их методы (какие действия позволяет выполнить над этим ресурсом) \nGet-WmiObject -List | Where-Object {$_.name -match \"video\"} поиск класса по имени, его свойств и методов \nGet-WmiObject -ComputerName localhost -Class Win32_VideoController отобразить содержимое свойств класса\ngwmi -List | where name -match \"service\" | ft -auto если в таблице присутствуют Methods, то можно взаимодействовать {StartService, StopService} \ngwmi -Class win32_service | select * отобразить список всех служб и всех их свойств \nGet-CimInstance Win32_service обращается на прямую к “root\\cimv2” \ngwmi win32_service -Filter \"name='Zabbix Agent'\" отфильтровать вывод по имени \n(gwmi win32_service -Filter \"name='Zabbix Agent'\").State отобразить конкретное свойство \ngwmi win32_service -Filter \"State = 'Running'\" отфильтровать запущенные службы \ngwmi win32_service -Filter \"StartMode = 'Auto'\" отфильтровать службы по методу запуска \ngwmi -Query 'select * from win32_service where startmode=\"Auto\"' WQL-запрос (WMI Query Language) \ngwmi win32_service | Get-Member -MemberType Method отобразить все методы взаимодействия с описание применения (Delete, StartService) \n(gwmi win32_service -Filter 'name=\"Zabbix Agent\"').Delete() удалить службу \n(gwmi win32_service -Filter 'name=\"MSSQL$MSSQLE\"').StartService() запустить службу\nGet-CimInstance -ComputerName $srv Win32_OperatingSystem | select LastBootUpTime время последнего включения \ngwmi -ComputerName $srv -Class Win32_OperatingSystem | select LocalDateTime,LastBootUpTime текущее время и время последнего включения \ngwmi Win32_OperatingSystem | Get-Member -MemberType Method методы reboot и shutdown \n(gwmi Win32_OperatingSystem -EnableAllPrivileges).Reboot() используется с ключем повышения привелегий \n(gwmi Win32_OperatingSystem -EnableAllPrivileges).Win32Shutdown(0) завершение сеанса пользователя\n\n(Get-WmiObject win32_battery).estimatedChargeRemaining заряд батареи в процентах \ngwmi Win32_UserAccount доменные пользователи \n(gwmi Win32_SystemUsers).PartComponent \nGet-CimInstance -ClassName Win32_LogonSession \nGet-CimInstance -ClassName Win32_BIOS\ngwmi -list -Namespace root\\CIMV2\\Terminalservices \n(gwmi -Class Win32_TerminalServiceSetting -Namespace root\\CIMV2\\TerminalServices).AllowTSConnections \n(gwmi -Class Win32_TerminalServiceSetting -Namespace root\\CIMV2\\TerminalServices).SetAllowTSConnections(1) включить RDP\n\n\nNLA\n\nNetwork Level Authentication\n\n(gwmi -class \"Win32_TSGeneralSetting\" -Namespace root\\cimv2\\Terminalservices -Filter \"TerminalName='RDP-tcp'\").UserAuthenticationRequired \n(gwmi -class \"Win32_TSGeneralSetting\" -Namespace root\\cimv2\\Terminalservices -Filter \"TerminalName='RDP-tcp'\").SetUserAuthenticationRequired(1) включить NLA \nGet-ItemProperty -Path \"HKLM:\\SYSTEM\\CurrentControlSet\\Control\\Terminal Server\\WinStations\\RDP-Tcp\" -Name SecurityLayer отобразить значение (2) \nGet-ItemProperty -Path \"HKLM:\\SYSTEM\\CurrentControlSet\\Control\\Terminal Server\\WinStations\\RDP-Tcp\" -Name UserAuthentication отобразить значение (1) \nSet-ItemProperty -Path \"HKLM:\\SYSTEM\\CurrentControlSet\\Control\\Terminal Server\\WinStations\\RDP-Tcp\" -Name SecurityLayer -Value 0 изменить значение \nSet-ItemProperty -Path \"HKLM:\\SYSTEM\\CurrentControlSet\\Control\\Terminal Server\\WinStations\\RDP-Tcp\" -Name UserAuthentication -Value 0 \nREG ADD HKLM\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Policies\\System\\CredSSP\\Parameters /v AllowEncryptionOracle /t REG_DWORD /d 2 отключить на клиентском компьютере проверку версии CredSSP, если на целевом комьютере-сервере не установлены обновления KB4512509 от мая 2018 года\n\nRegedit\nGet-PSDrive список всех доступных дисков/разделов, их размер и веток реестра \ncd HKLM:\\ HKEY_LOCAL_MACHINE \ncd HKCU:\\ HKEY_CURRENT_USER \nGet-Item получить информацию о ветке реестра \nNew-Item создать новый раздел реестра \nRemove-Item удалить ветку реестра \nGet-ItemProperty получить значение ключей/параметров реестра (это свойства ветки реестра, аналогично свойствам файла) \nSet-ItemProperty изменить название или значение параметра реестра \nNew-ItemProperty создать параметр реестра \nRemove-ItemProperty удалить параметр\nGet-ItemProperty HKLM:\\Software\\Microsoft\\Windows\\CurrentVersion\\Uninstall\\* | Select DisplayName список установленных программ \nGet-Item HKCU:\\SOFTWARE\\Microsoft\\Office\\16.0\\Outlook\\Profiles\\Outlook\\9375CFF0413111d3B88A00104B2A6676\\00000002 посмотреть содержимое Items \n(Get-ItemProperty HKCU:\\SOFTWARE\\Microsoft\\Office\\16.0\\Outlook\\Profiles\\Outlook\\9375CFF0413111d3B88A00104B2A6676\\00000002).\"New Signature\" отобразить значение (Value) свойства (Property) Items \n$reg_path = \"HKCU:\\SOFTWARE\\Microsoft\\Office\\16.0\\Outlook\\Profiles\\Outlook\\9375CFF0413111d3B88A00104B2A6676\\00000002\" \n$sig_name = \"auto\" \nSet-ItemProperty -Path $reg_path -Name \"New Signature\" -Value $sig_name изменить или добавить в корне ветки (Path) свойство (Name) со значением (Value) \nSet-ItemProperty -Path $reg_path -Name \"Reply-Forward Signature\" -Value $sig_name\n\n\nPerformance\nlodctr /R пересоздать счетчики производительности из системного хранилища архивов (так же исправляет счетчики для CIM, например, для cpu Win32_PerfFormattedData_PerfOS_Processor и iops Win32_PerfFormattedData_PerfDisk_PhysicalDisk). Ошибка 5 - нужны права Администратора, ошибка 2 - файлы счетчиков повреждены. \nsfc /scannow сканируем систему (если ошибка 2), для восстановления поврежденных счетчиков \nlodctr /S:PerfStringBackupTemp.ini сохраняет текущие информацию о счетчиках из реестра в указанном файле \nlodctr /R:PerfStringBackupTemp.ini восстановление из файла\n(Get-Counter -ListSet *).CounterSetName вывести список всех доступных счетчиков производительности в системе \n(Get-Counter -ListSet *memory*).Counter поиск по wildcard-имени во всех счетчиках (включая дочернии) \nGet-Counter \"\\Memory\\Available MBytes\" объем свободной оперативной памяти \nGet-Counter -cn $srv \"\\LogicalDisk(*)\\% Free Space\" % свободного места на всех разделах дисков \n(Get-Counter \"\\Process(*)\\ID Process\").CounterSamples \nGet-Counter \"\\Processor(_Total)\\% Processor Time\" –ComputerName $srv -MaxSamples 5 -SampleInterval 2 5 проверок каждые 2 секунды \nGet-Counter \"\\Процессор(_Total)\\% загруженности процессора\" -Continuous непрерывно \n(Get-Counter \"\\Процессор(*)\\% загруженности процессора\").CounterSamples\n(Get-Counter -ListSet *интерфейс*).Counter найти все счетчики \nGet-Counter \"\\Сетевой интерфейс(*)\\Всего байт/с\" отобразить все адаптеры (выбрать действующий по трафику)\n\n\nPerformanceCounter\n\n\nSNMP\n\nSetup SNMP Service\nInstall-WindowsFeature SNMP-Service,SNMP-WMI-Provider -IncludeManagementTools установить роль SNMP и WMI провайдер через Server Manager \nGet-WindowsFeature SNMP* \nAdd-WindowsCapability -Online -Name SNMP.Client~~~~0.0.1.0 установить компонент Feature On Demand для Windows 10/11\\Get-Service SNMP*\\Get-NetFirewallrule -DisplayName snmp | ft\\Get-NetFirewallrule -DisplayName snmp | Enable-NetFirewallRule`\n\nSetting SNMP Service via Regedit\nAgent: \nNew-ItemProperty -Path \"HKLM:\\SYSTEM\\CurrentControlSet\\services\\SNMP\\Parameters\\RFC1156Agent\" -Name \"sysContact\" -Value \"lifailon-user\" создать (New) или изменить (Set) \nNew-ItemProperty -Path \"HKLM:\\SYSTEM\\CurrentControlSet\\services\\SNMP\\Parameters\\RFC1156Agent\" -Name \"sysLocation\" -Value \"plex-server\"\nSecurity: \nNew-Item -Path \"HKLM:\\SYSTEM\\CurrentControlSet\\services\\SNMP\\Parameters\\TrapConfiguration\\public\" создать новый community string \nNew-ItemProperty -Path \"HKLM:\\SYSTEM\\CurrentControlSet\\Services\\SNMP\\Parameters\\ValidCommunities\" -Name \"public\" -Value 16 назначить права на public \n1 — NONE \n2 — NOTIFY позволяет получать SNMP ловушки \n4 — READ ONLY позволяет получать данные с устройства \n8 — READ WRITE позволяет получать данные и изменять конфигурацию устройства \n16 — READ CREATE позволяет читать данные, изменять и создавать объекты \nNew-ItemProperty -Path \"HKLM:\\SYSTEM\\CurrentControlSet\\Services\\SNMP\\Parameters\\PermittedManagers\" -Name \"1\" -Value \"192.168.3.99\" от кого разрешено принимать запросы \nGet-Service SNMP | Restart-Service\n\nsnmpwalk\nsnmpwalk -v 2c -c public 192.168.3.100 \nsnmpwalk -v 2c -c public -O e 192.168.3.100\n\nSNMP Modules\nInstall-Module -Name SNMP \nGet-SnmpData -IP 192.168.3.100 -OID 1.3.6.1.2.1.1.4.0 -UDPport 161 -Community public \n(Get-SnmpData -IP 192.168.3.100 -OID 1.3.6.1.2.1.1.4.0).Data \nInvoke-SnmpWalk -IP 192.168.3.100 -OID 1.3.6.1.2.1.1 пройтись по дереву OID \nInvoke-SnmpWalk -IP 192.168.3.100 -OID 1.3.6.1.2.1.25.6.3.1.2 список установленного ПО \nInvoke-SnmpWalk -IP 192.168.3.100 -OID 1.3.6.1.2.1.25.2.3.1 список разделов и памяти (C: D: Virtual Memory и Physical Memory) \nSet-SnmpData изменение данных на удаленном устройстве\nInstall-Module -Name SNMPv3 \nInvoke-SNMPv3Get получение данных по одному OID \nInvoke-SNMPv3Set изменение данных \nInvoke-SNMPv3Walk обход по дереву OID \nInvoke-SNMPv3Walk -UserName lifailon -Target 192.168.3.100 -AuthSecret password -PrivSecret password -OID 1.3.6.1.2.1.1 -AuthType MD5 -PrivType AES128\n\nLextm.SharpSnmpLib\nСинтаксис \nDownload lib\nAdd-Type -LiteralPath \"$home\\Desktop\\lextm.sharpsnmplib-12.5.2\\net471\\SharpSnmpLib.dll\"\n\n\nWalk\n\n\nZabbix\n\nZabbix Agent\nZabbix Agent Deploy:\n\nzabbix_agent2.conf\n\n\nZabbix Sender\nИспользуется для отправки данных на сервер\nСоздать host - задать произвольное имя (powershell-host) и добавить в группу на сервере\nСоздать Items вручную:\nName: Service Count \nType: Zabbix trapper \nKey: service.count \nType of Information: Numeric\n\n\nZabbix Get\nИспользуется для получения данных с агента (как их запрашивает сервер)\napt install zabbix-get \nnano /etc/zabbix/zabbix_agentd.conf \nServer=127.0.0.1,192.168.3.102,192.168.3.99 добавить сервера для получения данных через zabbix_get с агента (как их запрашивает сервер)\n.$path\\zabbix_get -s 192.168.3.101 -p 10050 -k agent.version проверить версию агента \n.$path\\zabbix_get -s 192.168.3.101 -p 10050 -k agent.ping 1 - ok \n.$path\\zabbix_get -s 192.168.3.101 -p 10050 -k net.if.discovery список сетевых интерфейсов \n.$path\\zabbix_get -s 192.168.3.101 -p 10050 -k net.if.in[\"ens33\"] \n.$path\\zabbix_get -s 192.168.3.101 -p 10050 -k net.if.out[\"ens33\"]\n\nUserParameter\nПользовательские параметры\nUserParameter=process.count,powershell -Command \"(Get-Process).Count\" \nUserParameter=process.vm[*],powershell -Command \"(Get-Process $1).ws\"\nПолучение данных:\nC:\\zabbix-agent2-6.4.5\\bin\\zabbix_get.exe -s 127.0.0.1 -p 10050 -k process.count \nC:\\zabbix-agent2-6.4.5\\bin\\zabbix_get.exe -s 127.0.0.1 -p 10050 -k process.vm[zabbix_agent2] \nC:\\zabbix-agent2-6.4.5\\bin\\zabbix_get.exe -s 127.0.0.1 -p 10050 -k process.vm[powershell]\nСоздать новые Items на сервере:\nkey: process.count \nkey: process.vm[zabbix_agent2]\n\nInclude Plugins\n\nДобавить параметр Include для включения конфигурационных файлов подключаемых плагинов\n\n'Include=.\\zabbix_agent2.d\\plugins.d\\*.conf' &gt;&gt; C:\\zabbix-agent2-6.4.5\\conf\\zabbix_agent2.conf\n\nСоздать конфигурационный файл с пользовательскими параметрами в каталоге, путь к которому указан в zabbix_agentd.conf\n\n'UserParameter=Get-Query-Param[*],powershell.exe -noprofile -executionpolicy bypass -File C:\\zabbix-agent2-6.4.5\\conf\\zabbix_agent2.d\\scripts\\User-Sessions\\Get-Query-Param.ps1 $1' &gt; C:\\zabbix-agent2-6.4.5\\conf\\zabbix_agent2.d\\plugins.d\\User-Sessions.conf\n\nПоместить скрипт Get-Query-Param.ps1 в каталог, путь к которому указан в User-Sessions.conf. Скрипт содержим пользовательские параметры, которые он принимает от Zabbix сервера для передачи их в функции скрипта.\n\n\n\nПроверить работу скрипта:\n\n$path = \"C:\\zabbix-agent2-6.4.5\\conf\\zabbix_agent2.d\\scripts\\User-Sessions\" \n.$path\\Get-Query-Param.ps1 ACTIVEUSER \n.$path\\Get-Query-Param.ps1 INACTIVEUSER \n.$path\\Get-Query-Param.ps1 ACTIVECOUNT \n.$path\\Get-Query-Param.ps1 INACTIVECOUNT\n\nСоздать Items с ключами:\n\nGet-Query-Param[ACTIVEUSER] Type: Text \nGet-Query-Param[INACTIVEUSER] Type: Text \nGet-Query-Param[ACTIVECOUNT] Type: Int \nGet-Query-Param[INACTIVECOUNT] Type: Int\n\nМакросы:\n\n{$ACTIVEMAX} = 16 \n{$ACTIVEMIN} = 0\n\nТриггеры:\n\nlast(/Windows-User-Sessions/Get-Query-Param[ACTIVECOUNT])&gt;{$ACTIVEMAX} \nmin(/Windows-User-Sessions/Get-Query-Param[ACTIVECOUNT],24h)={$ACTIVEMIN}\n\nZabbix API\nDocumentation\n$ip = \"192.168.3.102\" \n$url = \"http://$ip/zabbix/api_jsonrpc.php\"\nПолучение токена доступа:\n\n$token = \"2eefd25fdf1590ebcdb7978b5bcea1fff755c65b255da8cbd723181b639bb789\" сгенерировать токен в UI (http://192.168.3.102/zabbix/zabbix.php?action=token.list)\n\nuser.get method\n\n\n\nproblem.get method\n\n\n\nhost.get method\n\nПолучить список всех хостов (имя и id)\nEndpoint host documentation\nhost.create — создание новых хостов \nhost.delete — удаление хостов \nhost.get — получить список хостов \nhost.massadd - добавление (привязка) объектов на хосты \nhost.massremove - удаление объектов \nhost.massupdate - замена или обновление объектов \nhost.update - обновление хостов\n\n\nitem.get\n\nПолучить id элементов данных по наименованию ключа для конкретного хоста\n\n\nhistory.get\n\nПолучить всю историю элемента данных по его id\n\nКовенртация секунд в TimeSpan:\n$sec = $items_data_uptime.value\n\n$UpTime = ConvertSecondsTo-TimeSpan $sec[-1]\nКонвертация из времени Unix:\n$time = $items_data_uptime.clock\n\n$GetDataTime = ConvertFrom-UnixTime $time[-1]\n($hosts | where hostid -eq $host_id).host получить имя хоста \n$UpTime последнее полученное значение времени работы хоста \n$GetDataTime время последнего полученного значения\n\npki\nNew-SelfSignedCertificate -CertStoreLocation Cert:\\LocalMachine\\My -DnsName \"$env:computername\" -FriendlyName \"Test Certificate\" -NotAfter (Get-Date).AddYears(5) создать самоподписанный сертификат (в LocalMachine\\My - Сертификаты компьютера\\Личное) с сроком действия 5 лет\nGet-ChildItem -Path Cert:\\CurrentUser\\Root\\ список всех установленных сертификатов в хранилище Доверенные корневые ЦС Текущего пользователя \nGet-ChildItem -Path Cert:\\CurrentUser\\My\\ список самозаверяющих сертификатов в Личное хранилище Текущего пользователя \nGet-ChildItem -Path Cert:\\LocalMachine\\My\\ список самозаверяющих сертификатов в Личное хранилище Локального компьютера \nGet-ChildItem -Path Cert:\\LocalMachine\\My\\ | select NotBefore,NotAfter,Thumbprint,Subject срок действия сертификата \nGet-ChildItem -Path Cert:\\LocalMachine\\My\\ | where Thumbprint -eq D9356FB774EE0E6206B7D5B59B99102CA5B17BDA поиск сертификат по отпечатку\nGet-ChildItem -Path $env:APPDATA\\Microsoft\\SystemCertificates\\My\\Certificates\\ сертификаты в файловой системе, каждый файл соответствует сертификату, установленному в личном хранилище текущего пользователя \nGet-ChildItem -Path $env:APPDATA\\Microsoft\\SystemCertificates\\My\\Keys\\ ссылки на объекты закрытых ключей, созданных поставщиком хранилища ключей (KSP) \nGet-ChildItem -Path HKCU:\\Software\\Microsoft\\SystemCertificates\\CA\\Certificates | ft -AutoSize список сертификатов в реестре вошедшего в систему пользователя\n$cert = (Get-ChildItem -Path Cert:\\CurrentUser\\My\\)[1] выбрать сертификат \n$cert | Remove-Item удалить сертификат\nExport-Certificate -FilePath $home\\Desktop\\certificate.cer -Cert $cert экспортировать сертификат \n$cert.HasPrivateKey проверить наличие закрытого ключа \n$pass = \"password\" | ConvertTo-SecureString -AsPlainText -Force создать пароль для шифрования закрытого ключа \nExport-PfxCertificate -FilePath $home\\Desktop\\certificate.pfx -Password $pass -Cert $certificate экспортировать сертификат с закрытым ключем\nImport-Certificate -FilePath $home\\Desktop\\certificate.cer -CertStoreLocation Cert:\\CurrentUser\\My импортировать сертификат \nImport-PfxCertificate -Exportable -Password $pass -CertStoreLocation Cert:\\CurrentUser\\My -FilePath $home\\Desktop\\certificate.pfx\n\nOpenSSL\n\n\n\nИзменить пароль для PFX \nopenssl pkcs12 -in \"C:\\Cert\\domain.ru.pfx\" -out \"C:\\Cert\\domain.ru.pem\" -nodes экспортируем имеющийся сертификат и закрытый ключ в .pem-файл без пароля с указанием текущего пароля \nopenssl pkcs12 -export -in \"C:\\Cert\\domain.ru.pem\" -out \"C:\\Cert\\domain.ru_password.pfx\" -nodes конвертируем .pem обратно в .pfx c указанием нового пароля\n\n\nКонвертация из закрытого и открытого ключа PEM в PFX \nopenssl pkcs12 -export -in \"C:\\tmp\\vpn\\vpn.itproblog.ru-crt.pem\" -inkey \"C:\\tmp\\vpn\\vpn.itproblog.ru-key.pem\" -out \"C:\\tmp\\vpn\\vpn.iiproblog.ru.pfx\" \nin – путь до файла с открытым ключом \ninkey – путь до файла с закрытым ключом \nout – путь до файла, в который будет конвертирован сертификат (pfx)\n\n\nКонвертация PFX в CRT \nopenssl pkcs12 -in \"C:\\OpenSSL-Win64\\bin\\_.domain.ru.pfx\" -clcerts -out \"C:\\OpenSSL-Win64\\bin\\_.domain.ru.crt\" указывается текущий и 2 раза новый пароль PEM pass phrase (файл содержит EGIN CERTIFICATE и BEGIN ENCRYPTED PRIVATE KEY) \nopenssl pkcs12 -in \"C:\\OpenSSL-Win64\\bin\\_.domain.ru.pfx\" -clcerts -nokeys -out \"C:\\OpenSSL-Win64\\bin\\_.domain.ru.crt\" без ключа, получить открытую часть (файл содержит только EGIN CERTIFICATE)\n\n\nКонвертация PFX в KEY \nopenssl pkcs12 -in \"C:\\OpenSSL-Win64\\bin\\_.domain.ru.pfx\" -nocerts -out \"C:\\OpenSSL-Win64\\bin\\_.domain.ru.key\" файл содержит только BEGIN ENCRYPTED PRIVATE KEY\n\n\nСнять пароль к закрытого ключа .key \nopenssl rsa -in \"C:\\OpenSSL-Win64\\bin\\_.domain.ru.key\" -out \"C:\\OpenSSL-Win64\\bin\\_.domain.ru-decrypted.key\"\n\n\nCRT и KEY в PFX: \nopenssl pkcs12 -inkey certificate.key -in certificate.crt -export -out certificate.pfx\n\n\n\nOpenVPN\nInvoke-WebRequest -Uri https://swupdate.openvpn.org/community/releases/OpenVPN-2.6.5-I001-amd64.msi -OutFile $home\\Downloads\\OpenVPN-2.6.5.msi \nStart-Process $home\\Downloads\\OpenVPN-2.6.5.msi -ArgumentList '/quiet /SELECT_OPENSSL_UTILITIES=1' -Wait \nmsiexec /i $home\\Downloads\\OpenVPN-2.6.5.msi ADDLOCAL=EasyRSA /passive /quiet # установить отдельный компонент EasyRSA Certificate Management Scripts \n# msiexec /i $home\\Downloads\\OpenVPN-2.6.5.msi ADDLOCAL=OpenVPN.Service,Drivers,Drivers.Wintun,OpenVPN,OpenVPN.GUI,OpenVPN.GUI.OnLogon,EasyRSA /passive выборочная установка \n# Invoke-WebRequest -Uri https://github.com/OpenVPN/easy-rsa/releases/download/v3.1.5/EasyRSA-3.1.5-win64.zip -OutFile $home\\Downloads\\EasyRSA-3.1.5.zip скачать отдельный пакет EasyRSA \nrm $home\\Downloads\\OpenVPN-2.6.5.msi\ncd \"C:\\Program Files\\OpenVPN\\easy-rsa\" \nCopy-Item vars.example vars файл конфигурации для EasyRSA\n\n.\\EasyRSA-Start.bat среда EasyRSA Shell \neasyrsa init-pki инициализация PKI, создает директорию: C:\\Program Files\\OpenVPN\\easy-rsa\\pki и читает переменные файла \\easy-rsa\\vars \neasyrsa build-ca генерация корневого CA с указанием пароля и произвольное имя сервера (\\pki\\ca.crt и \\pki\\private\\ca.key) \neasyrsa gen-req server nopass генерация запроса сертификата и ключ для сервера OpenVPN - yes (\\pki\\reqs\\server.req и \\pki\\private\\server.key) \neasyrsa sign-req server server подписать запрос на выпуск сертификата сервера с помощью CA - yes (\\pki\\issued\\server.crt) \neasyrsa gen-dh создать ключ Диффи-Хеллмана (\\pki\\dh.pem) \neasyrsa gen-req client1 nopass генерация запроса сертификата и ключ для клиента OpenVPN (\\pki\\reqs\\client1.req и \\pki\\private\\client1.key) \neasyrsa sign-req client client1 подписать запрос на выпуск сертификата клиента с помощью CA - yes (\\pki\\issued\\client1.crt) \neasyrsa revoke client1 отозвать сертификат пользователя \nopenssl rsa -in \"C:\\Program Files\\OpenVPN\\easy-rsa\\pki\\private\\client1.key\" -out \"C:\\Program Files\\OpenVPN\\easy-rsa\\pki\\private\\client1_nopass.key\" снять защиту паролем для ключа (BEGIN ENCRYPTED PRIVATE KEY -&gt; BEGIN PRIVATE KEY) \nexit \ncd \"C:\\Program Files\\OpenVPN\\bin\" \n.\\openvpn --genkey secret ta.key генерация ключа tls-auth (\\bin\\ta.key) \nMove-Item \"C:\\Program Files\\OpenVPN\\bin\\ta.key\" \"C:\\Program Files\\OpenVPN\\easy-rsa\\pki\\\"\n\nserver.ovpn\n# Copy-Item \"C:\\Program Files\\OpenVPN\\sample-config\\server.ovpn\" \"C:\\Program Files\\OpenVPN\\config-auto\\server.ovpn\" \nNew-Item -ItemType File -Path \"C:\\Program Files\\OpenVPN\\config-auto\\server.ovpn\"\n\nNew-NetFirewallRule -DisplayName \"AllowOpenVPN-In\" -Direction Inbound -Protocol UDP –LocalPort 1194 -Action Allow на сервере \nNew-NetFirewallRule -DisplayName \"AllowOpenVPN-Out\" -Direction Outbound -Protocol UDP –LocalPort 1194 -Action Allow на клиенте \nGet-Service *openvpn* | Restart-Service\n\nclient.ovpn\n# Copy-Item \"C:\\Program Files\\OpenVPN\\sample-config\\client.ovpn\" \"C:\\Program Files\\OpenVPN\\config-auto\\client.ovpn\" \nNew-Item -ItemType File -Path \"C:\\Program Files\\OpenVPN\\config-auto\\client.ovpn\"\n\n\nClient\niwr -Uri https://openvpn.net/downloads/openvpn-connect-v3-windows.msi -OutFile \"$home\\downloads\\OpenVPN-Connect-3.msi\" \nПередать конфигурацию и ключи: \nclient.ovpn \nca.crt \ndh.pem \nta.key \nclient1.crt \nclient1.key\n\nRoute\nGet-Service RemoteAccess | Stop-Service \nSet-ItemProperty -Path \"HKLM:\\SYSTEM\\CurrentControlSet\\Services\\Tcpip\\Parameters\" -Name \"IPEnableRouter\" -Value 1 включает IP маршрутизацию \n(Get-ItemProperty \"HKLM:\\SYSTEM\\CurrentControlSet\\Services\\Tcpip\\Parameters\").IPEnableRouter \nGet-NetIPInterface | select ifIndex,InterfaceAlias,AddressFamily,ConnectionState,Forwarding | ft отобразить сетевые интерфейсы \nSet-NetIPInterface -ifIndex 13 -Forwarding Enabled включить переадресацию на интерфейсе\nsysctl net.ipv4.ip_forward=1 \necho \"sysctl net.ipv4.ip_forward = 1\" &gt;&gt; /etc/sysctl.conf\nGet-NetRoute \nNew-NetRoute -DestinationPrefix \"192.168.3.0/24\" -NextHop \"192.168.4.1\" -InterfaceIndex 8 \nroute -p add 192.168.3.0 mask 255.255.255.0 192.168.4.1 metric 1 \nroute -p change 192.168.3.0 mask 255.255.255.0 192.168.4.1 metric 2 \nroute -p add 192.168.3.0 mask 255.255.255.0 192.168.4.1 metric 1 if 7 указать номер сетевого интерфейса на который необходимо посылать пакет (Wintun Userspace Tunnel) \nroute print -4 \nroute delete 192.168.3.0\ntracert 192.168.3.101 с 192.168.4.6\n\nroute add -net 192.168.4.0 netmask 255.255.255.0 gw 192.168.3.100 \nroute -e\ntraceroute 192.168.4.6 с 192.168.3.101\n\nping 192.168.3.101 -t с 192.168.4.6 \ntcpdump -n -i ens33 icmp на 192.168.3.101\n\n\nNAT\nGet-Command -Module NetNat \nNew-NetNat -Name LocalNat -InternalIPInterfaceAddressPrefix \"192.168.3.0/24\" \nAdd-NetNatStaticMapping -NatName LocalNat -Protocol TCP -ExternalIPAddress 0.0.0.0 -ExternalPort 80 -InternalIPAddress 192.168.3.102 -InternalPort 80 \nRemove-NetNatStaticMapping -StaticMappingID 0 \nRemove-NetNat -Name LocalNat\n\nWireGuard\nInvoke-WebRequest \"https://download.wireguard.com/windows-client/wireguard-amd64-0.5.3.msi\" -OutFile \"$home\\Downloads\\WireGuard-Client-0.5.3.msi\" \nmsiexec.exe /i \"$home\\Downloads\\WireGuard-Client-0.5.3.msi\" DO_NOT_LAUNCH=1 /qn \nInvoke-WebRequest \"http://www.wiresock.net/downloads/wiresock-vpn-gateway-x64-1.1.4.1.msi\" -OutFile \"$home\\Downloads\\WireSock-VPN-Gateway-1.1.4.1.msi\" \nmsiexec.exe /i \"http://www.wiresock.net/downloads/wiresock-vpn-gateway-x64-1.1.4.1.msi\" /qn \n$env:Path = [System.Environment]::GetEnvironmentVariable(\"Path\",\"Machine\") + \";\" + [System.Environment]::GetEnvironmentVariable(\"Path\",\"User\") \nwg-quick-config -add -start \n26.115.154.67:8181 \n192.168.21.4/24 \nSuccessfully saved client configuration: C:\\ProgramData\\NT KERNEL\\WireSock VPN Gateway\\wsclient_1.conf \nSuccessfully saved server configuration: C:\\ProgramData\\NT KERNEL\\WireSock VPN Gateway\\wiresock.conf \nget-service *wire* \nwg show \nwg-quick-config -add -restart add client\nwiresock.conf\n\nwsclient_1.conf (добавить маршруты для клиента в AllowedIPs)\n\n\nVpnClient\nGet-Command -Module VpnClient \nAdd-VpnConnection -Name \"vpn-failon\" -ServerAddress \"26.115.154.67\" -TunnelType L2TP -L2tpPsk \"123098\" -EncryptionLevel \"Required\" -AuthenticationMethod MSChapv2 -RememberCredential -AllUserConnection –PassThru -Force \n-TunnelType PPTP/L2TP/SSTP/IKEv2/Automatic \n-L2tpPsk использовать общий ключ для аутентификации (без параметра, для L2TP аутентификации используется сертификат) \n-AuthenticationMethod Pap/Chap/MSChapv2/Eap/MachineCertificate \n-EncryptionLevel NoEncryption/Optional/Required/Maximum/Custom \n-SplitTunneling заворачивать весь трафик через VPN-туннель (включение Use default gateway on remote network в настройках параметра VPN адаптера) \n-UseWinlogonCredential использовать учетные данные текущего пользователя для аутентификации на VPN сервере \n-RememberCredential разрешить сохранять учетные данные для VPN подключения (учетная запись и пароль сохраняются в диспетчер учетных данных Windows после первого успешного подключения) \n-DnsSuffix domain.local \n-AllUserConnection разрешить использовать VPN подключение для всех пользователей компьютера (сохраняется в конфигурационный файл: C:\\ProgramData\\Microsoft\\Network\\Connections\\Pbk\\rasphone.pbk)\nInstall-Module -Name VPNCredentialsHelper модуль для сохранения логина и пароля в Windows Credential Manager для VPN подключения \nSet-VpnConnectionUsernamePassword -connectionname vpn-failon -username user1 -password password\nrasdial \"vpn-failon\" подключиться \nGet-VpnConnection -AllUserConnection | select * список VPN подключения, доступных для всех пользователей, найстройки и текущий статус подключения (ConnectionStatus) \nAdd-VpnConnectionRoute -ConnectionName vpn-failon -DestinationPrefix 192.168.3.0/24 –PassThru динамически добавить в таблицу маршрутизации маршрут, который будет активен при подключении к VPN \nRemove-VpnConnection -Name vpn-failon -AllUserConnection -Force удалить\nSet-VpnConnection -Name \"vpn-failon\" -SplitTunneling $True включить раздельное тунеллирование \nAdd-VpnConnectionRoute -ConnectionName \"vpn-failon\" -DestinationPrefix 172.22.22.0/24 настроить маршрутизацию к указанной подсети через VPN-соединение \n(Get-VpnConnection -ConnectionName \"vpn-failon\").routes отобразить таблицу маршрутизации для указанного соединения \nRemove-VpnConnectionRoute -ConnectionName \"vpn-failon\" -DestinationPrefix \"172.22.23.0/24\"\n\nProxyClient\n$user = \"lifailon\" \n$pass = \"Proxy\" \n$SecureString = ConvertTo-SecureString $pass -AsPlainText -Force \n$Credential = New-Object System.Management.Automation.PSCredential($user, $SecureString) \n[System.Net.Http.HttpClient]::DefaultProxy = New-Object System.Net.WebProxy(\"http://192.168.3.100:9090\") \n[System.Net.Http.HttpClient]::DefaultProxy.Credentials = [System.Net.CredentialCache]::DefaultCredentials \n[System.Net.Http.HttpClient]::DefaultProxy.Credentials = $Credential \nInvoke-RestMethod http://ifconfig.me/ip узнать внешний ip-адрес (по умолчанию в текущей сессии подключения будут происходить через заданный прокси сервер) \nInvoke-RestMethod https://kinozal.tv/rss.xml\n\nnetsh\n\nReverse Proxy\nnetsh interface portproxy add v4tov4 listenport=8080 listenaddress=0.0.0.0 connectport=80 connectaddress=192.168.3.108 настраивает входящее подключение на 8080 порту и переадресует трафик на 80 порт указанного хоста \nnetsh interface portproxy show all отобразить список всех настроек \nnetsh interface portproxy delete v4tov4 listenport=8080 listenaddress=0.0.0.0 удалить переадресацию\n\nWlan\nnetsh wlan show profile список сохраненны профилей Wi-Fi и паролей \nnetsh wlan show interfaces хар-ки текущей сети (MAC, speed) \nnetsh wlan show profile SSID-Name-Network key=clear очистить пароль \nnetsh wlan show networks список видемых сетей \nnetsh wlan disconnect отключиться от Wi-Fi \nnetsh wlan connect name=\"SSID-Name-Network\" подключиться \nnetsh wlan show drivers драйвер Wi-Fi \nnetsh wlan set hostednetwork mode=allow ssid=\"WiFi-Test\" key=\"password\" создание точки доступа Wi-Fi (SoftAP)\n\nFirewall\nnetsh advfirewall set allprofiles state off отключить fw \nnetsh advfirewall reset сбросить настройки \nnetsh advfirewall firewall add rule name=\"Open Remote Desktop\" protocol=TCP dir=in localport=3389 action=allow открыть порт 3389 \nnetsh advfirewall firewall add rule name=\"All ICMP V4\" dir=in action=allow protocol=icmpv4 открыть icmp\n\nOpenSSH\nGet-WindowsCapability -Online | ? Name -like 'OpenSSH.Client*' \nAdd-WindowsCapability -Online -Name OpenSSH.Client* \ndism /Online /Add-Capability /CapabilityName:OpenSSH.Client~~~~0.0.1.0 \niwr https://github.com/PowerShell/Win32-OpenSSH/releases/download/v9.2.2.0p1-Beta/OpenSSH-Win64-v9.2.2.0.msi -OutFile $home\\Downloads\\OpenSSH-Win64-v9.2.2.0.msi скачать \nmsiexec /i $home\\Downloads\\OpenSSH-Win64-v9.2.2.0.msi установить msi пакет \nSet-Service sshd -StartupType Automatic \nGet-NetTCPConnection | where LocalPort -eq 22 \nNew-NetFirewallRule -Name sshd -DisplayName 'OpenSSH Server (sshd)' -Enabled True -Direction Inbound -Protocol TCP -Action Allow -LocalPort 22 \nGet-NetFirewallRule -Name *ssh* \nStart-Process notepad++ C:\\Programdata\\ssh\\sshd_config конфигурационный файл \nGSSAPIAuthentication yes включить Kerberos аутентификацию (через AD) \nSyslogFacility LOCAL0 включить локальное ведение журнала в файл (C:\\ProgramData\\ssh\\logs\\sshd.log) \nLogLevel INFO \nRestart-Service sshd \nssh -K $srv выполнить Kerberos аутентификацию \nssh Lifailon@192.168.3.99 -p 22 \npwsh -command Get-Service \nssh -L 3101:192.168.3.101:22 -R 3101:192.168.3.101:22 lifailon@192.168.3.101 -p 22 SSH Tunnel lifailon@localhost:3101 -&gt; 192.168.3.101:3101\n\nPSRemoting over SSH\nAdd-WindowsCapability -Online -Name OpenSSH.Server~~~~0.0.1.0 установка OpenSSH Server \nGet-WindowsCapability -Online | ? Name -like 'OpenSSH.Ser*' \niex \"&amp; { $(irm https://aka.ms/install-powershell.ps1) } -UseMSI\" установка PowerShell Core последней версии (требуется на клиентской стороне) \nSet-Service -Name sshd -StartupType \"Automatic\" \nStart-Service sshd \nGet-NetTCPConnection -State Listen|where {$_.localport -eq '22'} \nEnable-NetFirewallRule -Name *OpenSSH-Server* \nNew-ItemProperty -Path \"HKLM:\\SOFTWARE\\OpenSSH\" -Name DefaultShell -Value \"C:\\Program Files\\PowerShell\\7\\pwsh.exe\" -PropertyType String –Force изменить интерпритатор по умолчанию на pwsh \nnotepad $Env:ProgramData\\ssh\\sshd_config\nPasswordAuthentication yes \nSubsystem powershell c:/progra~1/powershell/7/pwsh.exe -sshs -NoLogo # запуск интерпретатора pwsh для удаленных SSH подключений\nRestart-Service sshd\n$session = New-PSSession -HostName 192.168.3.100 -Port 2121 -UserName lifailon -SSHTransport \nInvoke-Command -Session $session -ScriptBlock {Get-Service}\n\nWinRM\nEnter-PSSession -ComputerName $srv подключиться к PowerShell сессии через PSRemoting. Подключение возможно только по FQDN-имени \nInvoke-Command $srv -ScriptBlock {Get-ComputerInfo} выполнение команды через PSRemoting \n$session = New-PSSession $srv открыть сессию \nGet-PSSession отобразить активные сессии \nicm -Session $session {$srv = $using:srv} передать переменную текущей сессии ($using) в удаленную \nDisconnect-PSSession $session закрыть сессию \nRemove-PSSession $session удалить сессию \nImport-Module -Name ActiveDirectory -PSSession $srv импортировать модуль с удаленного компьютера в локальную сессию\n\nWinRM Configuration\nwinrm quickconfig -quiet изменит запуск службы WinRM (Windows Remote Management) на автоматический, задаст стандартные настройки WinRM и добавить исключения для портов в fw \nEnable-PSRemoting –Force включить PowerShell Remoting, работает только для доменного и частного сетевых профилей Windows \nEnable-PSRemoting -SkipNetworkProfileCheck -Force для настройки компьютера в общей (public) сети (работает с версии powershell 6)\n$NetProfiles = Get-NetConnectionProfile отобразить профили сетевых подключений \nSet-NetConnectionProfile -InterfaceIndex $NetProfiles[1].InterfaceIndex -NetworkCategory Private изменить тип сети для профиля (DomainAuthenticated/Public) \n(Get-CimInstance -ClassName Win32_ComputerSystem).PartOfDomain проверить, что компьютер добавлен в домен AD \nGet-Service WinRM | Set-Service -StartupType AutomaticDelayedStart отложенный запуск \nGet-Service -Name winrm -RequiredServices статус зависимых служб \nNew-NetFirewallRule -Profile Any -DisplayName \"WinRM HTTP\" -Direction Inbound -Protocol TCP -LocalPort 5985,5986 \nTest-NetConnection $srv -port 5895 проверить порт \nTest-WSMan $srv -ErrorAction Ignore проверить работу WinRM на удаленном компьютере (игнорировать вывод ошибок для скрипта) или локально (localhost)\n$Cert = New-SelfSignedCertificate -CertStoreLocation Cert:\\LocalMachine\\My -DnsName \"$env:computername\" -FriendlyName \"WinRM HTTPS Certificate\" -NotAfter (Get-Date).AddYears(5) создать самоподписанный сертификат \n$Thumbprint = $Cert.Thumbprint забрать отпечаток \nNew-Item -Path WSMan:\\Localhost\\Listener -Transport HTTPS -Address * -CertificateThumbprint $Thumbprint -Name WinRM_HTTPS_Listener -Force создать прослушиватель \nNew-NetFirewallRule -DisplayName 'WinRM HTTPS' -Profile Domain,Private -Direction Inbound -Action Allow -Protocol TCP -LocalPort 5986 открыть порт в fw\n\nwinrm get winrm/config отобразить всю конфигурацию (Client/Service) \nwinrm get winrm/config/service/auth конфигурация авторизации на сервере \nwinrm enumerate winrm/config/listener текущая конфигурация прослушивателей WinRM (отображает отпечаток сертификата для HTTPS 5986) \nGet-ChildItem -Path Cert:\\LocalMachine\\My\\ | where Thumbprint -eq D9356FB774EE0E6206B7D5B59B99102CA5B17BDA | select * информация о сертификате\nls WSMan:\\localhost\\Client конфигурацию клиента \nls WSMan:\\localhost\\Service конфигурация сервера \nls WSMan:\\localhost\\Service\\auth список всех конфигураций аутентификации WinRM сервера \nSet-Item -path WSMan:\\localhost\\Service\\auth\\basic -value $true разрешить локальную аутентификацию к текущему серверу \nls HKLM:\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\WSMAN настройки в реестре (например, для включения аудентификации в \\Service\\auth_basic = 1) \nSet-Item WSMan:\\localhost\\Client\\TrustedHosts -Value 192.168.* -Force добавить доверенные хосты в конфигурацию на клиенте, чтобы работала Negotiate аутентификация через NTLM \nSet-Item WSMan:\\localhost\\Client\\TrustedHosts -Value 192.168.3.100 -Concatenate -Force добавить второй компьютер \nls WSMan:\\localhost\\Client\\TrustedHosts \nSet-Item WSMan:\\localhost\\Client\\AllowUnencrypted $true включить передача незашифрованных данных конфигурации клиента \nSet-Item WSMan:\\localhost\\Service\\AllowUnencrypted $true включить передача незашифрованных данных конфигурации сервера (необходимо быть в private сети)\nGet-PSSessionConfiguration проверить, включен ли PSremoting и вывести список пользователей и групп, которым разрешено подключаться через WinRM \nSet-PSSessionConfiguration -Name Microsoft.PowerShell -ShowSecurityDescriptorUI назначить права доступа через дескриптор безопасности текущей сессии (до перезагруки) \n(Get-PSSessionConfiguration -Name \"Microsoft.PowerShell\").SecurityDescriptorSDDL получить настройки дескриптора в формате SDDL \nSet-PSSessionConfiguration -Name Microsoft.PowerShell -SecurityDescriptorSDDL $SDDL применить настройки дескриптора на другом компьютере без использования GUI \\\nNew-LocalUser \"WinRM-Writer\" -Password (ConvertTo-SecureString -AsPlainText \"123098\") создать пользователя \nAdd-LocalGroupMember -Group \"Remote Management Users\" -Member \"WinRM-Writer\" добавить пользователя WinRM-Writer в локальную группу доступа “Пользователи удаленного управления” \ncmdkey /add:192.168.3.99 /user:WinRM-Writer /pass:123098 сохранить пароль в CredentialManager\ncmdkey /list \nImport-Module CredentialManager \nAdd-Type -AssemblyName System.Web \nNew-StoredCredential -Target 192.168.3.99 -UserName WinRM-Writer -Password 123098 -Comment WinRM сохранить пароль в CredentialManager (из PS5) \nGet-StoredCredential -AsCredentialObject \n$cred = Get-StoredCredential -Target 192.168.3.99 \nEnter-PSSession -ComputerName 192.168.3.99 -Credential $cred -Authentication Negotiate \nEnter-PSSession -ComputerName 192.168.3.99 -Credential $cred -Authentication Basic -Port 5985 работает при отключении allowunencrypted на стороне сервера и клиента \nwinrs -r:http://192.168.3.100:5985/wsman -u:WinRM-Writer -p:123098 ipconfig передать команду через winrs (-?) \nwinrs -r:https://192.168.3.100:5985/wsman -u:WinRM-Writer -p:123098 -ssl ipconfig через https \npwsh -Command \"Install-Module -Name PSWSMan\" установить модуль для использования в Linux системе\n\nKerberos\n.\\CheckMaxTokenSize.ps1 -Principals login -OSEmulation $true -Details $true узнать размер токена пользователя в домене \nGet-ItemProperty -Path HKLM:\\SYSTEM\\CurrentControlSet\\Control\\Lsa\\Kerberos\\Parameters | select maxtokensize максимальный размер токена на сервере \nHKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\services\\HTTP\\Parameters изменить размера, если заголовок пакета аутентификации превышает 16 Кб (из за большого кол-ва групп) \nMaxFieldLength увеличить до 0000ffff (65535) \nMaxRequestBytes увеличить до 0000ffff (65535)\n\nPackageManagement\nImport-Module PackageManagement импортировать модуль \nGet-Module PackageManagement информация о модуле \nGet-Command -Module PackageManagement отобразить все командлеты модуля \nGet-Package отобразить все установленные пакеты PowerShellGallery \nGet-Package -ProviderName msi,Programs список установленных программ\n[Net.ServicePointManager]::SecurityProtocol = [Net.SecurityProtocolType]::Tls12 включить использование протокол TLS 1.2 (если не отключены протоколы TLS 1.0 и 1.1) \nGet-PackageSource источники установки пакетов \nGet-PackageProvider отобразить список провайдеров менеджеров пакетов \nGet-PackageProvider | Where-Object Name -Match nuget \nFind-PackageProvider отображение всех доступных менеджеров пакетов \nFind-PackageProvider nuget \nInstall-PackageProvider NuGet -Force установить менеджер пакетов nuget \nInstall-PackageProvider PSGallery -Force установить источник \nInstall-PackageProvider Chocolatey -Force \nSet-PackageSource nuget -Trusted разрешить установку пакетов из указанного источника \nRegister-PSRepository -Name \"NuGet\" -SourceLocation \"https://www.nuget.org/api/v2\" -InstallationPolicy Trusted зарегестрировать менеджер пакетов используя url (работает для Power Shell Core) \nSet-PackageSource -Name NuGet -Trusted изменить источник по умолчанию \nFind-Package PSEverything поиск пакетов по имени во всех менеджерах \nFind-Package PSEverything -Provider NuGet поиск пакета у выбранного провайдера \nInstall-Module PSEverything -Scope CurrentUser установить модуль для текущего пользователя \nInstall-Package -Name VeeamLogParser -ProviderName PSGallery -scope CurrentUser \nGet-Command *Veeam* \nImport-Module -Name VeeamLogParser загрузить модуль \nGet-Module VeeamLogParser | select -ExpandProperty ExportedCommands отобразить список функций\n\nwinget\nИсходный код\nwinget list список установленных пакетов \nwinget search VLC найти пакет \nwinget show VideoLAN.VLC информация о пакете \nwinget show VideoLAN.VLC --versions список доступных версий в репозитории \nwinget install VideoLAN.VLC установить пакет \nwinget uninstall VideoLAN.VLC удалить пакет \nwinget download jqlang.jq загрузкить пакет (https://github.com/jqlang/jq/releases/download/jq-1.7/jq-windows-amd64.exe) \nwinget install jqlang.jq добавляет в переменную среду и псевдоним командной строки jq \nwinget uninstall jqlang.jq\n\njqlang\n\n\nScoop\nSet-ExecutionPolicy RemoteSigned -Scope CurrentUser \nirm get.scoop.sh | iex установка \nscoop help \nscoop search jq \nscoop info jq \n(scoop info jq).version \nscoop cat jq \nscoop download jq C:\\Users\\lifailon\\scoop\\cache \nscoop install jq C:\\Users\\lifailon\\scoop\\apps\\jq\\1.7 \nscoop list \n(scoop list).version \nscoop uninstall jq\n\nChocolatey\n\nchoco -v \nchoco -help \nchoco list \nchoco install adobereader\n\nNuGet\nInvoke-RestMethod https://dist.nuget.org/win-x86-commandline/latest/nuget.exe -OutFile \"$home\\Documents\\nuget.exe\" \nInvoke-Expression \"$home\\Documents\\nuget.exe search Selenium.WebDriver\" \nInvoke-Expression \"$home\\Documents\\nuget.exe install Selenium.WebDriver\" \nGet-Item $home\\Documents\\*Selenium*\n&amp; \"$home\\Documents\\nuget.exe\" list console-translate \n$nuget_api_key = \"&lt;API-KEY&gt;\" \n$source = \"https://api.nuget.org/v3/index.json\" \n$Name = \"Console-Translate\" \n$path = \"$home\\Documents\\$Name\" \nNew-Item -Type Directory $path \nCopy-Item \"$home\\Documents\\Git\\$Name\\$Name\\0.2\\*\" \"$path\\\" \nCopy-Item \"$home\\Documents\\Git\\$Name\\LICENSE\" \"$path\\\" \nCopy-Item \"$home\\Documents\\Git\\$Name\\README.md\" \"$path\\\"\n\nSet-Location $path \n&amp; \"$home\\Documents\\nuget.exe\" pack \"$path\\$Name.nuspec\" \n&amp; \"$home\\Documents\\nuget.exe\" push \"$path\\$Name.0.2.2.nupkg\" -ApiKey $nuget_api_key -Source $source \n&amp; \"$home\\Documents\\nuget.exe\" push \"$path\\$Name.0.2.2.nupkg\" -ApiKey $nuget_api_key -Source $source -SkipDuplicate\nInstall-Package Console-Translate -Source nuget.org \nGet-Package Console-Translate | select *\nRegister-PSRepository -Name \"NuGet\" -SourceLocation \"https://www.nuget.org/api/v2\" -InstallationPolicy Trusted \nGet-PSRepository \nFind-Module -Name Console-Translate \nInstall-Module Console-Translate -Repository NuGet\n&amp; \"$home\\Documents\\nuget.exe\" delete Console-Translate 0.2.0 -Source https://api.nuget.org/v3/index.json -ApiKey $nuget_api_key -NoPrompt\n\nModules\n\nGet-Query\nInstall-Module Get-Query -Repository NuGet установить модуль \nGet-Help Get-Query \nGet-Query localhost отобразить всех авторизованных пользователей, их статус и время работы (по умолчанию localhost) \nGet-Query 192.168.1.1.1 -proc список всех пользовательских процессов (по умолчанию -user *) \nGet-Query 192.168.1.1.1 -proc -user username список процессов указанного пользователя\n\nConsole-Translate\nInstall-Module Console-Translate -Repository NuGet \nGet-Translate \"Module for text translation\" \nGet-Translate \"Модуль для перевода текста\" \nGet-Translate \"Привет world\" -LanguageSelected т.к. больше латинских символов (на 1), то перевод будет произведен на английский язык \nGet-Translate \"Hello друг\" -LanguageSelected перевод на русский язык \nGet-Translate -Text \"Модуль для перевода текста\" -LanguageSource ru -LanguageTarget tr \nGet-Translate -Provider MyMemory -Text \"Hello World\" -Alternatives выбрать провайдер перевода и добавить альтернативные варианты вывода \nGet-DeepLX \"Get select\" ru \nStart-DeepLX -Job запустить сервер в режиме процесса \nStart-DeepLX -Status \nGet-DeepLX -Server 192.168.3.99 -Text \"Module for text translation\" ru \nStop-DeepLX \nGet-LanguageCode получение кодов языков по стандарту ISO-639-1\n\nConsole-Download\nInstall-Module Console-Download -Repository NuGet устаовить модуль из менеджера пакетов NuGet \nInvoke-Expression $(Invoke-RestMethod \"https://raw.githubusercontent.com/Lifailon/Console-Download/rsa/module/Console-Download/Console-Download.psm1\") или импортировать модуль из GitHub репозитория в текущую сессию PowerShell \nInvoke-Download -Url \"https://github.com/PowerShell/PowerShell/releases/download/v7.4.2/PowerShell-7.4.2-win-x64.zip\" загрузить файл в один поток с отображением скорости загрузки в реальном времен (путь загрузки файла по умолчанию: $home\\downloads) \nInvoke-Download -Url \"https://github.com/PowerShell/PowerShell/releases/download/v7.4.2/PowerShell-7.4.2-win-x64.zip\" -Thread 3 загрузить один и тотже файл в 3 потока (создается 3 файла, доступно от 1 до 20 потоков)\n\n$urls = Get-Content \"$home\\Desktop\\links.txt\" \nInvoke-Download $urls передайте список URL-адресов из файла для загрузки файлов, эквивалентному числу url\n$urls = Get-LookingGlassList отобразить актуальный список конечных точек Looking Glass через Looking.House (выдает 3 ссылки на загрузку файлов по 10, 100 и 1000 мбайт для каждого региона) \n$usaNy = $urls | Where-Object region -like *USA*New*York* отфильтровать список по региону и городу \n$url = $usaNy[0].url100mb забрать первую ссылку с файлов на 100 МБайт \nInvoke-Download $url начать загрузку файла \nInvoke-Download $url -Thread 3 начать загрузку 3-х одинаковых файлов\n\nPSEverything\nInstall-Module PSEverything -Repository NuGet \nFind-Everything pingui найти все файлы в системе (на всех локальных дисках) с именем pingui через dll csharp версии Everything (по умолчанию) \nFind-Everything pingui-0.1.py | Format-List \nFind-Everything pingui -es использовать cli версию Everything для поиска (при первом использовании версии, необходимо дождаться автоматической установки файлов зависимостей) \nFind-Everything pingui-0.1 -ComputerName localhost поиск на удаленном компьютере через REST API, если запущен HTTP-сервер Everything\n\nHardwareMonitor\nInstall-Module HardwareMonitor -Repository NuGet -Scope AllUsers \nInstall-LibreHardwareMonitor установить и запустить LibreHardwareMonitor в систему (https://github.com/LibreHardwareMonitor/LibreHardwareMonitor) \nInstall-OpenHardwareMonitor установить OpenHardwareMonitor (https://github.com/openhardwaremonitor/openhardwaremonitor) \nGet-Sensor | Where-Object {($_.SensorName -match \"Temperature\") -or ($_.SensorType -match \"Temperature\")} | Format-Table использовать LibreHardwareMonitor и WMI/CIM (по умолчанию) и отфильтровать вывод по наименованию датчикам или типу сенсора для вывода датчиков температуры \nGet-Sensor -Open использовать OpenHardwareMonitor \nGet-Sensor -ComputerName 192.168.3.99 -Port 8086 | Format-Table вывести датчики системы через REST API \nGet-Sensor -ComputerName 192.168.3.99 -Port 8085 -User hardware -Password monitor | Where-Object Value -notmatch \"^0,0\" | Format-Table использовать авторизацию и отфильтровать вывод не пустых датчиков \nGet-Sensor -Library | Where-Object Value -ne 0 | Format-Table использовать динамическую библиотеку (dll) через .NET\n\nCrystalDisk-Cli\nInstall-Module CrystalDisk-Cli -Repository NuGet \nGet-DiskInfoSettings отобразить настройки программы Crystal-DiskInfo (https://github.com/hiyohiyo/CrystalDiskInfo) \nGet-DiskInfoSettings -AutoRefresh 5 изминить время сканирования на 5 минут \nGet-DiskInfo -List отобразить список дисков \nGet-DiskInfo получить результаты последнего сканирования (статус, температура и т.п.) \nGet-DiskInfo -Report | Select-Object Name,Date,HealthStatus,Temperature получить актуальный отчет (запустить сканирование и дождаться результатов)\n\nPS-Pi-Hole\n\nsudo cat /etc/pihole/setupVars.conf | grep WEBPASSWORD получить токен доступа \n$Server = \"192.168.1.253\" \n$Token = \"5af9bd44aebce0af6206fc8ad4c3750b6bf2dd38fa59bba84ea9570e16a05d0f\" \nInvoke-Pi-Hole -Versions -Server $Server -Token $Token получить текущую версию ядра (backend) и веб (frontend) на сервере а также последнюю доступную версию для обновления \nInvoke-Pi-Hole -Releases -Server $Server -Token $Token узнать последнюю доступную версию в репозитории на GitHub \nInvoke-Pi-Hole -QueryLog -Server $Server -Token $Token отобразить полный журнал запросов (клиент, домен назначения, тип записи, статус время запроса и адрес пересылки forward dns - куда ушел запрос) \nInvoke-Pi-Hole -AdList -Server $Server -Token $Token получить списки блокировак используемых на сервере (дата обновления, количество доменов и url-источника) \nInvoke-Pi-Hole -Status -Server $Server -Token $Token статус работы режима блокировки \nInvoke-Pi-Hole -Enable -Server $Server -Token $Token включить блокировку \nInvoke-Pi-Hole -Disable -Server $Server -Token $Token отключить блокировку \nInvoke-Pi-Hole -Stats -Server $Server -Token $Token подключиться к серверу Pi-Hole для получения статистики (метрики: количество доменов для блокировки, количество запросов и блокировок за сегодня и т.д.) \nInvoke-Pi-Hole -QueryTypes -Server $Server -Token $Token статистика запросов по типу записей относительно 100% \nInvoke-Pi-Hole -TopClient -Server $Server -Token $Token список самых активных клиентов (ip/name и количество запросов проходящих через сервер) \nInvoke-Pi-Hole -TopPermittedDomains -Count 100 -Server $Server -Token $Token список самых посещяемых доменов и количество запросов \nInvoke-Pi-Hole -LastBlockedDomain -Server $Server -Token $Token адрес последнего заблокированного домена \nInvoke-Pi-Hole -ForwardServer -Server $Server -Token $Token список серверов для пересылки, которым обычно выступает DNS-сервер стоящий за Pi-Hole в локальной сети, например AD \nInvoke-Pi-Hole -Data -Server $Server -Token $Token количество запросов за каждые 10 минут в течение последних 24 часов\n\nCheck-Host\n\nInstall-Module CheckHost установить модуль работы с Check-Host (https://check-host.net) через api \nGet-CheckHost -List список хостов (node) разных регионов (40) \nGet-CheckHost -Server google.com -Type ping -Count 5 использовать 5 любых хостов для 4 пингов с каждого до указанного url (google) \nGet-CheckHost -Server google.com -Type dns -Count 5 проверить DNS (возвращает А-запись или диапазон с ip-адресом) \nGet-CheckHost -Server google.com:443 -Type http -Count 5 проверить доступность порта \nGet-CheckHost -Server google.com:443 -Type tcp -Count 5 проверить доступность TCP или UDP порта\n\nPSDomainTest\nInstall-Module PSDomainTest -Repository NuGet -Scope CurrentUser \nGet-DomainTest -Domain github.com -Warning протестировать домен и DNS записи на ошибки (вывести только ошибки) через ZoneMaster (https://github.com/zonemaster/zonemaster) \nGet-DomainTest -Domain github.com -Warning -json вывод в формате json \nGet-DomainTest -Domain github.com -html | Out-File .\\result.html получить отчет в формате HTML-таблицы с фильтрацией по столбцам\n\nWinAPI\nInstall-Module ps.win.api -Repository NuGet -AllowClobber \nImport-Module ps.win.api \nGet-Command -Module ps.win.api \nStart-WinAPI запустить сервер \nTest-WinAPI статус сервера \nStop-WinAPI остановить сервер \nRead-WinAPI отобразить лог в реальном времени \nGet-Hardware вывести сводную информацию о системе с использованием потоков (фоновых заданий) \nGet-DiskPhysical отобразить список физических дисков, их размер, интерфейс и статус \nGet-DiskPhysical -ComputerName 192.168.3.100 -Port 8443 -User rest -Pass api получить информацию с удаленного сервер, на котором запущен сервер WinAPI (доступно для всех функций модуля) \nGet-DiskLogical список логических дисков (включая виртуальные диски), их файловая система, общий и используемый размер в гб и процентах \nGet-DiskPartition список разделов физических дисков (отобразит скрытые разделы, загрузочный и порядок назначения байт) \nGet-Smart статус работы всех дисков и текущая температура \nGet-IOps количество операций ввода/вывода дисковой подсистемы \nGet-Files подробная информация о файлах (добавляет дату создания, изменения, доступа, количество дочерних файлов и директорий) \nFind-Process поиск пути к исполняемому файлу по имени остановленного (не запущенного) процесса в директориях \nGet-ProcessPerformance информация о процессах (Get-Process) в человеко-читаемом формате \nGet-CPU список все ядер и нагрузка на каждое ядро и на все сразу (суммарное процессорное время, привилегированное и пользовательское время процессора) \nGet-MemorySize размер оперативной, виртуальной памяти, суммарное потребление памяти процессов и путь к файлу подкачки \nGet-MemorySlots список всех слотов оперативной памяти \nGet-NetInterfaceStat статистика активного сетевого интерфейса за время с момента загрузки системы (количество пакетов и ГБ) \nGet-NetInterfaceStat -Current текущая статистика активного сетевого интерфейса (количество пакетов и МБ/c) \nGet-NetIpConfig конфигурация всех сетевых интерфейсов (ip и mac-адрес, статус DHCP сервера, дата аренды) \nGet-NetStat развернутая статистика сетевых интерфейсов (из Get-NetTCPConnection), добавляет имя процесса, имя удаленного хоста (через nslookup), время работы процесса (не процессорное время) и путь к исполняемому файлу \nGet-Performance информация из счетчиков (Get-Counter) человеко-читаемом формате \nGet-VideoCard информация о всех видео-картах (наименование, частота и объем видео-памяти) \nGet-Software список установленного програмного обеспечения \nGet-WinUpdate список обновлений Windows (дата установки и источник) \nGet-Driver список установленных драйверов (имя, провайдер, версия и дата установки)\n\npSyslog\nInstall-Module pSyslog -Repository NuGet \nStart-pSyslog -Port 514 запустить сервер на порту 514 (по умолчанию) \nStart-pSyslog -RotationSize 500 указать размер файла локального журнала для его ротации (обрезания) в КБ \nGet-pSyslog -Status | Format-List отобразить статус работы \nGet-pSyslog вывести журнал сообщений в реальном времени \nStop-pSyslog остановить сервер \nSend-pSyslog -Content \"Test\" -Server 192.168.3.99 отправить сообщение на Syslog-сервер \nSend-pSyslog -Content \"Test\" -Server 192.168.3.99 -Type Informational -PortServer 514 -PortClient 55514 \n(Get-Service -Name WinRM).Status | Send-pSyslog -Server 192.168.3.102 -Tag Service[WinRM] \nSend-pSyslog -Content \"test\" -Server 192.168.3.99 -PortServer 514 -Base64 использовать шифрование при отправки сообщения (расшифровка работает только для сервера pSyslog) \nStart-UDPRelay -inPort 515 -outIP 192.168.3.102 -outPort 514 запустить сервер в режиме UDP-Relay, который слушает на порту 515 и переадресует сообщения на Syslog сервер 192.168.3.102 с портом 514 \nSend-pSyslog -Server 192.168.3.99 -PortServer 515 -Content $(Get-Date) отправить сообщение на сервере UDP-Relay \nShow-pSyslog -Type Warning -Count отобразить метрики (количество ошибок) \nShow-pSyslog -Type Alert -Count \nShow-pSyslog -Type Critical -Count \nShow-pSyslog -Type Error -Count \nShow-pSyslog -Type Emergency -Count \nShow-pSyslog -Type Informational -Count \nShow-pSyslog -LogFile 05-06 | Out-GridView прочитать локальный журнал логирования и вывести в GridView для фильтрации сообщений \nShow-pSyslog -Count отобразить количество сообщений локального журнала \nShow-pSyslog -Count -LogFile 10-06 выбрать журнал по дате\n\nSyslog source message\n\n\nSyslog type message\n\n\nAtlassian\n\nBitbucket\n\nImport-Module PSBitBucket \nGet-Command -Module PSBitBucket \nSet-BitBucketConfigServer -Url $url -User username -Password password установить конфигурацию сервера BitBucket \nGet-BitBucketConfigServer получить текущую конфигурацию сервера BitBucket \nGet-Repositories получить список всех репозиториев для текущей конфигурации сервера BitBucket \nGet-ProjectKey получить ключ проекта BitBucket \nGet-BranchList -Repository pSyslog список всех веток в репозитории \nGet-Branch -Repository pSyslog -Branch main получить информацию о конкретной ветке репозитория \nGet-CommitMessage -Repository pSyslog -CommitHash $hash получить сообщение коммита по его хэшу \nGet-Commits -Repository pSyslog -Limit 10 список последних 10 коммитов в репозитории \nGet-CommitsForBranch -Repository pSyslog -Branch main список коммитов для конкретной ветки в репозитории\n\nJira\nInstall-Module JiraPS -Scope CurrentUser -Repository PSGallery -AllowClobber -Force \nGet-Command -Module JiraPS \nGet-JiraServerInfo информация о сервере \nAdd-JiraFilterPermission добавить разрешения для фильтра \nAdd-JiraGroupMember добавить участника в группу \nAdd-JiraIssueAttachment добавить вложения к задаче \nAdd-JiraIssueComment добавить комментария к задаче \nAdd-JiraIssueLink добавить ссылки на задачу \nAdd-JiraIssueWatcher добавить наблюдателя к задаче \nAdd-JiraIssueWorklog добавить рабочего журнала к задаче \nFind-JiraFilter поиск фильтра \nFormat-Jira форматирование данных Jira \nGet-JiraComponent получение компонента проекта \nGet-JiraConfigServer получение конфигурации сервера Jira \nGet-JiraField получение поля Jira \nGet-JiraFilter получение фильтра \nGet-JiraFilterPermission получение разрешения фильтра \nGet-JiraGroup получение группы \nGet-JiraGroupMember получение участников группы \nGet-JiraIssue получение задачи \nGet-JiraIssueAttachment получение вложения задачи \nGet-JiraIssueAttachmentFile получение файла вложения задачи \nGet-JiraIssueComment получение комментария задачи \nGet-JiraIssueCreateMetadata получение метаданных создания задачи \nGet-JiraIssueEditMetadata получение метаданных редактирования задачи \nGet-JiraIssueLink получение ссылки задачи \nGet-JiraIssueLinkType получение типа ссылки задачи \nGet-JiraIssueType получение типа задачи \nGet-JiraIssueWatcher получение наблюдателя задачи \nGet-JiraIssueWorklog получение рабочего журнала задачи \nGet-JiraPriority получение приоритета задачи \nGet-JiraProject получение проекта \nGet-JiraRemoteLink получение удаленной ссылки \nGet-JiraServerInformation получение информации о сервере Jira \nGet-JiraSession получение сессии \nGet-JiraUser получение пользователя \nGet-JiraVersion получение версии проекта \nInvoke-JiraIssueTransition выполнение перехода задачи \nInvoke-JiraMethod выполнение метода Jira \nMove-JiraVersion перемещение версии проекта \nNew-JiraFilter создание нового фильтра \nNew-JiraGroup создание новой группы \nNew-JiraIssue создание новой задачи \nNew-JiraSession создание новой сессии \nNew-JiraUser создание нового пользователя \nNew-JiraVersion создание новой версии проекта \nRemove-JiraFilter удаление фильтра \nRemove-JiraFilterPermission удаление разрешения фильтра \nRemove-JiraGroup удаление группы \nRemove-JiraGroupMember удаление участника группы \nRemove-JiraIssue удаление задачи \nRemove-JiraIssueAttachment удаление вложения задачи \nRemove-JiraIssueLink удаление ссылки задачи \nRemove-JiraIssueWatcher удаление наблюдателя задачи \nRemove-JiraRemoteLink удаление удаленной ссылки \nRemove-JiraSession удаление сессии \nRemove-JiraUser удаление пользователя \nRemove-JiraVersion удаление версии проекта \nSet-JiraConfigServer установка конфигурации сервера Jira \nSet-JiraFilter установка фильтра \nSet-JiraIssue установка задачи \nSet-JiraIssueLabel установка метки задачи \nSet-JiraUser установка пользователя \nSet-JiraVersion установка версии проекта\n\nConfluence\nInstall-Module ConfluencePS -Scope CurrentUser -Repository PSGallery -AllowClobber -Force \nGet-Command -Module ConfluencePS \nAdd-ConfluenceAttachment добавить вложения к странице \nAdd-ConfluenceLabel добавить метки к странице \nConvertTo-ConfluenceStorageFormat конвертация содержимого в формат хранения Confluence \nConvertTo-ConfluenceTable конвертация данных в таблицу Confluence \nGet-ConfluenceAttachment получение вложения страницы \nGet-ConfluenceAttachmentFile получение файла вложения страницы \nGet-ConfluenceChildPage получение дочерних страниц \nGet-ConfluenceLabel получение меток страницы \nGet-ConfluencePage получение информации о странице \nGet-ConfluenceSpace получение информации о пространстве \nInvoke-ConfluenceMethod выполнение метода Confluence \nNew-ConfluencePage создание новой страницы \nNew-ConfluenceSpace создание нового пространства \nRemove-ConfluenceAttachment удаление вложения страницы \nRemove-ConfluenceLabel удаление метки со страницы \nRemove-ConfluencePage удаление страницы \nRemove-ConfluenceSpace удаление пространства \nSet-ConfluenceAttachment установка вложения страницы \nSet-ConfluenceInfo установка информации о странице \nSet-ConfluenceLabel установка метки страницы \nSet-ConfluencePage установка страницы\n\nPester\nИсходный код\nInstall-Module -Name Pester -Repository PSGallery -Force -AllowClobber \nImport-Module Pester \n$(Get-Module Pester -ListAvailable).Version\n.Tests.ps1\n\n\nDSC\nImport-Module PSDesiredStateConfiguration \nGet-Command -Module PSDesiredStateConfiguration \n(Get-Module PSDesiredStateConfiguration).ExportedCommands \nGet-DscLocalConfigurationManager\nGet-DscResource \nGet-DscResource -Name File -Syntax синтаксис\nEnsure = Present настройка должна быть включена (каталог должен присутствовать, процесс должен быть запущен, если нет – создать, запустить) \nEnsure = Absent настройка должна быть выключена (каталога быть не должно, процесс не должен быть запущен, если нет – удалить, остановить)\n\n$Path = (DSConfigurationProxy).DirectoryName \nTest-DscConfiguration -Path $Path | select * ResourcesInDesiredState - уже настроено, ResourcesNotInDesiredState - не настроено (не соответствует) \nStart-DscConfiguration -Path $Path \nGet-Job \n$srv = \"vproxy-01\" \nGet-Service -ComputerName $srv | ? name -match w32time # Start-Service \nicm $srv {Get-Process | ? ProcessName -match calc} | ft # Stop-Process -Force \nicm $srv {ls C:\\ | ? name -match Temp} | ft rm`\n\n$Path = (InstallPowerShellCore).DirectoryName \nTest-DscConfiguration -Path $Path \nStart-DscConfiguration -Path $path -Wait -Verbose \nGet-Job\n\nPSAppDeployToolkit\n\nInstall-DeployToolkit\n\n\nDeploy-Notepad-Plus-Plus\n$url_notepad = \"https://github.com/notepad-plus-plus/notepad-plus-plus/releases/download/v8.6.6/npp.8.6.6.Installer.x64.exe\" \nInvoke-RestMethod $url_notepad -OutFile \"$home\\Downloads\\PSAppDeployToolkit\\Toolkit\\Files\\npp.8.6.6.Installer.x64.exe\"\n\npowershell -File \"$home\\Downloads\\PSAppDeployToolkit\\Toolkit\\Deploy-Application.ps1\"\n\nUninstall-Notepad-Plus-Plus\n\npowershell -File \"$home\\Downloads\\PSAppDeployToolkit\\Toolkit\\Deploy-Application.ps1\"\n\nDeploy-WinSCP\n\n\nLoad Testing\n\nwrk\n\n\nApache Benchmark\n\n$ab = \"$HOME\\Documents\\apache\\ab.exe\" \n. $ab -n 10000 -c 100 http://192.168.3.100:8444/api/provider/list\n\n\nLocust\nLocust - это инструмент нагрузочного тестирования для HTTP и других протоколов на Python.\npip3 install locust\n\nlocust -f locustfile.py --host http://192.168.3.100:8444 \n$env:QUERY = \"The+Rookie\" определяем переменную окружения для параметра запросов \nlocust -f locustfile.py --host http://192.168.3.100:8444 -u 10 -r 2 -t 30s количество виртуальных пользователей (VU), частота появления новых пользователей в секунду (10 пользователей будут созданы за 5 секунд) и длительность 30 секунд \nlocust -f locustfile.py --host http://192.168.3.100:8444 -u 10 -r 2 -t 30s --headless --csv locustresult запуск без веб-интерфейса с выгрузкой результатов в csv файлы\nЗапуск Web-интерфейса в контейнере Docker:\nmkdir locust &amp;&amp; cd locust\n\nsudo docker build -t locust-alpine-web . &amp;&amp; sudo docker run -d --name locust -p 8089:8089 --restart=unless-stopped locust-alpine-web\n\nLLM\n\nOpenAI\nПример запроса для перевода текста\n\n\nMock\nСоздаем серверную заглушку для API OpenAI через JSON Server\nnpm install -g json-server@0.17.4\nКонфигурация ответов в файле openai.json\n\nНастройка маршрутизации в файле routes.json\n\nКонфигурация сервера в файле json-server.json\n\nЗапускаем сервер:\njson-server --watch openai.json --routes routes.json\nДелаем запрос:\n$(Invoke-RestMethod -Uri \"http://localhost:3001/v1/chat/completions\").choices.message.content\n\nOpenRouter\nРегестрируем аккаунт на OpenRouter через Google, выпускаем api ключ и выбираем бесплатную модель.\n\n\nLM Studio\nAPI в LM Studio совместим с OpenAI\nПолучить список моделей:\n\nРежим чата (когда stream установлен в True, ответ приходит по частям):\n\n\nOllama\n\n.\\ollama serve запускаем сервер \n.\\ollama pull mistral:7b-instruct загружаем модель (https://ollama.com/library/mistral) \n.\\ollama run mistral запустить консоль для общения с LLM в режиме чата\n\n\nGigaChat\n\nWindows\nDevelopers chat\n\nУстановка сертификатов:\n\nInvoke-WebRequest \"https://gu-st.ru/content/lending/russian_trusted_root_ca_pem.crt\" -OutFile \"$home\\Downloads\\russian_trusted_root_ca.cer\" скачать сертификат минцифры \nInvoke-WebRequest \"https://gu-st.ru/content/lending/russian_trusted_sub_ca_pem.crt\" -OutFile \"$home\\Downloads\\russian_trusted_sub_ca.cer\" \nImport-Certificate -FilePath \"$home\\Downloads\\russian_trusted_root_ca.cer\" -CertStoreLocation \"Cert:\\CurrentUser\\Root\" установить сертификат минцифры \nImport-Certificate -FilePath \"$home\\Downloads\\russian_trusted_sub_ca.cer\" -CertStoreLocation \"Cert:\\CurrentUser\\CA\"\n\n\n\nАвторизация по Sber ID и генерация новых авторизационных данных для получения токена: Developers (время жизни 30 минут)\n\n\n\n\nФормирование авторизационных данных в формате Base64 из Client ID и Client Secret:\n\n\n\n\n\n\n\nПолучение токена:\n\n\n\n$Cred_Base64   = \"N2U2ZDJmOWYtODI1ZS00OWI3LTk4ZjQtNjJmYmI3NTA2NDI3OmIyYzgwZmZmLTEzOGUtNDg1Mi05MjgwLWE2MGI4NTc0YTM2MQ==\" \n$UUID = [System.Guid]::NewGuid() генерируем UUID для журналирования входящих вызовов и разбора инцидентов\n\n\n\n\nПараметры:\n\n\n\n\n\n\n\nСоставление запросов:\n\n\n\n\n\nLinux\n\nУстановка сертификатов в Ubuntu:\n\nwget https://gu-st.ru/content/lending/russian_trusted_root_ca_pem.crt \nwget https://gu-st.ru/content/lending/russian_trusted_sub_ca_pem.crt \nmkdir /usr/local/share/ca-certificates/russian_trusted \ncp russian_trusted_root_ca_pem.crt russian_trusted_sub_ca_pem.crt /usr/local/share/ca-certificates/russian_trusted \nupdate-ca-certificates -v \nwget -qS --spider --max-redirect=0 https://www.sberbank.ru\n\nПолучение токена:\n\n\ncurl -s --location \"https://gigachat.devices.sberbank.ru/api/v1/models\" --header \"Authorization: Bearer $GIGA_TOKEN\" | jq . для проверки\n\nСоставление запроса:\n\n\n\nYandexGPT\n\nПолучить OAuth-Token:\n\nCreate AIM Token время жизни IAM-токена не больше 12 часов \nyandexPassportOauthToken=\"y0_AgAAAAAGaLFLAATuwQAAAAD3xtRLQE4hvlazQ5euKO43XXXXXXXXXXX\" для bash \n$yandexPassportOauthToken = \"y0_AgAAAAAGaLFLAATuwQAAAAD3xtRLQE4hvlazQ5euKO43XXXXXXXXXXX\" для PowerShell\n\nОбменять OAuth-Token на IAM-Token:\n\nIAM_TOKEN=$(curl -s -d \"{\\\"yandexPassportOauthToken\\\":\\\"$yandexPassportOauthToken\\\"}\" \"https://iam.api.cloud.yandex.net/iam/v1/tokens\" | jq -r .iamToken) \n$IAM_TOKEN = $(Invoke-RestMethod -Method POST -Uri \"https://iam.api.cloud.yandex.net/iam/v1/tokens\" -Body $(@{yandexPassportOauthToken = \"$yandexPassportOauthToken\"} | ConvertTo-Json -Compress)).iamToken\n\nПолучить FOLDER_ID:\n\n\n\n\nСоставление запроса:\n\n\n\n\nSuperAGI\nИсходный код\nPlayground generate\nAPI документация\n\n\n\nReplicate\nAPI curl examples\n\n\n\nGoogle API\n\nGoogle Translate\n\n\nGoogle Search\n\n\nGoogle Search via RapidAPI\nGoogle-Search72\n\n\nGoogle Filter\nhttps://www.google.com/search?q=the+rookie+2018+imdb формат url-запроса поиска с пробелами \nhttps://www.google.com/search?q=the+rookie+2018+site:imdb.com поиск по сайту \nhttps://www.google.com/search?q=the+rookie+intitle:index.of+\"last modified\"+(mkv|avi) искать страницы, на которых указано “last modified” (последние изменения), заголовок страницы через расширенный оператор поиска (все перечисленные слова должны встречаться в заголовке) содержит слово “index.of” (указывает на директорию на веб-сервере, которая содержит список файлов) и искать файлы с расширениями .mkv или (|) .avi \nhttps://www.google.com/search?q=the+rookie+2018+filetype:torrent \nинструкция gopro hero 11 filetype:pdf искать сразу документ (на странице .pdf или загрузка) \n\"действия/глаголы, утвержденные для использования в командлетах\" искать по фразе целиком, без разбиения на отдельные слова \n\"ягуар скорость -животное -xe -xj\" узнаем скорость Ягуара, исключаем животное и модели автомобиля \n\"intitle:лучшие фильмы 2023\" запрос ищет страницы, заголовки (title HTML документа) которых содержат слова “лучшие”, “фильмы” и “2023” (все слова должны быть в заголовке) \n\"allintitle:лучшие фильмы 2023\" запрос ищет страницы, заголовки (title HTML документа) которых содержат слова “лучшие”, “фильмы” или “2023” (одно из) \n\"intext:telegram бот powershell\" поиск страниц, содержащих указанное ключевое слово в тексте страницы (а не только в заголовке) \n\"inurl:lifailon\" поиск страниц, в URL которых содержится указанное ключевое слово \nintitle:index.of \"game of thrones\" mkv daterange:2010..2015 фильтрация по дате изменения, оператор позволяет задать диапазон дат в формате YYYYMMDD..YYYYMMDD \nintitle:index.of \"game of thrones\" mkv after:2015 ограничить результаты поиска файлов, измененных до (before) или после (after) указанной даты \nintitle:index.of \"game of thrones\" mkv from:2010 to:2015 фильтрация по диапазону дат \nhttps://www.google.com/search?q=the-rookie-2018+site:imdb.com&amp;btnI редирект на первый url\n\nMedia API\n\nIMDb\nIMDb8\n\n\nMoviesDatabase\nMoviesDatabase\n\n\nTMDB\nDeveloper TMDB\n\n\nOMDb\nПолучение API ключа по email\n$API_KEY = \"XXXXXXXX\" \n$IMDb_ID = \"tt7587890\" \ncurl -s \"https://omdbapi.com/?apikey=$($API_KEY)&amp;i=$($IMDb_ID)\" | jq . \ncurl -s \"https://omdbapi.com/?apikey=$($API_KEY)&amp;i=$($IMDb_ID)\" | ConvertFrom-Json \nInvoke-RestMethod \"https://omdbapi.com/?apikey=$($API_KEY)&amp;s=The Rookie\" \nInvoke-RestMethod \"https://omdbapi.com/?apikey=$($API_KEY)&amp;t=The Rookie\" поиск по Title \nInvoke-RestMethod \"https://omdbapi.com/?apikey=$($API_KEY)&amp;t=The Rookie&amp;y=1990\" поиск по Title и году выхода \nInvoke-RestMethod \"https://omdbapi.com/?apikey=$($API_KEY)&amp;t=The Rookie&amp;type=movie\" поиск только фильма (movie) или сериала (series) \n$(Invoke-RestMethod \"https://omdbapi.com/?apikey=$($API_KEY)&amp;s=The Rookie\").Search поиск всех совпадений (фильмы и сериалы)\n\nivi\nivi api doc\nInvoke-RestMethod https://api.ivi.ru/mobileapi/categories список категорий и жанров (genres/meta_genres) \nInvoke-RestMethod https://api.ivi.ru/mobileapi/collections подборки\n(Invoke-RestMethod \"https://api.ivi.ru/mobileapi/search/v7/?query=zimorodok\").result.seasons.number кол-во сезонов \n(Invoke-RestMethod \"https://api.ivi.ru/mobileapi/search/v7/?query=zimorodok\").result.seasons[1].episode_count кол-во серий во втором сезоне \n(Invoke-RestMethod \"https://api.ivi.ru/mobileapi/search/v7/?query=zimorodok\").result.seasons[1].ivi_release_info.date_interval_min дата выхода следующей серии \n(Invoke-RestMethod \"https://api.ivi.ru/mobileapi/search/v7/?query=zimorodok\").result.kp_rating рейтинг в Кинопоиск (8.04)\n$id = (Invoke-RestMethod \"https://api.ivi.ru/mobileapi/search/v7/?query=zimorodok\").result.kp_id получить id в Кинопоиск (5106881) \nid=$(curl -s https://api.ivi.ru/mobileapi/search/v7/?query=zimorodok | jq .result[].kp_id) получить id в Кинопоиск\n\nKinopoisk\n\n\nkinopoisk.dev\nПолучить токен \nДокументация по API в формате OpenAPI\nGET /v1.4/movie/{id} поиск по id\n\n\nGET /v1.4/movie/search\n\n\n\nUrlCode\n\n\n\n\n\n\nKinopoiskApiUnofficial\nБесплатно 500 запросов в сутки. Swagger documentation\n\ncurl -s \"https://kinopoiskapiunofficial.tech/api/v2.2/films/1142153\" -H \"accept: application/json\" -H \"X-API-KEY: $API_KEY\" | jq .\n\nKinobox\n$url = \"https://www.kinopoisk.ru/film/694051\" \n$kp_id = $url -replace \".+/\" \nhttps://kinomix.web.app/#694051 \ncurl -s -X GET \"https://kinobox.tv/api/players/main?kinopoisk=$kp_id\" -H \"accept: application/json\" поиск по id Кинопоиск \ncurl -s -X GET \"https://kinobox.tv/api/players/main?imdb=tt2293640\" -H \"accept: application/json\" поиск по id IMDb \ncurl -s -X GET \"https://kinobox.tv/api/players/main?title=minions\" -H \"accept: application/json\" поиск основных плееров по названию \ncurl -s -X GET \"https://kinobox.tv/api/players/all?title=minions\" -H \"accept: application/json\" поиск всех плееров \ncurl -s -X GET \"https://kinobox.tv/api/popular/films\" -H \"accept: application/json\" популярные фильмы \ncurl -s -X GET \"https://kinobox.tv/api/popular/series\" -H \"accept: application/json\" популярные сериалы\n\nVideoCDN\nИсходный код\nAPI и API JSON\n\n\n\nTorrent\n\nJackett\nИсходный код\nmkdir /jackett \ndocker-compose.yml\n\ndocker-compose up -d jackett \ndocker exec -it jackett /bin/bash доступ к оболочке во время работы контейнера \ndocker logs -f jackett мониторинг журналов контейнера\n/jackett/data/Jackett/ServerConfig.json место хранения конфигурации сервера \n/jackett/data/Jackett/Indexers/*.json место хранения конфигурации индексаторов\n$API_KEY = \"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\" \nInvoke-RestMethod \"http://127.0.0.1:9117/api/v2.0/indexers/rutor/results/torznab/api?apikey=$API_KEY\" Прочитать RSS ленту RuTor \n$query = \"the+rookie\" \nInvoke-RestMethod \"http://127.0.0.1:9117/api/v2.0/indexers/rutor/results/torznab/api?apikey=$API_KEY&amp;t=search&amp;cat=&amp;q=$query\" поиск в RuTor \nInvoke-RestMethod \"http://127.0.0.1:9117/api/v2.0/indexers/kinozal/results/torznab/api?apikey=$API_KEY&amp;t=search&amp;q=$query\" поиск в кинозал \nInvoke-RestMethod \"http://127.0.0.1:9117/api/v2.0/indexers/kinozal/results/torznab/api?apikey=$API_KEY&amp;t=search&amp;q=$query&amp;cat=5000\" отфильтровать вывод по сериалам (Capabilities: 5000) \nInvoke-RestMethod \"http://127.0.0.1:9117/api/v2.0/indexers/all/results/torznab/api?apikey=$API_KEY&amp;t=search&amp;q=riverdale\" поиск во всех индексаторах \n$(Invoke-RestMethod \"http://127.0.0.1:9117/api/v2.0/indexers/all/results/torznab/api?apikey=$API_KEY&amp;t=indexers&amp;configured=true\").indexers.indexer cписок всех настроенных индексаторов (трекеров)\n\nTorrent-API-py\nИсходный код\nДокументация\n\n$srv = \"http://localhost:8009\" local \n$srv = \"https://torrent-api-py-nx0x.onrender.com\" public \nInvoke-RestMethod $srv/api/v1/sites список доступных трекеров \nInvoke-RestMethod \"$srv/api/v1/search/?site=torlock&amp;query=the+rookie&amp;limit=0&amp;page=1\" поиск в выбранном трекере \nInvoke-RestMethod \"$srv/api/v1/all/search?query=the+rookie&amp;limit=0\" поиск по названию во всех трекерах\n\nPlex\n$API_TOKEN = \"XXXXXXXXXXXXXXXXXXXX\"\n\n$(Invoke-RestMethod -Headers $headers -Uri http://localhost:32400/servers).MediaContainer.Server версия сервера \nInvoke-RestMethod -Headers $headers -Uri http://localhost:32400/diagnostics/logs -OutFile log.zip выгруить лог с сервера \n$(Invoke-RestMethod -Headers $headers -Uri http://localhost:32400/library/sections).MediaContainer.Directory список секций добавленных на сервер \n$section_key = $(Invoke-RestMethod -Headers $headers -Uri http://localhost:32400/library/sections).MediaContainer.Directory.key[0] \nInvoke-RestMethod -Headers $headers -Uri http://localhost:32400/library/sections/$section_key/refresh синхронизация указанной секции в Plex по ключу \n$(Invoke-RestMethod -Headers $headers -Uri http://localhost:32400/library/sections/2/folder).MediaContainer.Metadata получить список директорий и файлов в корне выбранной секции \n$(Invoke-RestMethod -Headers $headers -Uri http://localhost:32400/library/sections/2/folder?parent=204).MediaContainer.Metadata получить список всех файлов в указанной директории через ключ (MediaContainer.Metadata.key) конечной точки\n\nJellyfin\nИсходный код\nAPI документация\n$API_TOKEN \"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\" \nInvoke-RestMethod -Headers @{\"X-Emby-Token\" = $API_TOKEN} http://localhost:8096/Users список пользователей и их id \n$Users = Invoke-RestMethod -Headers @{\"X-Emby-Token\" = $API_TOKEN} http://localhost:8096/Users \n$UserId = $($Users | Where-Object Name -match \"Lifailon\").Id забрать id пользователя \nInvoke-RestMethod -Headers @{\"X-Emby-Token\" = $API_TOKEN} http://localhost:8096/System/Info информация о системе \n$(Invoke-RestMethod -Headers @{\"X-Emby-Token\" = $API_TOKEN} http://localhost:8096/Items).Items список добавленных объектов директорий \n$ItemId = $(Invoke-RestMethod -Headers @{\"X-Emby-Token\" = $API_TOKEN} http://localhost:8096/Items).Items[-1].Id забрать id директории \n$Data = $(Invoke-RestMethod -Headers @{\"X-Emby-Token\" = $API_TOKEN} \"http://localhost:8096/Users/$UserId/Items?ParentId=$ItemId\").Items получить содержимое корневой директории по Id из Items \n$TvId = $($data | Where-Object Name -match \"Rookie\").Id найти сериал или фильм по имени и забрать его Id \n$(Invoke-RestMethod -Headers @{\"X-Emby-Token\" = $API_TOKEN} \"http://localhost:8096/Users/$UserId/Items?ParentId=$TvId\").Items получить содержимое дочерней директории по Id ее родительской директории\n\nTelegram\n@BotFather (https://t.me/BotFather) /newbot\nFormat: https://api.telegram.org/bot&lt;token&gt;/&lt;endpoint&gt;\ngetupdates\n\nGet-FromTelegram \nGet-FromTelegram -Last \nGet-FromTelegram -Date \nGet-FromTelegram -ChatID\nsendmessage\n\nSend-ToTelegram -Text \"Send test from powershell\"\n\n/Service vpnagent \n/Service WinRM \n/Service test\n\nButton\n\n\nSend-ToTelegramFile\nhttps://core.telegram.org/bots/api#senddocument\n\nSend-ToTelegramFile -Path \"C:\\Users\\Lifailon\\Documents\\lake.jpg\" -Token \"7777777777:AAF...\" -Chat \"7777777777\"\n\nDiscord\nDevelopers\nСоздаем Applications (General Information). В Bot привязываем к Application и копируем токен авторизации. В OAuth2 - URL Generator выбираем bot и права Administrator и копируем созданный URL для добавления на канал. Переходим по url и добавляем бота на сервер. Получаем ID канала на сервере (текстовые каналы, правой кнопкой мыши копируем ссылку и забираем последний id в url).\n\nSend to Discord\n\n\n\nRead from Discord\n\n\n\nHttpClient\n\n\nButton\n\n\nDiscord.Net.Webhook\n\n\nDiscord.Net.WebSocket\n\n\noh-my-posh\nInstall\nwinget install JanDeDobbeleer.OhMyPosh -s winget \nchoco install oh-my-posh -y \nscoop install https://github.com/JanDeDobbeleer/oh-my-posh/releases/latest/download/oh-my-posh.json \nSet-ExecutionPolicy Bypass -Scope Process -Force; Invoke-Expression ((New-Object System.Net.WebClient).DownloadString('https://ohmyposh.dev/install.ps1'))\nThemes\nGet-PoshThemes отобразить список всех тем \noh-my-posh init pwsh --config \"$env:POSH_THEMES_PATH/di4am0nd.omp.json\" | Invoke-Expression применить (использовать) тему в текущей сессии \noh-my-posh init pwsh --config \"https://raw.githubusercontent.com/JanDeDobbeleer/oh-my-posh/main/themes/cert.omp.json\" | Invoke-Expression считать тему из репозитория \nNew-Item -Path $PROFILE -Type File -Force создайт файл профилья PowerShell \n'oh-my-posh init pwsh --config \"$env:POSH_THEMES_PATH/di4am0nd.omp.json\" | Invoke-Expression' &gt; $PROFILE сохранить тему профиля (загружать тему при запуске PowerShell)\n\nthemes-performance\nInstall-Module themes-performance -Repository NuGet установить модуль с темами \nSet-PoshTheme -Theme System-Sensors использовать тему с датчиками из LibreHardwareMonitor \nSet-PoshTheme -Theme System-Sensors -Save загрузить тему из репозитория на локальный компьютер и сохранить тему в профиле \nSet-PoshTheme -Theme System-Performance использовать тему с датчиками системы, получаемыми из системы WMI/CIM (заряд батареи ноутбука | загрузка CPU в % | использование оперативной памяти | скорость активного сетевого интерфейса) \nSet-PoshTheme -Theme System-Performance -Save \nSet-PoshTheme -Theme Pwsh-Process-Performance время работы текущего процесса pwsh (процессорное время), количество работающих/общее (статус успех/ошибка) фоновых заданий, Working Set текущего процесса и всех процессов PowerShell в системе \nSet-PoshTheme -Theme Pwsh-Process-Performance -Save\n\nWindows-Terminal\n\nTerminal-Icons\nInstall-Module -Name Terminal-Icons -Repository PSGallery \nscoop bucket add extras \nscoop install terminal-icons\nnotepad $PROFILE \nImport-Module -Name Terminal-Icons\nИспользует шрифты, которые необходимо установить и настроить в параметрах профиля PowerShell: Nerd Fonts \nСписок шрифтов \nСкачать и установить шрифт похожий на Cascadia Code - CaskaydiaCove\nУстановить шрифт в конфигурацию Windows Terminal для PowerShell Core:\n\n\nCustom Actions\nCustom actions: https://learn.microsoft.com/ru-ru/windows/terminal/customize-settings/actions \nEscape-последовательности: https://learn.microsoft.com/ru-ru/cpp/c-language/escape-sequences?view=msvc-170\n\n\nPandoc\n\npandoc -s README.md -o index.html конвертация из Markdown в HTML \npandoc README.md -o index.html --css=styles.css применить стили из css \npandoc -s index.html -o README.md конвертация из HTML в Markdown \npandoc -s README.md -o README.docx конвертация в Word \npandoc -s README.md -o README.epub конвертация в открытый формат электронных версий книг \npandoc -s README.md -o README.pdf конвертация в PDF (требуется rsvg-convert) \npandoc input.md -f markdown+hard_line_breaks -o output.md конвертация из markdown документа, который не содержит обратный слэш в конце каждой строки для переноса (), который их добавит\n\nConvert Excel to Markdown\n\n\nFFmpeg\n\nffmpeg -i input.mp4 output.gif конвертировать mp4 в gif \nffmpeg -i input.mp4 -filter_complex \"scale=1440:-1:flags=lanczos\" output.gif изменить разрешение на выходе \nffmpeg -i input.mp4 -filter_complex \"scale=1440:-1:flags=lanczos\" -r 10 output.gif изменить количество кадров в секунду на выходе \nffmpeg -i input.mp4 -filter_complex \"fps=5,scale=960:-1:flags=lanczos,split[s0][s1];[s0]palettegen=max_colors=32[p];[s1][p]paletteuse=dither=bayer\" output.gif сжатие за счет цветовой политры \nffmpeg -i input.mp4 -ss 00:00:10 -frames:v 1 -q:v 1 output.jpg вытащить скриншот из видео на 10 секунде \nffmpeg -i input.mp4 -ss 00:00:05 -to 00:00:10 -c copy output.mp4 вытащить кусок видео \nffmpeg -i \"%d.jpeg\" -framerate 2 -c:v libx264 -r 30 -pix_fmt yuv420p output.mp4 создать видео из фото (1.jpeg, 2.jpeg и т.д.) с framerate (частотой кадров) в создаваемом видео 2 кадра в секунду \nffmpeg -i \"rtsp://admin:password@192.168.3.201:554\" -rtsp_transport tcp -c:v copy -c:a aac -strict experimental output.mp4 запись без перекодирования (copy) RTSP-потока с камеры видеонаблюдения (+ аудио в кодеке AAC) в файл \nffmpeg -i \"rtsp://admin:password@192.168.3.201:554\" -rtsp_transport tcp -c:v copy -c:a aac -strict experimental -movflags +faststart+frag_keyframe+empty_moov output.mp4 переместить метаданные в начало файла, что позволяет начать воспроизведение файла в видеоплеере до его полной загрузки \nffmpeg -i \"rtsp://admin:password@192.168.3.201:554\" -rtsp_transport tcp -frames:v 1 -c:v mjpeg output.jpg сделать скриншот \nffmpeg -i input.mp4 -vf \"pad=width=iw:height=ih+100:x=0:y=100:color=black\" -c:a copy output.mp4 width=iw: (ширина видео остается как у исходного файла), height=ih+100 (высота видео увеличивается на 100 пикселей), x=0 (горизонтальное смещение установлено в 0), y=100 (вертикальное смещение установлено в 100 пикселей вниз, чтобы добавить черное пространство сверху), color=black (цвет добавленного пространства — черный)\n\nHandBrake\n\nHandBrakeCLI -i input.mp4 -o output.mkv конвертирует видео в формате mp4 в формат mkv с использованием стандартных настроек HandBrake \nHandBrakeCLI -i input.mp4 -o output.mkv -q 20 установить качество видео 20, значения варьируются от 0 (максимальное качество) до 51 (минимальное качество), где 20 считается хорошим качеством для большинства видео \nHandBrakeCLI -i input.mp4 -o output.mkv -r 30 установить частоту кадров на 30 fps \nHandBrakeCLI -i input.mp4 -o output.mkv --maxWidth 1280 --maxHeight 720 изменить размер на 1280х720 \nHandBrakeCLI -i input.mp4 -o output.mkv -b 1500 установить битрейт видео 1500 кбит/с \nHandBrakeCLI -i input.mp4 -o output.mkv -e x264 преобразовать видео с использованием кодека x264 \nHandBrakeCLI -i input.mp4 -o output.mp4 --crop 0:200:0:0 обрезать видео снизу на 200px (верх:низ:лево:право) \nHandBrakeCLI -i input.mp4 -o output.mp4 --start-at duration:5 --stop-at duration:15 обрезать видео (на выходе будет 15-секундное видео с 5 по 20 секунду)\n\nImageMagick\nSource: ImageMagick\nmagick identify -verbose PowerShell-Commands.png извлечь метаданные изображения \nmagick PowerShell-Commands.png output.jpg конвертация формата изображения \nmagick PowerShell-Commands.png -resize 800x600 output.jpg изменить размер (увеличить или уменьшить) \nmagick PowerShell-Commands.png -crop 400x300+100+50 output.jpg обрезать \nmagick PowerShell-Commands.png -rotate 90 output.jpg повернуть изображение \nmagick PowerShell-Commands.png -fill white -pointsize 24 -gravity center -annotate +0+0 \"PowerShell\" output.jpg наложить текст на изображение \nmagick PowerShell-Commands.png -brightness-contrast +20x+10 output.jpg изменить яркость и контрастность \nmagick convert -delay 100 1.png 2.png 3.png output.gif создать gif из изображений \nmagick convert image1.jpg image2.jpg -append output.jpg вертикально объединенить изображения\n\nyt-dlp\n\nyt-dlp -F https://www.youtube.com/watch?v=gxplizjhqiw отобразить список всех доступных форматов \nyt-dlp -J https://www.youtube.com/watch?v=gxplizjhqiw вывести данные в формате JSON \nyt-dlp -J https://www.youtube.com/watch?v=gxplizjhqiw | jq -r .formats.[].format id - resolution (format_note) \nyt-dlp -f 137 https://www.youtube.com/watch?v=gxplizjhqiw загрузить только видео в указанном формате по id \nyt-dlp -f bestaudio https://www.youtube.com/watch?v=gxplizjhqiw загрузить только аудио \nyt-dlp -f best https://www.youtube.com/watch?v=gxplizjhqiw загрузить видео с аудио в лучшем качестве \nyt-dlp -f 'bestvideo[height&lt;=1080]+bestaudio/best[height&lt;=1080]' https://www.youtube.com/watch?v=gxplizjhqiw загрузить в указанном качестве \nyt-dlp -r 2m https://www.youtube.com/watch?v=gxplizjhqiw ограничить скорость загрузки до 2 МБит/с\n\n\nWPF\nДля генеранции форм интерфейса можно использовать Toolbox в PSScriptPad от Ironman или онлайн редактор XAML от OpenSilver.\n\n","path":null},{"url":"https://lifailon.github.io/golang/","title":"GoLang","description":null,"body":"\n    \n\n\n    Вольный и расширенный перевод репозитория Go Cheat Sheet на русский язык.\n\n\n\nДругие ресурсы\nПодборка открытых и бесплатных ресурсов для изучения Go на русском языке:\n\nЭффективный Go - перевод официальной документации Effective Go (не завершен и устарел).\nЭффективный Go - актуальный перевод от сентября 2024 года.\nТур по Go - перевод официального тура по Go (исходный код) на русский язык от 2018 года.\nТур по Go - расширенный тур на русском языке с поддержкой выполнения кода в встроенном Playground.\nGo в примерах - исходный код для сборки Go в примерах на русском языке (перевод от 2015 года, форк репозитория Go by Example).\nВведение в программирование на Go - исходный код для сборки книги (перевод книги An Introduction to Programming in Go) от 2019 года.\nМаленькая книга о Go - перевод от 2022 года репозитория The Little Go Book (исходник от 2015 года).\nПаттерны параллельного программирования Go от 2018 года.\nГайды Uber по написанию кода на Go - перевод оригинального репозитория на русский язык от 2020 года.\nКурс Golang от Хекслет.\nПрактика GO на упражнениях от Schoolsw3.\nРуководство по языку Go от Metanit.\nКурс по изучению Golang для начинающих.\nШпаргалка по Go в переводе с Немецкого языка.\nGUI на Golang на GTK+ 3.\nШпаргалка для собеса по GoLang на Хабр.\n\nБесплатные курсы:\n\nОсновы Go - курс от Яндекс Практикум (2 модуля на 30 часов).\nОсновы Go - курс от Хек Слет (34 урока, 97 тестов и 37 упражнений в тренажере).\nРазработка веб-сервисов на Golang - курс по Go от Mail Ru на платформе Coursera.\nGo на практике - курс от академии Select (8 материалов на 2 часа изучения), включающий в себя разработку REST API и gRPC сервисов.\nПрограммирование на Golang - курсы от Stepik с получением сертификата (35 уроков, 64 теста и 94 задачи).\nPRO Go. Основы программирования - курсы от Stepik с получением сертификата (38 уроков, 121 тестов и 191 задач).\nGo - первое знакомство - курсы от Stepik с получением сертификата (42 урока, 110 тестов и 45 задач).\nТвой Golang - курсы от Stepik с получением сертификата (154 урока, 29 часов видео, 187 тестов и 58 задач).\n\n\nУчастники\nЕсли вы нашли ошибку или хотите расширить список заметок, а также знаете другие источники для изучения, сообщите о них, внеся изменения через Pull Requests.\n\nИсточники\nБольшинство примеров кода исходного репозитория взяты из официального тура по Go, который является прекрасным введением для знакомства с языком.\nВы также можете использовать онлайн компилятор на официальном сайте или развернуть собственную песочницу Better Go Playground для запуска и проверки блоков кода.\n\nОписание языка\n\nИмперативный язык, где описывается последовательность шагов (инструкций), которые необходимо выполнить для достижения результата. В отличии от декларативных языков, где описывается результат, который нужно получить, оставляя процесс выполнения скрытым (например, как в SQL или HTML).\nИспользуется статическая типизация для проверка типов переменных во время компиляции. Это когда тип переменной не может быть изменен после его присвоения (например, как в TypeScript в отличии от JavaScript).\nСинтаксис похож на C (но меньше скобок и нет точек с запятой в конце каждой строки), а структура — на Oberon-2.\nКомпилируется в машинный код без использования промежуточных слоев (Runtime, например, как JVM в Java или .NET в C#), который должен быть установлен на машине для работы программы.\nНет классов, но есть структуры с методами.\nНе предоставляет подклассов, основанного на типах, но имеет возможность заимствовать части реализации, встраивая типы в структуру или интерфейс (embedding).\nФункции могут возвращать несколько значений и их можно присваивать переменным, так как они рассматриваются как объекты.\nФункции можно передавать в другие функции в качестве аргументов, а также функции могут возвращать другие функции как результат.\nИмеет замыкания (closures), которые позволяют функциям хранит и использовать переменные из внешней области видимости, даже если она выполняется в другом контексте (например, за пределами этой области).\nНевозможно напрямую изменять значение указателя с помощью арифметических операций (например, ptr++). Это нужно, чтобы исключить возможные ошибки, такие как выход за пределы памяти или доступ к неправильным участкам памяти.\nВстроенные примитивы параллелизма: горутины и каналы.\nПоддерживаются динамические и статические срезы (slices, аналог списков или массивов в других языках, где элементы хранятся в порядке их добавления и индексируются числами), а также карты (maps, аналог словарей или хэш-таблиц, где содержится уникальный ключ и его значение).\n\n\nПакеты\n\nДекларация пакета (объявление через import) производится в начале каждого исходного файла.\nИсполняемые файлы находятся в пакете main.\nИмя пакета соответствует последнему имени в пути импорта (например, math/rand - пакет rand).\nИдентификатор функции в верхнем регистре является экспортируемый (доступны из других пакетов).\nИдентификатор функции в нижнем регистре является частный (недоступны из других пакетов).\n\n\nПолучение информации о функции\n\n\nИнициализация проекта\n\n\nСтандартный ввод и вывод\n\nВывод в терминал (Print)\nСтандартные методы Print и Println (добавляет символ переноса строки в конец вывода) из пакета fmt используются для вывода содержимое на экран.\n\nЗапуск:\ngo run main.go\nВывод:\n\n\nВвод с клавиатуры (Scan)\nМетод Scan из пакета fmt используются для чтения данных из стандартного ввода. Он считывает значения и записывает их в переменные по указанным адресам (с использованием оператора &amp;).\n\n\nТабличный вывод (tabwriter)\nМетод tabwriter.NewWriter из пакета text инициализирует фильтр, который перехватывает поток текста, ищет в нем знаки табуляции \\t и заменяет их на нужное количество пробелов для создания ровных колонок.\n\nВывод похож на Format-Table из коллекций в PowerShell:\n\n\nЛогирование (log)\nМетод slog из пакета log предоставляет структурированный вывод (записывает логи в виде пар ключ-значение), который используется для отображения состояния работы приложения в современной формате.\n\n\nОператоры\n\nАрифметика\nОператорОписание\n+сложение\n-вычитание\n*умножение\n/деление *\n%деление, возвращающие только остаток\n&amp;побитовое и\n|побитовое или\n^побитовое исключающее или * *\n&amp;^очистить бит (и нет) * * *\n&lt;&lt;сдвиг влево * * * *\n&gt;&gt;сдвиг вправо\n\n* Если оба операнда имеют целый тип (int, int8, int32, int64), результат также будет целым числом, при этом остаток отбрасывается. Если хотя бы один из операндов имеет тип с плавающей точкой (float32, float64), результат будет дробным числом.\n* * Возвращает 0, если биты двух операндов равны, или 1, если биты двух операндов различны.\n* * * Возвращает 0, если соответствующий бит второго операнда равен 1, или бит первого операнда (0 или 1), если соответствующий бит второго операнда равен 0.\n* * * * Сдвигает все биты числа влево на указанное количество позиций (аналог умножения числа на 2 в степени количества сдвигов), а новые биты справа заполняются нулями.\n\nСравнение\nОператорОписание\n==равно\n!=не равно\n&lt;меньше\n&lt;=меньше или равно\n&gt;больше\n&gt;=больше или равно\n\n\nЛогика\nОператорОписание\n&amp;&amp;логическое и\n||логическое или\n!логическое отрецание\n\n\nДругие\nОператорОписание\n&amp;указатель (адрес в памяти на переменную)\n*разыменовать указатель\n&lt;-оператор отправки / получения\n\n\nПеременные\nТип указывается после идентификатора (названия переменной):\n\n\nОбласть видимости\nВ разных лексических блоках возможно заново объявлять переменные с одинаковыми именами. Компилятор считывая ссылку на переменную, ищет ее объявление начиная с текущего блока и выше.\n\n\nФункции\n\n\nЗамыкания\n\n\nВариативные функции\nВариативная функция работает и вызывается как любая другая функция, за исключением того, что в нее возможно передать произвольное количество аргументов, используя ... перед типом данных указанного параметра.\n\n\nТипы данных\n\nТип данныхОписаниеДиапазон значений\nuint8Беззнаковые 8-битные целые числаот 0 до 255\nuint16Беззнаковые 16-битные целые числаот 0 до 65535\nuint32Беззнаковые 32-битные целые числаот 0 до 4294967295\nuint64Беззнаковые 64-битные целые числаот 0 до 18446744073709551615\nint8Знаковые 8-битные целые числаот -128 до 127\nint16Знаковые 16-битные целые числаот -32768 до 32767\nint32Знаковые 32-битные целые числаот -2147483648 до 2147483647\nint64Знаковые 64-битные целые числаот -9223372036854775808 до 9223372036854775807\n\nВсе предварительно объявленные идентификаторы Go определены в пакете builtin.\n\nПреобразование типов\n\n\nФорматированние вывода\n\nPrintf\nФорматирование вывода - это процесс преобразования данных из внутреннего представления (переменных, структур, чисел) в определенный текстовый формат для отображения на экран или записи в файл.\nФорматОписание\n%Tвывод типа данных содержимого переменной\n%pвывод значения указателя (адрес в памяти, в шестнадцатеричном виде)\n%vуниверсальный спецификатор, для типа boolean (аналогичен %t), целочисленных типов (%d), чисел с плавающей точкой - %g, строк - %s\n%#vвывод значения (структуру, срез, карту или другой тип) в виде Go-литерала (как его можно было бы записать в исходном коде Go) для отладки\n%tвывод значений типа boolean (true или false)\n%sвывод строки (string)\n%fвывод чисел с плавающей точкой (float32 или float64)\n%5fширина значения (если значение меньше ширины, то остаток заполняется пробелами)\n%.2fточность остатока (выводит 2 цифры в дробной части после точки)\n%dвывод целых чисел в десятичной системе\n%oвывод целых чисел в восьмеричной системе\n%bвывод целых чисел в двоичной системе\n%cвывод символов, представленных числовым кодом (тип данных rune или byte) в формате их числовых/буквенных значений\n%qвывод символов в одинарных кавычках (тип данных rune или byte в формате кодового значения Unicode)\n%xвывод целых чисел в шестнадцатеричной системе, буквенные символы числа имеют нижний регистр a-f\n%Xвывод целых чисел в шестнадцатеричной системе, буквенные символы числа имеют верхний регистр A-F\n%Uвывод символов в формате кодов Unicode, например, U+1234\n%eвывод чисел с плавающей точкой в экспоненциальном представлении, например, -1.234456e+78\n%Eтоже самое что %e но в верхнем регистре, например, -1.234456E+78\n\n\n\nSprintf\nМетод Sprintf может использоваться для преобразования целого числа в строку или округления целих дробных с помощью форматирования.\n\n\nСтруктуры управления\n\nУсловия (if else)\n\n\nПереключатели (switch)\nПосле выполнения условия при использование переключателей, прерывания обрабатываются автоматически.\n\n\nПереключение типа\nПереключение типа похоже на обычный оператор switch, но в условиях указывается типы (а не значения), которые сравниваются с типом значения, содержащегося в данном значении интерфейса.\n\n\nСквозной переход (fallthrough)\nFallthrough - это поведение оператора switch, когда после выполнения кода для одного case выполнение не прерывается, а продолжается в следующий case, даже если он не совпадает, пока не встретит break или не закончится блок.\n\n\nЦиклы (for)\nВ Go используются только универсальные циклы for, другие операторы (например, while или until) отсутствуют.\n\n\nПримеры циклов\n\n\nТипы последовательностей\nТипы последовательностей представляют собой структуры данных, хранящие упорядоченные наборы значений.\n\nМассивы (array)\nМассив (статические срезы) - фиксированная по размеру последовательность элементов (arr[10]).\n\n\nСрезы (slice)\nСрез (динамические массивы) - это последовательность элементов одного типа с динамической структурой, которая может быть получена из массивов или других срезов с помощью операции среза (arr[start:end]). Срезы могут иметь явное указание длины и емкости, которые можно задать с помощью встроенный функции make, например, чтобы инициализировать элементы среза нулевыми значениями или заранее выделить нужное количество памяти (количество элементов в срезе не ограничивается, но потребует выделения новой памяти).\n\n\nОперации с срезами\nУказатель — ссылается на первый элемент массива, доступный через срез (может не совпадать с началом самого массива).\nДлина (length) — количество элементов в срезе.\nЕмкость (capacity) — общее количество элементов от начала среза до конца базового массива, на котором основан срез.\nЕсли изменить значение в базовом массиве, то значение в дочернем срезе также изменится (или наоборот), т.к. элементы слайса и массива находятся в одном участке памяти. При создание среза на основе массива достаточной длины, возможно избежать операций выделения памяти при создании нового массива и копирования элементов из одного массива в другой.\n\n\nДиапазоны (range)\nДиапазон используется для перебора индексов и элементов массива в цикле.\n\n\nКарта (map)\nМаппинг используется для хранения и сопоставления данных.\n\n\nСортировка (sort)\nMap реализована как хэш-таблица, и при переборе в цикле порядок элементов будет рандомным, даже если структура не меняется.\nДля опредиления порядка, необходимо сначала извлечь ключи из map в срез (slice), отсортировать этот срез с помощью функции sort и затем итерироваться по отсортированным ключам.\n\n\nСтруктуры (struct)\nВместо классов (class) в Go используются структуры (struct), которые являются новым типом данных комбинированных значений, а также могут содержать методы. Поля структуры всегда инициализируются нулевыми значениями при ее объявлении.\n\nПример использования структуры и перебор элементов в цикле.\n\n\nАнонимные структуры\nВ отличии от map[string]interface{}, анонимные структуры имеют строгую типизацию, что уменьшает ошибки и повышает производительность, но его нельзя использовать в разных местах без дублирования объявления.\n\n\nУказатели\nАргументы в функциях и методах всегда копируются, указатели позволяют работать напрямую с содержимым переданных переменных и структурами данных, без копирования их содержимого (изменяя оригинальную переменную).\nОператор &amp; используется для взятия адреса из памяти, а не значения самой переменной.\nФункция new() выделяет память для указанного типа и возвращает переменной указатель на него, в отличие от оператора &amp;, который возвращает указатель на существующую переменную.\n\n\n\nИнтерфейсы (interface)\nИнтерфейс - это набор методов (требований), которые должен иметь тип, чтобы соответствовать этому интерфейсу.\n\n\nВстраивание\nВ Go нет подклассов, вместо этого используется встраивание интерфейса и структуры, которое добавляет методы встроенной структуры к внешней.\n\n\nОбработка ошибок\nОбработка исключений отсутствует. Вместо этого функции, которые могут выдать ошибку, просто объявляют дополнительное возвращаемое значение типа error (чаще всего вторым возвращаемым параметром).\nВстроенный тип интерфейса error — это общепринятый интерфейс для представления состояния ошибки, при этом нулевое значение не представляет ошибки.\n\nПример:\n\n\nПараллелизм\n\nГорутины\nГорутины — это легковесные потоки (управляемые Go, а не потоками ОС).\ngo f(a, b) запускает новую горутину, которая запускает f (при условии, что f — это функция).\n\n\nСинхронизация\nПакет sync используется для ожидания завершения всех запущенных горутин.\nКлючевое слово defer (откладывать) используется для планирования выполнения указанной внешней функции непосредственно на момент выхода из текущей (вызывающей) функции (альтернатива try...finally).\n\n\nТаймер\nТаймеры из пакета time используются для задержки (паузы) на указанное время:\n\n\nMutex\nMutex позволяет избежать конги данных (конфликт на запись).\n\n\nНебуферизованный канал\nНебуферизованный канал блокирует операцию записи, пока не будет выполнено чтение, и наоборот.\n\n\nБуферизованный канал\nБуферизованный канал позволяет отправлять и получать данные без блокировки, пока размер буфера не будет превышен, как только буфер заполняется, запись блокируется, пока другие горутины не начнут извлекать значения из канала.\nЗакрытие канала — это сигнал получателю, что больше значений не будет отправляться в канал, при этом отправленные в него данные не удаляются. Это необходимо для того, чтобы получатели знали, что можно завершить чтение. Закрытие канала происходило только в той горутине, которая отправляет данные.\n\nВывод: 0 1 2 3 4 5 6 7 8 9 Канал закрыт, данные не доступны\n\nСелекторы\nОператор select работает как многоканальный оператор switch. Выбор блоков в операциях с несколькими каналами, если один из них разблокируется, выполняется соответствующие условие. Он блокируется до тех пор, пока одно из выражений case не будет готов к выполнению, при этом остальные игнорируются.\n\n\nАксиомы канала\nОтправка в пустой канал блокируется навсегда и вызывает фатальную ошибку:\n\nЧтение из нулевого канала блокируется навсегда:\n\nОтправка в закрытый канал вызывает панику:\n\nПрием из закрытого канала немедленно возвращает нулевое значение:\n\n\nПримеры каналов и горутин\n\n\nМатематические вычисления (math)\n\n\nОбработка текста (strings)\n\nМетоды из пакета strings для работы со строками:\n\n\nРегулярные выражения (regexp)\nОсновные элементы синтаксиса регулярных выражений:\nСимволОписание\n.любой символ, кроме символа новой строки\n*0 или более повторений\n+1 или более повторений\n{n}точно n повторений (например, a{3}, соответствует: \"aaa\")\n{n,}минимум n повторений (например, a{2,}, соответствует: \"aa\", \"aaa\" и т.д.)\n{n,m}от n до m повторений (например, a{2,4}, соответствует: \"aa\", \"aaa\", \"aaaa\")\n?0 или 1 повторений\n^начало строки\n$конец строки\n[]группа символов (например, [a-z])\n\\sлюбой пробельный символ (пробел, табуляция, новая строка и другие пробельные символы)\n\\dцифра (эквивалентно [0-9])\n\\Dлюбой символ, не являющийся цифрой (эквивалентно [^0-9])\n\\wбуквенно-цифровой символ (буквы, цифры и подчеркивание, эквивалентно [a-zA-Z0-9_])\n\\Wне буквенно-цифровой символ (эквивалентно [^a-zA-Z0-9_])\n\\bграница слова (например, \\bword\\b соответствует \"word\", и не подхоит \"wordy\")\n(?i)делает выражение нечувствительным к регистру\n\\экранирование специальных символов\n()группа захвата\n|логическое ИЛИ (например, `a\n\n\nMatchString\nregexp.MatchString — проверяет, соответствует ли строка регулярному выражению.\n\n\nCompile\nregexp.Compile — компилирует регулярное выражение и возвращает объект типа *regexp.Regexp, если выражение корректное, или возвращается ошибка.\n\n\nFindAllString\nregexp.FindAllString — находит все подстроки в строке, которые соответствуют регулярному выражению, и возвращает их в виде среза строк.\n\n\nReplaceAllString\nregexp.ReplaceAllString — заменяет все соответствующие части строки.\n\n\nГруппы захвата\n\nИзвлечение логина и домена из почтовых адресов:\n\n\nREST API\n\nHTTP сервер\nРеализация простого API сервера на базе встроенной библиотеки net/http:\n\nДелаем запрос к API через curl:\n\n\nHTTP клиент\nДелаем запрос к API в Go:\n\nHTTP запрос к API для получения последней версии релиза указаного репозитория в GitHub:\n\ngo run main.go\n\nВызов системных команд (exec)\nПроверка доступности всех хостов в указанной подсети (асинхронный ICMP опрос):\n\ngo run main.go 192.168.3.0\n\nВстраивание файлов (embed)\nПрограммы Go могут встраивать статические файлы с помощью пакета embed и директиву go:embed path/filename:\n\n","path":null},{"url":"https://lifailon.github.io/devops/","title":"DevOps","description":null,"body":"\n    \n\n\n    Заметки по инструментам направления DevOps.\n\n\n\nGit\ngit --version \ngit config --global user.name \"Lifailon\" добавить имя для коммитов \ngit config --global user.email \"lifailon@yandex.ru\" \ngit config --global --edit \ngit config --global core.editor \"code --wait\" изменить редактор коммитов по умолчанию \nssh-keygen -t rsa -b 4096 \nGet-Service | where name -match \"ssh-agent\" | Set-Service -StartupType Automatic \nGet-Service | where name -match \"ssh-agent\" | Start-Service \nGet-Service | where name -match \"ssh-agent\" | select Name,Status,StartType \nssh-agent \nssh-add C:\\Users\\Lifailon\\.ssh\\id_rsa \ncat ~\\.ssh\\id_rsa.pub | Set-Clipboard copy to settings keys \ncd $home\\Documents\\Git \ngit clone git@github.com:Lifailon/lifailon.github.io \ncd lifailon.github.io \ngit grep \"ping ya.ru\" поиск текста в файлах \ngit fetch загрузить изменения из удаленного хранилища для обновления всех веток локального репозитория, не затрагивая текущую рабочую ветку (загружает все коммиты, ветки и т.д. которые не присутствуют в локальном репозитории) \ngit fetch --all загрузить все ветки с удаленного репозитория (обновляет информацию о состоянии удаленного репозитория и загружает все изменения ваших веток без автоматического объединения) \ngit pull загрузить изменения из удаленного хранилища для обновления локального репозитория (выполняет git fetch, чтобы получить последние изменения из удаленного репозитория, а затеим объеденяем изменения с локальной копией с помощью git merge для обновления текущей рабочей ветки) \ngit stash сохраняет текущие незакоммиченные изменения в временное хранилище (например, на время выполнения git pull), в т.ч. неотслеживаемые файлы и очищает рабочую директорию (вернет в состояние, соответствующее последнему коммиту) \ngit stash pop применяет последние изменения из стэша к текущей ветке (вернутся только измененные строки в файлах, при этом будут сохранены новые добавленные строки в файле без конфликтов) и удаляет их из стэша \ngit stash apply применяет изменения, но не удаляет их из стэша \ngit status отобразить статус изменений по файлам \ngit diff отобразить историю изменений построчно \ngit diff pandoc сравнивает изменения в текущей рабочей директории с последним коммитом в указанной ветке pandoc \ngit add . добавить (проиндексировать) изменения во всех файлах текущего каталога \ngit commit -m \"update powershell commands\" сохранить изменения с комментарием \ngit push синхронизировать локальные изменения с репозиторием на сервере \ngit push origin mkdocs-material отправить в конкретную ветку \ngit push origin --delete mkdocs удалить ветку на удаленном сервере \ngit commit --amend изменить комментарий в последнем коммите (до push) \ngit commit --amend --no-edit --date=\"Sun Oct 27 23:20:00 2024 +0300\" изменить дату последнего коммита \ngit branch -a отобразить все ветки (в том числе удаленные remotes/origin) \ngit branch hugo создать новую ветку \ngit branch -m hugo-public переименовать текущую ветку \ngit branch -d hugo-public удалить ветку \ngit switch hugo переключиться на другую ветку \ngit push origin hugo отправить изменения в указанную ветку \ngit branch --set-upstream-to=origin/hugo hugo локальная ветка hugo будет отслеживать удаленную ветку hugo на удаленном сервере-репозитории origin (позволяет не указывать название удаленной ветки при каждом использовании команд git push или git pull) \ngit switch pandoc переключиться на другую ветку \ngit merge hugo слияние указанной ветки (hugo) в текущую ветку (pandoc)  \ngit log --oneline --all отобразить список всех коммитов и их сообщений \ngit log --graph коммиты и следование веток \ngit log --author=\"Lifailon\" показывает историю коммитов указанного пользователя \ngit blame .\\posh.md показывает, кто и когда внес изменения в каждую строку указанного файла (НОМЕР_КОММИТА (ИМЯ_ПОЛЬЗОВАТЕЛЯ ДАТА НОМЕР_СТРОКИ) ТЕКСТ.) \ngit show d01f09dead3a6a8d75dda848162831c58ca0ee13 отобразить подробный лог по номеру коммита \ngit checkout filename устаревшая команда, откатить не проиндексированные изменения для коммита, возвращая его к состоянию, каким оно было на момент последнего коммита (если не было индексации через add) \ngit restore filename отменить все локальные изменения в рабочей копии независимо от того, были они проиндексированы или нет (через add), возвращая его к состоянию на момент последнего коммита \ngit restore --source d01f09dead3a6a8d75dda848162831c58ca0ee13 filename восстановить файл на указанную версию по хэшу индентификатора коммита \ngit reset HEAD filename удалить указанный файл из индекса без удаления самих изменений в файле для последующей повторной индексации (если был add но не было commit, потом выполнить checkout) \ngit reset --soft HEAD^ отменяет последний (^) коммит, сохраняя изменения из этого коммита в рабочем каталоге и индексе (подготовленной области), можно внести изменения в файлы и повторно их зафиксировать через commit \ngit reset --hard HEAD^ полностью отменяет последний коммит, удаляя все его изменения из рабочего каталога и индекса до состояния предыдущего перед последним коммитом (аналогично HEAD~1) \ngit push origin main --force удалить последний коммит на удаленном сервере репозитория после reset --hard HEAD^  \ngit reset --hard d01f09dead3a6a8d75dda848162831c58ca0ee13 откатывает изменения к указанному коммиту и удаляет все коммиты, которые были сделаны после него (будут потеряны все незакоммиченные изменения и историю коммитов после указанного) \ngit revert HEAD --no-edit создает новый коммит, который отменяет последний коммит (HEAD^) и новый коммит будет добавлен поверх него (события записываются в git log) \ngit revert d01f09dead3a6a8d75dda848162831c58ca0ee13 создает новый коммит, который отменяет изменения, внесенные в указанный коммит с хешем (не изменяет историю коммитов, а создает новый коммит с изменениями отмены)\n\nDocker\n\nWSL\nwsl --list список установленных дистрибутивов Linux \nwsl --list --online список доступных дистрибутивов \nwsl --install -d Ubuntu установить Ubuntu в Windows Subsystem for Linux \nwsl --status \nwsl --exec \"htop\" выполнить команду в подсистеме Linux по умолчанию \nwsl -e bash -c \"docker -v\" \nwsl -e bash -c \"systemctl status docker\"\n\nInstall\napt update &amp;&amp; apt upgrade -y \napt install docker.io \nsystemctl status docker \nsystemctl start docker \nsystemctl enable docker \niptables -t nat -N DOCKER \ndocker -v\ndocker events отобразить все происходящие события в процессе работы\nsudo usermod -aG docker lifailon добавить пльзователя в группу docker \nnewgrp docker применить изменения в группах\ncurl https://registry-1.docker.io/v2/ проверить доступ к Docker Hub \ncurl -s -X POST -H \"Content-Type: application/json\" -d '{\"username\": \"lifailon\", \"password\": \"password\"}' https://hub.docker.com/v2/users/login | jq -r .token &gt; dockerToken.txt получить временный токен доступа для авторизации \nsudo docker login вход в реестр репозитория hub.docker.com \ncat dockerToken.txt | sudo docker login --username lifailon --password-stdin передать токен авторизации (https://hub.docker.com/settings/security) из файла через stdin \ncat /root/.docker/config.json | jq -r .auths[].auth место хранения токена авторизации в системе \ncat /root/.docker/config.json | python3 -m json.tool\n\nProxy\n\nСоздаем дополнительную конфигурацию для службы Docker в файле /etc/systemd/system/docker.service.d/http-proxy.conf:\n\nsystemctl daemon-reload \nsystemctl restart docker\n\nLogging\nНацелить логирование всех контейнеров по умолчанию на сервер syslog через файл /etc/docker/daemon.json:\n\nИзменить режим логирования выбранного контейнера в файле docker-compose.yml:\n\n\nMirror\necho '{ \"registry-mirrors\": [\"https://dockerhub.timeweb.cloud\"] }' &gt; \"/etc/docker/daemon.json\" \necho '{ \"registry-mirrors\": [\"https://huecker.io\"] }' &gt; \"/etc/docker/daemon.json\" \necho '{ \"registry-mirrors\": [\"https://mirror.gcr.io\"] }' &gt; \"/etc/docker/daemon.json\" \necho '{ \"registry-mirrors\": [\"https://daocloud.io\"] }' &gt; \"/etc/docker/daemon.json\" \necho '{ \"registry-mirrors\": [\"https://c.163.com\"] }' &gt; \"/etc/docker/daemon.json\"\nsystemctl restart docker\n\nNexus\nНебезопасные HTTP-соединения с Nexus сервером (если не использует HTTPS):\n\ndocker login 192.168.3.105:8882 авторизируемся в репозитории Docker Registry на сервере Nexus \ndocker tag lifailon/docker-web-manager:latest 192.168.3.105:8882/docker-web-manager:latest создаем тег с прявязкой сервера \ndocker push 192.168.3.105:8882/docker-web-manager:latest загружаем образ на сервер Nexus\ncurl -sX GET http://192.168.3.105:8882/v2/docker-web-manager/tags/list | jq отобразить список доступных тегов \ndocker pull 192.168.3.105:8882/docker-web-manager:latest загрузить образ из Nexus\n\nRun\nCommands: search/pull/images/creat/start/ps/restart/pause/unpause/rename/stop/kill/rm/rmi\ndocker search speedtest поиск образа в реестре \ndocker pull adolfintel/speedtest скачать образ LibreSpeed из реестра Docker Hub (https://hub.docker.com/r/adolfintel/speedtest) \ndocker images (docker image ls) отобразить все локальные (уже загруженные) образы docker (image ls) \ndocker images --format \"table {{.ID}}\\t{{.Repository}}\\t{{.Tag}}\" отфильтровать вывод (json-формат) \ndocker create -it --name speedtest -p 8080:80 adolfintel/speedtest создать контейнер из образа adolfintel/speedtest с именем speedtest и проброс 80 порта контейнера на 8080 порт хоста \ndocker start speedtest запустить созданный контейнер \nss -ltp | grep 8080 проверить, что порт открыт \ndocker ps отобразить все запущенные докер контейнеры \ndocker ps -a список всех существующих контейнеров (для их запуска/удаления по NAMES/ID и код выхода Exited 0 - успешная остановка) \ndocker ps -s размер контейнеров (–size) \ndocker restart speedtest перезапустить контейнер \ndocker pause speedtest приостановить контейнер \ndocker unpause uptime-kuma возобновить работу контейнера \ndocker rename speedtest speedtest-2 переименоввать контейнер (docker rename old_name new_name) \ndocker stop speedtest-2 остановить работающий контейнер с отправкой главному процессу контейнера сигнал SIGTERM, и через время SIGKILL \ndocker kill uptime-kuma остановить работающий контейнер с отправкой главному процессу контейнера сигнал SIGKILL \ndocker kill $(docker ps -q) остановить все контейнеры \ndocker rm speedtest-2 удалить контейнер \ndocker rmi adolfintel/speedtest удалить образ \ndocker run -p 8443:8443 -it --entrypoint /bin/sh container_name запустить контейнер и подключиться к нему (даже если контейнер уходит в ошибку при запуске)  \ndocker run -d --restart=unless-stopped --name openspeedtest -p 3000:3000 -p 3001:3001 openspeedtest/latest загрузить образ OpenSpeedTest (https://hub.docker.com/r/openspeedtest/latest), создать контейнер и запустить в одну команду в фоновом режиме (-d/–detach, терминал возвращает контроль сразу после запуска контейнера, если не используется, можно видеть логи, но придется остановить контейнер для выхода) \ndocker rm openspeedtest &amp;&amp; docker rmi openspeedtest/latest удаляем контейнер и образ в одну команду \ndocker run --name pg1 -p 5433:5432 -e POSTGRES_PASSWORD=PassWord -d postgres создать контейнер postgres (https://hub.docker.com/_/postgres) с параметрами (-e) \ndocker run -d --restart=always --name uptime-kuma -p 8080:3001 louislam/uptime-kuma:1 создать и запустить контейнер Uptime-Kuma (https://hub.docker.com/r/elestio/uptime-kuma) в режиме always, при котором контейнер должен перезапускаться автоматически, если он остановится или если перезапустится Docker (например, после перезагрузки хоста) \ndocker history openspeedtest:latest отображает слои образа, их размер и команды, которые были выполнены при его создании\n\nAlias\n\n\nUpdate\ndocker update --restart unless-stopped uptime-kuma изменить режим перезапуска контейнера после его остановки на unless-stopped (режим аналогичен always, но контейнер не будет перезапущен, если он был остановлен вручную с помощью docker stop) \ndocker update --restart on-failure uptime-kuma контейнер будет перезапущен только в случае его завершения с ошибкой, когда код завершения отличается от 0, через двоеточие можно указать количество попыток перезапуска (например, on-failure:3) \ndocker update --cpu-shares 512 --memory 500M uptime-kuma задать ограничения по CPU, контейнер будет иметь доступ к указанной доле процессорного времени в диапазоне от 2 до 262,144 (2^18) или –cpus (количество процессоров), –memory/–memory-swap и –blkio-weight для IOps (относительный вес от 10 до 1000)\n\nStats\ndocker stats посмотреть статистику потребляемых ресурсов запущенными контейнерами (top) \ndocker stats --no-stream --format json вывести результат один раз в формате json\n\nLogs\ndocker logs uptime-kuma --tail 100 отобразить логи конкретного запущенного контейнера в терминале (последние 100 строк) \ndocker system events предоставляют события от демона dockerd в реальном времени \njournalctl -xeu docker.service \ndocker system df отобразить сводную информацию занятого пространства образами и контейнерами \ndu -h --max-depth=1 /var/lib/docker \ndu -h --max-depth=2 /var/lib/docker/containers\n\nНастройка логирования в docker compose:\n\n\nVolume\ndocker volume ls показывает список томов и место хранения (механизмы хранения постояннымх данных контейнера на хостовой машине, которые сохраняются между перезапусками или пересозданиями контейнеров) \ndocker volume inspect uptime-kuma подробная информация конфигурации тома (отображает локальный путь к данным в системе, Mountpoint: /var/lib/docker/volumes/uptime-kuma/_data) \ndocker volume create test создать том \ndocker volume rm test удалить том \ndocker run -d --restart=always --name uptime-kuma -p 8080:3001 -v uptime-kuma:/app/data louislam/uptime-kuma:1 создать и запустить контейнер на указанном томе (том создается автоматически, в дальнейшем его можно указывать при создании контейнера, если необходимо загружать из него сохраненные данные)\n\ntmpfs\nВременная файловая система для хранения данных в оперативной памяти (исчезают после остановки контейнера):\n\n\nnfs\nМонтирование NFS (без необходимости предварительного монтирования на хосте) через драйвер opts:\n\n\ncifs\n\n\nmount\nsudo apt install cifs-utils smbclient -y \nsmbclient //192.168.3.100/backup -U guest% проверить гостевой доступ \nsudo mkdir /mnt/smb_backup &amp;&amp; sudo chown -R 1000:1000 /mnt/smb_backup создать директорию для монтирования \nmount -t cifs //192.168.3.100/backup /mnt/smb_backup -o user=guest примонтировать (до перезагрузки) \necho \"//192.168.3.100/backup /mnt/smb_backup cifs username=guest,password=,uid=1000,gid=1000,rw,vers=3.0 0 0\" | sudo tee -a /etc/fstab \nmount -a &amp;&amp; systemctl daemon-reload &amp;&amp; df -h примонтировать (применить все записи из fstab)\n\n\nNetwork\ndocker network ls список сетей \ndocker network inspect bridge подробная информация о сети bridge \ndocker inspect uptime-kuma | jq .[].NetworkSettings.Networks узнать наименование сетевого адаптера указанного контейнера \ndocker run -d --name uptime-kuma --network host nginx louislam/uptime-kuma:1 запуск контейнера с использованием host сети, которая позволяет контейнеру использовать сеть хостовой машины \ndocker network create network_test создать новую сеть \ndocker network connect network_test uptime-kuma подключить работающий контейнер к указанной сети \ndocker network disconnect network_test uptime-kuma отключить от сети\n\nbridge\nКонтейнеры взаимодействуют между собой через виртуальный мост (используя container_name для связи, в т.ч. с другими контейнерами через проброс сети в помощью external), и используют NAT для выхода в Интернет.\n\n\nhost\nВ сетевом режиме host используется сеть хоста напрямую (порты через секцию ports не пробрасываются).\n\n\nmacvlan\nmacvlan - это сетевой драйвер, который работает на уровне L2, где контейнеры получают свои MAC и IP адреса во внешней сети хоста (линкуется по названию интерфейса).\nsudo ip link set eth0 promisc on включить режим promisc на интерфейсе хоста, что бы иметь возможность принимать все пакеты, проходящие через хост, независимо от MAC-адреса.\nSet-VMNetworkAdapter -VMName hv-us-101 -MacAddressSpoofing On включить режим promisc на виртуальной машине Hyper-V\n\n\nipvlan\nipvlan не создаёт отдельные MAC-адреса, поэтому может работать на wlan (Wi-Fi) интерфейсах хоста.\n\n\nInspect\ndocker inspect uptime-kuma подробная информация о контейнере (например, конфигурация NetworkSettings) \ndocker inspect uptime-kuma --format='{{.LogPath}}' отобразить, где хранятся логи для конкретного контейнера в локальной системе \ndocker inspect uptime-kuma | grep LogPath \ndocker inspect $(docker ps -q) --format='{{.NetworkSettings.Ports}}' отобразить TCP порты всех запущенных контейнеров \ndocker inspect $(docker ps -q) --format='{{.NetworkSettings.Ports}}' | grep -Po \"[0-9]+(?=}])\" отобразить порты хоста (внешние) \ndocker port uptime-kuma отобразить проброшенные порты контейнера \nfor ps in $(docker ps -q); do docker port $ps | sed -n 2p | awk -F \":\" '{print $NF}'; done отобразить внешние порты всех запущенных контейнеров \nid=$(docker inspect uptime-kuma | jq -r .[].Id) узнать ID контейнера по его имени в конфигурации \ncat /var/lib/docker/containers/$id/config.v2.json | jq . прочитать конфигурационный файл контейнера\n\nExec\ndocker exec -it uptime-kuma /bin/bash подключиться к работающему контейнеру (при выходе из оболочки, контейнер будет работать), используя интерпритатор bash \ndocker top uptime-kuma отобразить работающие процессы контейнера \ndocker exec -it --user root uptime-kuma bash apt-get install -y procps авторизоваться под пользователем root и установить procps \ndocker exec -it uptime-kuma ps -aux отобразить работающие процессы внутри контейнера \ndocker exec uptime-kuma kill -9 25055 убить процесс внутри контейнера\n\nCopy\nКопируем базу данных sqlite3, обновляем пароль и разблокируем пользователя Grafana:\n\n\nPrune\ndocker network prune &amp;&amp; docker image prune &amp;&amp; docker volume prune &amp;&amp; docker container prune удалить все неиспользуемые сети, висящие образа, остановленные контейнеры, все неиспользуемые тома \nsystem prune –volumes заменяет все четыре команды для очистки и дополнительно очищает кеш сборки\n\nRemove\ndocker image prune -a удалить все образы, которые не используются хотя бы одним контейнером \ndocker images -q | xargs docker rmi удалить все образы\nУдаление системы контейнеризации:\n\n\nDiff\ndocker diff &lt;container_id_or_name&gt; отображает изменения, внесённые в файловую систему контейнера по сравнению с исходным образом\nA — добавленные файлы \nC — изменённые файлы \nD — удалённые файлы\n\nDocker Socket API\ncurl --silent -XGET --unix-socket /run/docker.sock http://localhost/version | jq . использовать локальный сокет (/run/docker.sock) для взаимодействия с Docker daemon через его API \ncurl --silent -XGET --unix-socket /run/docker.sock http://localhost/info | jq . количество образов, запущенных и остановленных контейнеров и остальные метрики ОС \ncurl --silent -XGET --unix-socket /run/docker.sock http://localhost/events логи Docker daemon \ncurl --silent -XGET --unix-socket /run/docker.sock -H \"Content-Type: application/json\" http://localhost/containers/json | jq . список работающих контейнеров и их параметры конфигурации \ncurl --silent -XGET --unix-socket /run/docker.sock http://localhost/containers/uptime-kuma/json | jq . подробные сведения (конфигурация) контейнера \ncurl --silent -XPOST --unix-socket /run/docker.sock -d \"{\"Image\":\"nginx:latest\"}\" http://localhost/containers/create?name=nginx создать контейнер с указанным образом в теле запроса (должен уже присутствовать образ) \ncurl --silent -XPOST --unix-socket /run/docker.sock http://localhost/containers/17fab06a820debf452fe685d1522a9dd1611daa3a5087ff006c2dabbe25e52a1/start запустить контейнер по Id \ncurl --silent -XPOST --unix-socket /run/docker.sock http://localhost/containers/17fab06a820debf452fe685d1522a9dd1611daa3a5087ff006c2dabbe25e52a1/stop остановить контейнер \ncurl --silent -XDELETE --unix-socket /run/docker.sock http://localhost/containers/17fab06a820debf452fe685d1522a9dd1611daa3a5087ff006c2dabbe25e52a1 удалить контейнер\n\nDocker TCP API\n\ncurl --silent -XGET http://192.168.3.102:2375/version | jq .\nКонечная точка /metrics для Prometheus:\n\ncurl http://192.168.3.102:9323/metrics\n\nDocker Socket Proxy\nПроксирование локального сокета Docker на базе HAProxy (не требуется внесение изменений в системные файлы, такие как daemon.json и docker.service) с контролем доступа к конечным точкам с использованием переменных среды.\n\n\nContext\ndocker context create rpi-106 --docker \"host=tcp://192.168.3.106:2375\" добавить подключение к удаленному хосту через протокол TCP \ndocker context create rpi-106 --docker \"host=ssh://lifailon@192.168.3.106:2121\" добавить подключение к удаленному хосту через протокол SSH \ndocker context ls список всех доступных контекстов (* отображается текущий) \ndocker context inspect rpi-106 конфигурация указанного контекста \ndocker context use rpi-106 переключиться на выбранный контекст (возможно на прямую взаимосдействовать с удаленным Docker Engine через cli, за исключением взаимодействия через Socket) \ndocker context rm rpi-106 удалить контекст\n\nDCM\ndcm (Docker Context Manager) - это простая реализация TUI интерфейса на базе fzf, для переключения контекста из перечисленного списка хостов. Т.к. для использовать TUI интерфейсов требуется взаимодействие с сокетом, недостаточно изменить только переменную DOCKER_HOST или использовать команду docker context, по этому используется механиз ssh forwarding, который пробрасывает сокета с удаленной машины в локальную систему (используется временный файл, с изменением пути в переменной окружения).\n\n\nLazyDocker\nLazyDocker - TUI интерфейс для управления Docker.\nscoop install lazydocker || choco install lazydocker установка в Windows (https://github.com/jesseduffield/lazydocker)\n\n\nctop\nctop - top-like интерфейс для метрик и управления контейнерами Docker.\nscoop install ctop установка в Windows (https://github.com/bcicen/ctop)\n\nctop отображает сводную таблицу (top) CPU, MEM, NET RX/TX, IO R/W \no - графики \nl - логи контейнера в реальном времени \ns - stop/start \nR - remove после stop \np - pause/unpause \nr - restart \ne - exec shell\n\ndtop\ndtop - top real-time для контейнеров Docker от создателя Dozzle.\n\n\nDockly\nnpm install -g dockly TUI интерфейс на базе Node.js и Blessed \ndocker run -it --rm -v /var/run/docker.sock:/var/run/docker.sock lirantal/dockly запуск в Docker \ndockly\n\nPush\ndocker login \ngit clone https://github.com/Lifailon/TorAPI \ncd TorAPI \ndocker build -t lifailon/torapi . собрать образ для публикации на Docker Hub \ndocker push lifailon/torapi загрузить образ на Docker Hub\ndocker pull lifailon/torapi:latest загрузить образ из Docker Hub \ndocker run -d --name TorAPI -p 8443:8443 lifailon/torapi:latest загрузить образ и создать контейнер\n\nBuildx\nsudo apt install docker-buildx -y установить систему для мультиплатформенной сборки \ndocker buildx create --use --name multiarch-builder --driver docker-container оздать и запустить сборщик в контейнере \ndocker buildx ls \ndocker buildx rm multiarch-builder\ngo list -u -m all &amp;&amp; go get -u ./... обновить пакеты приложения на Go\nДобавить аргументы в Dockerfile и передать их в переменные для сборки:\n\ndocker buildx build –platform linux/amd64,linux/arm64 .\ndocker buildx build –platform linux/amd64,linux/arm64 -t lifailon/logporter –push .\nnpm outdated &amp;&amp; npm update --save обновить паеты node.jd приложения\nПередаем аргументы в параметры платформы для образа:\n\n\nDockerfile\nFROM указывает базовый образ, на основе которого будет создаваться новый образ \nLABEL добавляет метаданные к образу в формате ключ-значение \nENV устанавливает переменные окружения, которые будут доступны внутри контейнера со значениями по умолчанию (можно переопределить через -e, который имеет повышенный приоритет) \nARG определяет переменные, которые могут быть переданы и доступны только на этапе сборки образа (выполнения инструкций в dockerfile через docker build --build-arg) и недоступны в контейнере \nUSER устанавливает пользователя, от имени которого будут выполняться следующие команды \nWORKDIR устанавливает рабочий каталог внутри контейнера для последующих команд \nSHELL задает командную оболочку, которая будет использоваться для выполнения команд RUN, CMD и ENTRYPOINT (по умолчанию /bin/sh -c, например на SHELL [\"/bin/bash\", \"-c\"]) \nRUN выполняет команды в контейнере во время сборки образа \nCOPY копирует файлы и каталоги из указанного источника на локальной машине в файловую систему контейнера \nADD копирует файлы и каталоги в контейнер, поддерживает загрузку файлов из URL и автоматическое извлечение архивов \nCMD определяет команду, которая будет выполняться при запуске контейнера, может быть переопределена при запуске \nENTRYPOINT задает основную команду, которая будет выполняться при запуске контейнера без возможности ее переопредиления, но с возможностью передачи аргументов \nVOLUME создает точку монтирования для хранения данных в хостовой системе \nEXPOSE указывает, какие порты контейнера будут доступны извне \nHEALTHCHECK определяет команду для проверки состояния работающего контейнера \nONBUILD задает команды, которые будут автоматически выполнены при сборке дочерних образов \nSTOPSIGNAL определяет сигнал, который будет отправлен контейнеру для его остановки\nПример использования ADD для загрузки из url:\n\nПример сборки приложения на node.js:\ngit clone https://github.com/Lifailon/TorAPI \ncd TorAPI \nnano Dockerfile\n\ndocker build -t torapi . собрать образ из dockerfile\n\n\nCompose\n\n\nUptime-Kuma\nUptime-Kuma - веб-интерфейс для мониторинга доступности хостов (ICMP), портов (TCP), веб-контент (HTTP/HTTPS запросы), gRPC, DNS, контейнеры Docker, базы данных и т.д с поддержкой уведомлений в Telegram.\nnano docker-compose.yml\n\ndocker-compose up -d\nkuma_db=$(docker inspect uptime-kuma | jq -r .[].Mounts.[].Source) место хранения конфигураций в базе SQLite \ncp $kuma_db/kuma.db $HOME/uptime-kuma-backup.db\nСгенерировать API ключ: http://192.168.3.101:8081/settings/api-keys \ncurl -u\":uk1_fl3JxkSDwGLzQuHk2FVb8z89SCRYq0_3JbXsy73t\" http://192.168.3.101:8081/metrics\nПример конфигурации для Prometheus:\n\nDashboard для Grafana - Uptime Kuma - SLA/Latency/Certs (id 18667)\nUptime-Kuma-Web-API - оболочка API и Swagger документация написанная на Python с использованием FastAPI и Uptime-Kuma-API.\nnano docker-compose.yml\n\ndocker-compose up -d\nOpenAPI Docs (Swagger): http://192.168.3.101:8082/docs\n\n\nDockge\nDockge - веб интерфейс для управления стеками Docker Compose от создателя Uptime Kuma.\n\n\nDozzle\nDozzle (https://github.com/amir20/dozzle) - легковесное приложение с веб-интерфейсом для мониторинга журналов Docker (без хранения).\nmkdir dozzle &amp;&amp; cd dozzle &amp;&amp; mkdir dozzle_data\necho -n DozzleAdmin | shasum -a 256 сгенерировать пароль в формате sha-256 и передать в конфигурацию\nnano ./dozzle_data/users.yml\n\nИли сгенерировать пользователя в формате yaml конфигурации:\n\nЗапускаем контейнер:\n\ndocker-compose up -d\nКонтейнер на агенте:\n\n\nBeszel\nBeszel - веб-интерфейс (как Grafana) для мониторинга хостов и контейнеров (как node_exporter и cAdvisor вместе), backend на базе Pocket Base для хранения данных, также поддерживает оповещения в Telegram и другие мессенджеры через вебхук shoutrrr (от создателя Watchtower).\n\n\nWatchtower\nWatchtower - следит за тегом latest в реестре Docker Hub и обновлять контейнер, если он станет устаревшим.\n\ndocker-compose up -d\nПроброс потра используется для получения метрик через Prometheus (команда --http-api-metrics) с токеном доступа. Если нужно запускать обновления только через API, нужно добавить команду --http-api-update, или указать команду --http-api-periodic-polls, что бы использовать ручное и автоматическое обновление.\ncurl -H \"Authorization: Bearer demotoken\" http://192.168.3.101:8070/v1/metrics получить метрики \ncurl -H \"Authorization: Bearer demotoken\" http://192.168.3.101:8070/v1/update проверить и запустить обновления\nДобавить scrape_configs в prometheus.yml для сбора метрик:\n\ndocker-compose restart prometheus\nЧтобы исключить обновления, нужно добавить “lable” при запуске контейнера:\n\n\nPortainer\n\ndocker stack deploy -c portainer-agent-stack.yml portainer развернуть в кластере swarm (на каждом node будет установлен агент, который будет собирать данные, а на manager будет установлен сервер с web панелью)\nhttps://192.168.3.101:9443\ndocker run -d --name portainer_agent -p 9001:9001 --restart=always -v /var/run/docker.sock:/var/run/docker.sock -v /var/lib/docker/volumes:/var/lib/docker/volumes portainer/agent:latest установить агент на удаленный хост\nhttps://192.168.3.101:9443/#!/endpoints добавить удаленный хост по URL 192.168.3.102:9001\ndocker volume create portainer_data создать volume для установки локального контейнера (не в кластер swarm) \ndocker create -it --name=portainer -p 9000:9000 --restart=always -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer создать локальный контейнер \ndocker start portainer\nhttp://192.168.3.101:9000\n\nDocker.DotNet\n\n\nSwarm\ndocker swarm init инициализировать manager node и получить токен для подключения worker node (на сервере) \ndocker swarm join-token worker получить токен для подключения worker или manager \ndocker swarm join --token SWMTKN-1-1a078rm7vuenefp6me84t4swqtvdoveu6dh2pw34xjcf2gyw33-81f8r32jt3kkpk4dqnt0oort9 192.168.3.101:2377 подключение на worker node (на клиенте) \ndocker node ls отобразить список node на manager node \ndocker node inspect u4u897mxb1oo39pbj5oezd3um подробная информация (конфигурация) о node по id \ndocker swarm leave --force выйти из кластера на worker node (на manager node изменится статус с Ready на Down) \ndocker node rm u4u897mxb1oo39pbj5oezd3um удалить node (со статусом Down) на manager node \ndocker swarm init --force-new-cluster заново инициализировать кластер (если упал, при наличии одного менеджера)\ndocker pull lifailon/torapi:latest \nnano docker-stack.yml\n\ndocker stack deploy -c docker-stack.yml TorAPI собрать стек сервисов (на worker node появится контейнер TorAPI_torapi.1.ug5ngdlqkl76dt)\ndocker stack ls отобразить список стеков (название стека и количество в нем сервисов, без учета реплик) \ndocker stack services TorAPI аналог docker service ls, но для отображения списока сервисов указанного стека \ndocker service ls отобразить список всех сервисов для всех стеков (имя формате &lt;stackName_serviceName&gt;, с количеством и статусом реплик)\ndocker stack ps TorAPI статистика работы всех сервисов внутри стека (аналог docker ps) \ndocker service ps TorAPI_torapi аналог docker stack ps, но для отображения статистики указанного сервиса \ndocker service logs TorAPI_torapi -fn 0 просмотреть логи сервиса по всех репликам кластера одновременно\ndocker node update --label-add dev=true iebj3itgan6xso8px00i3nizc добавить ноду в группу по метке для линковки при запуске \ndocker service update --image lifailon/torapi:fake TorAPI_torapi запустить обновление образа для сервиса \ndocker service scale TorAPI_torapi=3 масштабировать сервис до указанного числа реплик\ndocker service inspect --pretty TorAPI_torapi отобразить конфигурацию сервиса \ndocker service inspect TorAPI_torapi отобразить подробную конфигурацию сервиса в формате json \ndocker stack rm TorAPI удалить стек (не требует остановки контейнеров)\n\n\nKubernetes\nNode - Физическая или виртуальная машина, входящая в состав кластера. На каждом узле работает kubelet (агент Kubernetes) и контейнерная среда. \nPod - наименьшая и самая простая единица в Kubernetes. Содержит один или несколько контейнеров, которые разделяют одно сетевое пространство (общий IP и порты) и имеют общие тома (volumes) для хранения данных. \nDeployment - управляет состоянием группы идентичных подов (реплик). Отвечает за их масштабируемость (увеличение или уменьшение числа подов), восстановление (перезапуск подов при сбоях), обновление (rolling updates) и откат (rollback) версий приложения. \nService - отвечает за балансировку нагрузки (обрабатывает входящий трафик и распределяет его между подами), а также обеспечивая постоянный IP-адрес и DNS-имя, даже в случае их пересоздания. \nConfigMap и Secret – хранит конфигурационные данные (например, настройки приложения) в виде пар “ключ-значение” или содержимого файлов (в открытом или зашифрованном виде).\n\nMinikube\nMinikube - это локальный кластер (одноузловой экземпляр, запускаемый в виртуальной среде) Kubernetes от создателя оригинального k8s.\n\nsudo cp ~/.minikube/ca.crt /usr/local/share/ca-certificates/minikube.crt &amp;&amp; update-ca-certificates &amp;&amp; openssl verify /usr/local/share/ca-certificates/minikube.crt установка сертификатов в Linux \nImport-Certificate -FilePath \"$HOME\\.minikube\\ca.crt\" -CertStoreLocation Cert:\\LocalMachine\\Root &amp;&amp; Import-Certificate -FilePath \"$HOME\\.minikube\\profiles\\minikube\\client.crt\" -CertStoreLocation Cert:\\CurrentUser\\My &amp;&amp; ls Cert:\\LocalMachine\\Root | Where-Object Subject -Match \"minikube\" установка сертификатов в Windows\nminikube start --vm-driver=hyperv --memory=4g --cpus=2 запустить кластер и создать виртуальную машину \nminikube status статус работы кластера \nminikube stop остановить кластер \nminikube delete удалить виртуальную машину \nminikube profile list узнать информацию о драйвере, ip, версии и количество Nodes \nminikube dashboard --port 8085 запустить api сервер и интерфейс состояния\nminikube addons list  список доступных дополнений и их статус работы \nminikube addons enable metrics-server активировать дополнение, которое предоставляет метрики для HPA, такие как загрузка процессора и использование памяти \nkubectl get deployment metrics-server -n kube-system текущее состояние развертывания metrics-server в кластере \nkubectl get pod,svc -n kube-system отобразить список системных подов и сервисов в кластере (pod/metrics-server-7fbb699795-wvfxb) \nkubectl logs -n kube-system deployment/metrics-server отобразить логи metrics-server \nkubectl top pods отобразить метрики на подах (CPU/MEM) \nminikube addons disable metrics-server отключить дополнение\nminikube addons enable ingress включить Nginx Ingress Controller \nkubectl get pods -n kube-system отобразить список системных подов (должен появиться ingress-nginx-controller) \nminikube tunnel --alsologtostderr создает виртуальный LoadBalancer в Minikube, для перенаправления трафика на нужный сервис, вместо использования NodePort\n\nMicrok8s\nMicrok8s - это полностью совместимый и легкий Kubernetes в одном пакете, работающий на 42 разновидностях Linux от компании Canonical.\nsnap install microk8s --classic установка \nmicrok8s status --wait-ready отобразить статус работы (дождаться инициализации служб Kubernetes) и список дополнений \nmicrok8s start запустить или остановить (stop) MicroK8s и его службы \nmicrok8s enable dashboard запустить dashboard \nmicrok8s enable dns установка обновлений \nsudo usermod -a -G microk8s $USER &amp;&amp; mkdir -p ~/.kube &amp;&amp; chmod 0700 ~/.kube добавить текущего пользователя в группу управления microk8s (создается при установке) \nalias kubectl='microk8s kubectl' добавить псевдоним, для использования команды kubectl через microk8s \nkubectl get nodes отобразить список нод \nkubectl config view --raw &gt; $HOME/.kube/config передать конфигурацию в MicroK8s, для использования с существующим kubectl\n\nK3s\nK3s — это полностью совместимый дистрибутив Kubernetes в формате единого двоичного файле, который удаляет хранение драйверов и поставщика облачных услуг, а также добавляет поддержку sqlite3 для backend хранилища от компании Rancher Labs (SUSE).\ncurl -sfL https://get.k3s.io | sh - установка службы в systemd и утилит kubectl, crictl, k3s-killall.sh и k3s-uninstall.sh \nsudo chmod 644 /etc/rancher/k3s/k3s.yaml &amp;&amp; sudo chown $(id -u):$(id -g) /etc/rancher/k3s/k3s.yaml назначить права на конфигурацию текущему пользователю \nsudo cat /var/lib/rancher/k3s/server/node-token токен авторизации \ncurl -sfL https://get.k3s.io | K3S_URL=https://192.168.3.101:6443 K3S_TOKEN=&lt;TOKEN&gt; sh - передать переменные окружения K3S_URL и K3S_TOKEN токен для установки на рабочие ноды (команда удаления: sudo /usr/local/bin/k3s-agent-uninstall.sh) \nsudo nano /boot/firmware/cmdline.txt включить cgroups v1 вместо v2 =&gt; systemd.unified_cgroup_hierarchy=0 cgroup_enable=memory cgroup_memory=1 \nk3s kubectl get nodes отобразить список нод в кластере \nsudo k3s crictl ps отобразить список всех запущенных контейнеров, включая системные для работы класетра \nsudo k3s etcd-snapshot save создать снапшот etcd (распределённого key-value хранилища, которое отвечает за состояние всего кластера Kubernetes) \nsudo k3s etcd-snapshot restor восстановление кластера из снапшота\n\nDashboard\nПример развертывания Kubernetes Dashboard в кластере k3s:\n\n\nHeadlamp\nHeadlamp - это современная альтернатива Dashboard c расширенным функционалом, созданная сообществом Kubernetes Special Interest Groups.\n\n\nk9s\nK9s - это TUI интерфейс для взаимодействия с кластерами Kubernetes (базовое управление и просмотр логов) с поддержкой плагинов.\nwget https://github.com/derailed/k9s/releases/latest/download/k9s_linux_amd64.deb &amp;&amp; sudo apt install ./k9s_linux_amd64.deb &amp;&amp; rm k9s_linux_amd64.deb установка в системе с архитектурой amd64 \nwget https://github.com/derailed/k9s/releases/latest/download/k9s_linux_arm64.deb &amp;&amp; sudo apt install ./k9s_linux_arm64.deb &amp;&amp; rm k9s_linux_arm64.deb установка в системе с архитектурой arm64 \nwinget install k9s || scoop install k9s || choco install k9s || curl.exe -A MS https://webinstall.dev/k9s | powershell установка в Windows\n\nПодключаем плагин kubectl-node-shell как плагин k9s в файле ~/.config/k9s/plugins.yaml для подключения к терминалу хоста под пользователем root:\n\n\nkubectl\necho \"source &lt;(kubectl completion bash)\" &gt;&gt; ~/.bashrc включить автодополнение для kubectl в bash \necho \"alias k=kubectl &amp;&amp; complete -F __start_kubectl k\" &gt;&gt; ~/.bashrc добавить псевдоним k для команды kubectl \nkubectl completion fish | source автодополнение в fish shell\nKUBECONFIG=~/.kube/config:~/.kube/config2 использовать несколько файлов kubeconfig одновременно (в выводе объеденяет конфигурацию) \nkubectl config view отобразить текущую конфигурацию (настройка подключения kubectl к Kubernetes, которое взаимодействует с приложением через конечные точки REST API)\nkubectl config get-contexts отобразить список всех доступных контекстов (список кластеров) \nkubectl config current-context отобразить текущий контекст \nkubectl config use-context default переключить контекст (установить контекст default как контекст по умолчанию)\nkubectl auth can-i --list отобразить права доступа\nkubectl cluster-infoотобразить адреса главного узла и сервисов \nkubectl cluster-info dump вывести состояние текущего кластера \nkubectl cluster-info dump --output-directory=./cluster-state выгрузить состояние текущего кластера в директорию cluster-state (информация для отладки)\nkubectl api-resources отобразить все поддерживаемые типы ресурсов\nkubectl get events --sort-by=.metadata.creationTimestamp вывести все логи, отсортированные по времени\nkubectl get nodes отобразить список node и их статус работы, роль (master или node), время запуска и версию \nkubectl get node --selector='!node-role.kubernetes.io/master' отобразить все рабочие узлы (с помощью селектора исключаем узлы с меткой master) \nkubectl describe nodes rpi-105 отобразить детальную информацию по конкретной ноде (labels, annotations, системная информация, запущенные поды и используемые ими и суммарно нодой ресурсы, а также логи - events) \nkubectl top nodes отобразить метрики всех нод\nkubectl get namespaces вывести список все доступных пространств имен\nkubectl get jobs -A проверить статус выполнения заданий во всех namespace\nkubectl get pv --sort-by=.spec.capacity.storage вывести список PersistentVolumes (физический или логический том, например, NFS или локальное хранилища на конкретной ноде), отсортированные по емкости \nkubectl get pvc -A отобразить все PersistentVolumeClaim (запрос PV для использования в контейнерах для хранения данных) во всех неймспейсах\nkubectl create deployment torapi --image=lifailon/torapi:latest --replicas=3 --dry-run=client -o yaml генерация манифеста deployment.yaml \nkubectl create service loadbalancer torapi --tcp=8444:8443 --dry-run=client -o yaml генерация манифеста service.yaml в режиме балансировки нагрузки (port:targetPort (порт контейнера))\nkubectl diff -f ./deployment.yaml сравнить текущее состояние кластера с состоянием, в котором находился бы кластер в случае применения манифеста\nkubectl get deployments отобразить статус всех Deployments в указанном namespace (-n kubernetes-dashboard), которые в свою очередь управляют Pod-ами (RADY - текущее количество желаемых реплик в рабочем состояние, например, 2 из 2 и UP-TO-DATE — количество реплик, обновленных до последней версии)\nkubectl get pods отобразить статус всех подов \nkubectl get pods --show-labels отобразить все заданные lables в подах \nkubectl get pods --field-selector=status.phase=Running отобразить все запущенные поды (фильтрация по статусу) \nkubectl get pods -o name отобразить только имена в формате pod/&lt;podName&gt;\nkubectl get pods -o wide выводит дополнительную информации в текстовом формате (для подов это внутренний ip-адрес и название ноды, на которой он работает) \nkubectl get pods -o json отобразить подробный вывод в формате json или yaml \nkubectl get pods -o=custom-columns=NAME:.metadata.name,STATUS:.status.phase,NODE:.spec.nodeName отобразить нужные поля таблицы вывода в пользовательском формате\nkubectl top pods отобразить нагрузку на подах \nkubectl top pods --containers отобразить метрики вместе с используемыми в подах контейнерами\nKUBE_EDITOR=\"nano\" kubectl edit deployments.apps/torapi отредактировать манифест Deployment в редакторе nano\nkubectl get rs состояние реплик (ReplicaSet) для всех подов (DESIRED - желаемое количество экземпляров-реплик и CURRENT - текущее количество реплик) \nkubectl scale deployments/torapi --replicas=3 масштабировать или уменьшить количество подов в deployment до указанного числа реплик \nkubectl patch deployment/torapi --type=json -p '[{\"op\":\"replace\",\"path\":\"/spec/replicas\",\"value\":3}]' пропатчить текущую конфигурацию \nkubectl events rs/torapi изменения фиксируется в логах ReplicaSet (Scaled up replica set torapi-54775d94b8 from 2 to 3) \nkubectl describe deployments.apps/torapi отобразить подробную конфигурацию развертвывания (шаблон и логи) \nkubectl autoscale deployment torapi --min=2 --max=10 автоматически масштабировать развёртывание в диапазоне от 2 до 10 подов\nkubectl get services отобразить список сервисов (их TYPE, CLUSTER-IP, EXTERNAL-IP и PORT(S)), которые принимают внешний трафик \nkubectl get endpoints torapi-service отобразить на какие адреса (ip и порт) подов перенаправляется трафик сервиса\nkubectl delete service torapi-service удалить service\nkubectl logs torapi-54775d94b8-t2dhm отобразить логи выбранного пода (сообщения, которые приложение отправляет в stdout) \nkubectl logs -l app=torapi --follow выводить лог на всех запущенных репликах подов (фильтрация по label) в реальном времени (--follow)\nkubectl attach pods/torapi-54775d94b8-t2dhm\nkubectl exec torapi-54775d94b8-t2dhm -c torapi -- ls -lha выполнить команду в указанноv контейнере внутри указанного пода \nkubectl exec torapi-54775d94b8-t2dhm -c torapi -- env отобразить список глобальных переменных в контейнере (например определить $HOME) \nkubectl exec -it torapi-54775d94b8-t2dhm -c torapi -- curl http://localhost:8443/api/provider/list проверить доступность приложения внутри контейнера \nkubectl exec -it torapi-54775d94b8-t2dhm -c torapi -- sh запустить sh или bash сессию в контейнере пода\nkubectl -n $NS exec $pod -c $container -- sh -c \"for i in \\$(seq 1 $cpuCount); do yes $procName &gt; /dev/null 2&gt;&amp;1 &amp; done\" запустить нагрузку \nkubectl -n $NS exec $pod -c $container -- sh -c \"grep $procName /proc/[0-9]*/cmdline | awk -F'/proc/' '{split(\\$2,a,\\\"/\\\");sum=sum\\\" \\\"a[1]}END{print sum}' | xargs kill\" остановить нагрузку \nkubectl -n $NS exec $pod -c $container -- sh -c \"echo \\\"Количество процессов нагрузки: \\\"\\$((\\$(grep $procName /proc/[0-9]*/cmdline 2&gt;&amp;1 | wc -l)-3))\" получить количество процессов нагрузки (1 yes процесс = 1 vCPU)\nkubectl get cm получить все ConfigMap \nkubectl describe cm kube-root-ca.crt отобразить содержимое ConfigMap (на примере корневого сертифика)\nkubectl create secret generic admin-password --from-literal=username=admin --from-literal=password=pass создать секрет в формате ключ-значение \nkubectl create secret generic api-key --from-file=api-key.txt создать секрет из содержимого файла \nkubectl get secret получить список всех секретов \nkubectl describe secret admin-password получить информацию о секрете (размер в байтах) \nkubectl get secret admin-password -o yaml получить содержимое секретов в кодировке base64 \nkubectl get secret admin-password -o jsonpath=\"{.data.password}\" | base64 --decode декодировать содержимое секрета \nkubectl delete secret admin-password удалить секрет\nkubectl set image deployments/openrouter-bot openrouter-bot=lifailon/openrouter-bot:0.5.0 выполнить плавающие обновление образа работающих контейнеров (формат: containerName=imagePath:tag ) \nkubectl rollout status deployments/openrouter-bot проверить статус обновления \nkubectl set image deployments/openrouter-bot openrouter-bot=lifailon/openrouter-bot:0.1.0 выполнить обновление на несуществующую версию \nkubectl rollout undo deployments/openrouter-bot откатить deployment к редыдущему развёртыванию (к предыдущему известному и работающему состоянию) \nkubectl rollout history deployment/openrouter-bot отобразить историю образов \nkubectl rollout undo deployments/openrouter-bot --to-revision=1 откатиться к определённой ревизии из истории\nkubectl label pods podName new-label=awesome добавить метку \nkubectl annotate pods podName icon-url=http://goo.gl/XXBTWq добавить аннотацию\nКлючевые уровни детального вывода для отладки в Kubectl:\n--v=3\tРасширенная информация об изменениях \n--v=6\tПоказать запрашиваемые ресурсы \n--v=9\tПоказать содержимого HTTP-запроса в полном виде (включая заголовки)\n\nJSONPath\nkubectl get nodes -o=jsonpath='{.items[*].status.addresses[*].address}' отобразить ip-адреса всех node \nkubectl config view -o jsonpath='{.users[*].name}' получить список пользователей в конфигурации \nkubectl config view -o jsonpath='{.users[?(@.name == \"test\")].user.password}' получить пароль для пользователя test\nФункцияОписаниеПримерРезультат\ntextобычный текстkind is {.kind}kind is List\n@текущий объект{@}то же, что и ввод\n. или []оператор выбора по ключу{.kind}, {['kind']} или {['name\\.type']}List\n..рекурсивный спуск{..name}127.0.0.1 127.0.0.2 myself e2e\n*шаблон подстановки для получение всех объектов{.items[*].metadata.name}[127.0.0.1 127.0.0.2]\n[start:end:step]оператор индексирования{.users[0].name}myself\n[,]оператор объединения{.items[*]['metadata.name', 'status.capacity']}127.0.0.1 127.0.0.2 map[cpu:4] map[cpu:8]\n?()фильтрация{.users[?(@.name==\"e2e\")].user.password}secret\nrange и endперебор списка (цикл){range .items[*]}[{.metadata.name}, {.status.capacity}] {end}[127.0.0.1, map[cpu:4]] [127.0.0.2, map[cpu:8]]\n''интерпретируемая в кавычках строка{range .items[*]}{.metadata.name}{'\\t'}{end}127.0.0.1 127.0.0.2\n\n\nGo Template\nkubectl get pods -o jsonpath='{range .items[*]}{.spec.nodeName}{\": \"}{.metadata.name}{\"\\n\"}{end}' отобразить в формате nodeName: podeName \nkubectl get pods -o go-template --template '{{range .items}}{{.spec.nodeName}}: {{.metadata.name}}{{\"\\n\"}}{{end}}' тоже самое, используя Go template\nGo Template Playground Online\nПример условия и цикла:\n\nДля шаблона:\n\n\nDeployment and Service\n\nkubectl apply -f namespace.yaml\n\nkubectl apply -f deployment.yaml\n\nkubectl apply -f service.yaml\nkubectl get pods будет создано два пода \nkubectl logs torapi-54775d94b8-t2dhm отобразить логи пода, будут идти запросы от ip kube-probe/1.32 для проверки здоровья \nkubectl exec -it torapi-54775d94b8-t2dhm -- npm --version вывести версию npm внутри контейнера\n\nProxy and forward\nПроверить распредиление нагрузки в режиме LoadBalancer:\n\nkubectl proxy запустить прокси сервер для локального взаимодействия с частной сетью кластера Kubernetes через API (без авторизации), где автоматически создаются конечные точки для каждого пода в соответствии с его именем \ncurl http://localhost:8001 отобразить список всех доступных конечных точек (endpoints) \ncurl -s http://localhost:8001/api/v1/namespaces/rest-api/pods | jq -r .items[].metadata.name вывести список всех имен подов в указанном namespace \ncurl -s http://localhost:8001/api/v1/namespaces/rest-api/services/torapi-service:8444/proxy/api/provider/list конечная точка, которая напрямую проксирует запрос внутрь пода (к конечной точке приложения в контейнере)\nkubectl port-forward -n rest-api pods/torapi-54775d94b8-t2dhm 8443:8443 запустить проброс порта из пода \ncurl http://localhost:8443/api/provider/list\ncurl http://torapi-service.rest-api.svc.cluster.local:8444/api/provider/list запрос к поду из контейнера любого друго namespace внутри кластера (Использует Cluster-IP)\n\nHPA\nHPA (Horizontal Pod Autoscaling) - горизонтальное масштабирование позволяет автоматически увеличивать или уменьшать количество реплик (подов) в зависимости от текущей нагрузки по показателям метрик, получаемых из metrics-server. Если нагрузка на одну поду увеличивается, то реплика должна снять нагрузку с первого пода, тем самым средняя нагрузка на 1 под будет ниже.\nkubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml установить metrics-server в кластер\nkubectl top nodes отобразить метрики ресурсов для всех узлов в кластере \nkubectl get deployment metrics-server -n kube-system отобразить статус работы metrics-server \nkubectl logs -n kube-system deployment/metrics-server проверить логи metrics-server\nkubectl edit deployment metrics-server -n kube-system отключить проверку TLS\n\nkubectl rollout restart deployment metrics-server -n kube-system перезапустить metrics-server\n\nkubectl apply -f torapi-hpa.yaml\nkubectl top pods -n rest-api отобразить нагрузку на подах по cpu и memory \nkubectl get --raw \"/apis/metrics.k8s.io/v1beta1/namespaces/rest-api/pods\" | jq . получить метрики напрямую из API\nkubectl get hpa отобразить статус работы всех HPA и текущие таргеты (cpu: 1%/50%) \nkubectl get pods будет активен 1 под из 5 подов (вместо двух, изначально определенных в Deployment)\nkubectl describe hpa -n rest-api torapi-hpa отобразить статус работы HPA (текущее и тригерное значение для масштабирования)\n\n\nIngress\nIngress - это балансировщик нагрузки, который управляет HTTP или HTTPS трафиком в кластер и направляет его к нужным логическим сервисам (балансировка между нодами по имени и маршрутизация запросов к разным конечным точкам в пути).\nkubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/main/deploy/static/provider/cloud/deploy.yaml установить Ingress Controller в кластер \nkubectl get pods -n ingress-nginx \nkubectl get svc -n ingress-nginx\n\nkubectl apply -f ingress.yaml\nkubectl get ingress отобразить статус работы ingress (используемое proxy приложение, внешние адреса в балансировке и общий порт)\nИзменить работу масштабирования HPA на основе 50 и выше HTTP-запросов в секунду через метрику nginx_ingress_controller_requests:\n\nkubectl apply -f hpa.yaml\nkubectl get hpa отобразить статус работы HPA\n\nMetalLB\nMetalLB - балансировщик нагрузки для локальных кластеров, эмулирующий работу облачных провайдеров. Настраивается пул адресов, и в случае падения ноды, переводит IP-адреса сервисов на другую ноду. Для сервисов LoadBalancer (включая Ingress-контроллер) выдается один внешний виртуальный ip-адрес, который прописывается на внешнем DNS сервере.\n\nРазрешить анонсирование IP-адресов из default-pool в локальной сети через протокол ARP на уровне L2/Ethernet:\n\nkubectl apply -f l2-advertisement.yaml\nСоздаем новый пул адресов:\n\nkubectl apply -f ip-address-pool.yaml\nДобавляем annotations на нужном сервисе:\n\n\nLonghorn\nLonghorn — это распределённая блочная система хранения данных для Kubernetes с поддержкой управления через Web UI, которая превращает локальные диски нод в кластерное хранилище за счет репликации. Pod обращается к тому через Engine -&gt; Engine записывает данные во все реплики синхронно -&gt; Чтение может происходить из любой реплики\n\nТребуется установить зависимости на нодах:\n\nДоступ к данным:\n\n\nPersistentVolume\nНастройка NFS сервера:\n\nСоздание PersistentVolume в кластере (хранилище):\n\nkubectl apply -f pv-nfs.yaml\nkubectl get pv\nСоздание PersistentVolumeClaim для использования подом:\n\nkubectl apply -f pvc-nfs.yaml\nkubectl get pvc\n\nS3\nMinIO — это высокопроизводительное, совместимое с S3 решение для хранения объектов.\n\n\ns3fs\ns3fs - инструмент для монтирования S3 совместимого хранилища на базе FUSE, позволяя управлять файлами и каталогами в локальной файловой системе.\nsudo apt install -y s3fs установка \nsudo mkdir -p /mnt/s3 создать директорию для монтирования \necho \"admin:MinioAdmin\" &gt; /tmp/s3cred &amp;&amp; chmod 600 /tmp/s3cred сохранить авторизационные данные для подключения к s3 \ns3fs &lt;BUCKET_NAME:PATH&gt; &lt;MOUNTPOINT_PATH&gt; &lt;OPTION&gt; формат монтирования \nsudo s3fs velero /mnt/s3 -o url=http://localhost:9000 -o use_path_request_style -o passwd_file=/tmp/s3_cred монтировать файловую систему \nmount | grep /mnt/s3 отобразить точки монтирования \nsudo umount /mnt/s3 отмонтировать\n\n\nVelero\nVelero (ранее Heptio Ark) - это инструменты для резервного копирования и восстановления ресурсов кластера Kubernetes и постоянных томов.\n\nСоздаем креды для подключения к s3 хранилищу minio:\n\nУстановка в кластер:\n\nkubectl get pods -n velero проверяем, что под запущен \nkubectl logs deploy/velero -n velero проверяем, что нет ошибок подключения к s3 \nvelero backup-location get отобразить статус BSL (Backup Storage Location) (PHASE - Available)\nvelero backup create telegram-bot-backup --include-namespaces telegram запустить backup \nvelero schedule create telegram-daily --schedule \"0 3 * * *\" --include-namespaces telegram --ttl 168h запускать каждый день в 03:00 (ttl определяет автоматическуое удаление всех созданных velero ресурсов через 7 дней) \nvelero backup describe telegram-bot-backup --details отобразить статус резервного копирования (ключевое - статус, продолжительность копирования и список ресурсов) \nvelero backup get отобразить список всех бэкапов, их статус (Completed, Failed, InProgress) и namespace\nvelero restore create --from-backup telegram-bot-backup --include-namespaces telegram восстанавливает все ресурсы из указанного бэкапа \nkubectl get deployments -n telegram --show-labels отобразить все доступные lables в deployments \nkubectl get all -n telegram --show-labels отобразить все доступные ресурсы в указанном namespace \nvelero restore create --from-backup telegram-bot-backup --include-namespaces telegram --include-resources deployments,configmaps --selector app=your-deployment-name восстановить только конкретные ресурсы с фильтрацией по lables \nvelero restore get отобразить статус восстановления\n\nVelero UI\nvelero-ui - веб-интерфейс для управления Velero (vmware-tanzu).\n\n\nArgoCD\nArgo CD - это декларативный инструмент непрерывного развертывания Kubernetes, использующий методологию GitOps, где Git репозиторий является единственным источником правды.\n\nРежимы синхронизации:\n\nForce - принудительно пересоздает ресурсы, даже если Kubernetes запрещает их изменение без подтверждения (эквивалент, kubectl --force).\nPrune - удаляет любые ресурсы в кластере, которые отсутствуют в текущем состоянии Git-репозитория (т.е. помечены желтой корзиной).\nDry Run - тестовый запуск (проверка синхронизации), позволяющий отобразить какие изменения будут применены к кластеру без фактического их выполнения.\nApply Only - будет только добавлять/обновлять ресурсы, но никогда не удалит ресурсы (обратное действие Prune).\n\nОпции синхронизации:\n\nSkip Schema Validation - отключает проверку на соответствие YAML-манифестов официальной схеме Kubernetes OpenAPI, например, для работы с кастомными ресурсами (CRD) или при ошибках валидации.\nAuto-Create Namespace - автоматическое создание namespace перед синхронизацией ресурсов, если пространство имен, указанное в манифесте, не существует.\nPrune Last - изменяет порядок, сначала применяет новые ресурсы, дожидается их готовности, и только потом удаляет старые/устаревшие ресурсы.\nApply Out of Sync Only - обрабатывает только те ресурсы, которые Argo CD пометил как Out of Sync (который определяется после Refresh в процессе сравнения с Git-репозиторием), пропуская все остальные, ускоряя процесс.\nRespect Ignore Differences - игнорировать изменения в определенных полях, например, количество реплик, если используется HPA (Horizontal Pod Autoscaling).\nServer-Side Apply - использует логику объединения изменений на стороне API-сервера Kubernetes, а не на стороне клиента Argo CD, что помогает с большими ресурсами и предотвращает конфликты last-applied-configuration.\nReplace - вместо стандартного kubectl apply, для объединения изменений, использует kubectl replace, где полностью заменяются существующие объекты, или kubectl create, если объекта нет.\nRetry - если синхронизация завершается с ошибкой (например, API-сервер недоступен или лимит запросов превышен), будет повторяться попытка синхронизации через заданные интервалы времени.\n\n\nKeel\nKeel — это инструмент для автоматизации обновлений образов в Kubernetes.\nПример развертвывания Keel с помощью Helm Chart через ArgoCD:\n\nДобавить аннотации в Deployment для отслеживания обновлений образов по major (1.0), minor (1.1) или patch (1.1.1) версии:\n\n\nKrew\nKrew — менеджер плагинов для kubectl.\n\nПлагинОписание\nkubectx &amp; kubensБыстрое переключение между контекстами (кластерамси) и пространствами имен (требует установку fzf).\nktopМониторинг нагрузки всех node и pods в реальном времени.\nketall/get-allОтображает все ресурсы Kubernetes.\nkubectl-treeОтображает зависимости ресурсов в древовидном формате.\nkubectl-node-shellBash скрипт для подключения к оболочке операционной системы хоста (node, монтирует pode на базе Alpine).\nkubetailBash скрипт, позволяющий объединять логи из нескольких подов в один поток.\nkubetail &amp; DashboardПанель управления для просмотра логов в терминале или браузер.\nsternОдновременный просмотр логов из нескольких подов в одном потоке.\noutdatedОтображает устаревшие образы, которые доступны к обновлению.\n\n\nKubetail Dashboard:\n\n\nKompose\nKompose - инструмент, который конвертируемт спецификацию docker-compose в манифесты Kubernetes.\n\nkompose --file docker-compose.yaml convert конвертация\ndocker-compose bridge convert встроенный конвертер в compose на базе шаблонов helm.\n\nKustomize\nKustomize — это встроенный в kubectl (с версии 1.14) инструмент для управления и слияния конфигураций Kubernetes без использования шаблонизаторов (как в Helm). Он похож на Make, т.к. его действия объявлены в файле kustomization.yaml, и на sed, т.к. он выводит отредактированный текст (без создания новых и изменения исходных манифестов).\nkubectl version --client\ncurl -sSL \"https://raw.githubusercontent.com/kubernetes-sigs/kustomize/master/hack/install_kustomize.sh\" | bash &amp;&amp; mv kustomize $HOME/.local/bin/ установить внешний исполняемый файл\n\nФормат запуска: kustomize build &lt;path_dir/url&gt; || kubectl kustomize &lt;path_dir/url&gt;\nkubectl kustomize ./base объеденить все манифесты перечисленные в resources в один yaml файл (в правильном порядке), где к каждому ресурсу автоматически добавляется namespace,  указанный в kustomization файле\nkubectl apply -k ./base применить все перечисленные манифесты в файле kustomization.yaml\nKustomize работает по принципу наследования конфигураций, где директория base/ содержит базовые манифесты (например, deployment.yaml и service.yaml), а директория overlays/ — содержит изменения для разных окружений (например, overlays/dev и overlays/test), переопределяя только указанные параметры.\nПример структуры:\n\nПример дочернего файла overlays/test/kustomization.yaml:\n\nПример конфигурации для overlays/test/path-hpa.yaml:\n\nkubectl kustomize overlays/test/ проверить конфигурацию \nkubectl apply -k overlays/test применить конфигурацию\nГенерация configMap из файлов и переменных окружения:\n\n\nHelm\nHelm - это шаблонизатор для управления конфигурациями и менеджер пакетов Kubernetes, использующий чарты (charts, которые являются пакетами), содержащими всю информацию для установки и управления приложениями в Kubernetes.\ncurl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash\nПример базовой структуры:\n\nChart.yaml:\n\nvalues.yaml:\n\ntemplates/deployment.yaml:\n\nservice.yaml:\n\nhelm template torapi . напечатать итоговую спецификацию (проверить подстановку переменных) \nhelm install torapi . установка в кластер \nhelm upgrade torapi . обновление релиза (при изменение значение в values.yaml) \nhelm uninstall torapi . удалить\nПубликация и установка:\n\n\nAWS\nУстановка aws cli\nНастройка профиля по умолчанию (настройки подключения):\n\nПеременные окружения для подключения к облаку или localstack:\n\nСоздание s3 хранилища:\n\nСоздание группы, потока и запись логов в CloudWatch:\n\n\nAzure\nInstall-Module -Name Az -Scope CurrentUser -Repository PSGallery -Force установить все модули для работы с Azure \nGet-Module *Az.* список всех модулей\nGet-Command -Module Az.Accounts отобразить список команд модуля Az.Accounts \nConnect-AzAccount подключиться у учетной записи Azure \nGet-AzContext получить текущий статус подключения к Azure \nGet-AzSubscription получить список подписок Azure, доступных для текущего пользователя \nSet-AzContext установить контекст Azure для конкретной подписки и/или учетной записи \nDisconnect-AzAccount отключиться от учетной записи Azure\nGet-Command -Module Az.Compute \nGet-AzVM получить список виртуальных машин в текущей подписке или группе ресурсов \nGet-AzVMSize получить список доступных размеров виртуальных машин в определенном регионе \nGet-AzVMImage получить список доступных образов виртуальных машин \nNew-AzVM создать новую виртуальную машину \nRemove-AzVM удалить виртуальную машину \nStart-AzVM запустить виртуальную машину \nStop-AzVM остановить виртуальную машину \nRestart-AzVM перезагрузить виртуальную машину\nGet-Command -Module Az.Network \nGet-AzVirtualNetwork получить список виртуальных сетей в текущей подписке или группе ресурсов \nNew-AzVirtualNetwork создать новую виртуальную сеть \nRemove-AzVirtualNetwork удалить виртуальную сеть \nGet-AzNetworkInterface получить список сетевых интерфейсов \nNew-AzNetworkInterface создать новый сетевой интерфейс \nRemove-AzNetworkInterface удалить сетевой интерфейс\nGet-Command -Module Az.Storage \nGet-AzStorageAccount получить список учетных записей хранилища \nNew-AzStorageAccount создать новую учетную запись хранилища \nRemove-AzStorageAccount удалить учетную запись хранилища \nGet-AzStorageContainer список контейнеров в учетной записи хранилища \nNew-AzStorageContainer создать новый контейнер в учетной записи хранилища \nRemove-AzStorageContainer удалить контейнер\nGet-Command -Module Az.ResourceManager \nGet-AzResourceGroup получить список групп ресурсов в текущей подписке \nNew-AzResourceGroup создать новую группу ресурсов \nRemove-AzResourceGroup удалить группу ресурсов \nGet-AzResource получить список ресурсов \nNew-AzResource создать новый ресурс \nRemove-AzResource удалить ресурс\nGet-Command -Module Az.KeyVault \nGet-AzKeyVault список хранилищ ключей \nNew-AzKeyVault создать новое хранилище ключей в Azure \nRemove-AzKeyVault удалить хранилище ключей в Azure\nGet-Command -Module Az.Identity \nGet-AzADUser получить информацию о пользователях Azure Active Directory \nNew-AzADUser создать нового пользователя \nRemove-AzADUser удалить пользователя \nGet-AzADGroup получить информацию о группах \nNew-AzADGroup создать новую группу \nRemove-AzADGroup удалить группу\n\nManage-VM\n\nNew-AzResourceGroup -Name \"Resource-Group-01\" -Location \"EastUS\" создать группу ресурсов (логический контейнер, в котором происходит развертывание ресурсов Azure) \nGet-AzVMImageOffer -Location \"EastUS\" -PublisherName \"MicrosoftWindowsServer\" список доступных образов Windows Server для установки \n$cred = Get-Credential \nNew-AzVm -ResourceGroupName \"Resource-Group-01\" -Name \"vm-01\" -Location 'EastUS' -Image \"MicrosoftWindowsServer:WindowsServer:2022-datacenter-azure-edition:latest\" -Size \"Standard_D2s_v3\" -OpenPorts 80,3389 --Credential $cred создать виртуальную машину \nGet-AzVM -ResourceGroupName \"Resource-Group-01\" -Name \"vm-01\" -Status | Select @{n=\"Status\"; e={$_.Statuses[1].Code}} статус виртуальной машины \nStart-AzVM -ResourceGroupName \"Resource-Group-01\" -Name \"vm-01\" запустить виртуальную машину \nStop-AzVM -ResourceGroupName \"Resource-Group-01\" -Name \"vm-01\" -Force остановить виртуальную машину \nInvoke-AzVMRunCommand -ResourceGroupName \"Resource-Group-01\" -VMName \"vm-01\" -CommandId \"RunPowerShellScript\" -ScriptString \"Install-WindowsFeature -Name Web-Server -IncludeManagementTools\" установить роль веб-сервера IIS\n\nManage-Disk\n\n$diskConfig = New-AzDiskConfig -Location \"EastUS\" -CreateOption Empty -DiskSizeGB 512 -SkuName \"Standard_LRS\" создать диск на 512 Гб \n$dataDisk = New-AzDisk -ResourceGroupName \"Resource-Group-01\" -DiskName \"disk-512\" -Disk $diskConfig создание объекта диска для подготовки диска данных к работе \nGet-AzDisk -ResourceGroupName \"Resource-Group-01\" -DiskName \"disk-512\" список дисков \n$vm = Get-AzVM -ResourceGroupName \"Resource-Group-01\" -Name \"vm-01\" \nAdd-AzVMDataDisk -VM $vm -Name \"Resource-Group-01\" -CreateOption Attach -ManagedDiskId $dataDisk.Id -Lun 1 подключить диск к виртуальной машине \nUpdate-AzVM -ResourceGroupName \"Resource-Group-01\" -VM $vm обновить конфигурацию виртуальной машины \nGet-Disk | Where PartitionStyle -eq 'raw' | Initialize-Disk -PartitionStyle MBR -PassThru | New-Partition -AssignDriveLetter -UseMaximumSize | Format-Volume -FileSystem NTFS -NewFileSystemLabel \"disk-512\" -Confirm:$false инициализировать диск в ОС (необходимо подключиться к виртуальной машине) с таблицей MBR, создать раздел и назначить все пространство и форматировать в файловую систему NTFS\n\nVercel\nnpm i -g vercel установить глобально в систему Vercel CLI \nvercel --version выводит текущую версию установленного Vercel CLI \nvercel login выполняет вход в аккаунт Vercel (&gt; Continue with GitHub) \nvercel logout выполняет выход из аккаунта Vercel \nvercel init инициализирует новый проект в текущей директории (создает файл конфигурации vercel.json и другие файлы, необходимые для проекта) \nvercel dev запускает локальный сервер для проверки работоспособности (http://localhost:3000) \nvercel deploy загружает проект на серверы Vercel и развертывает его \nvercel link привязывает текущую директорию к существующему проекту на сервере Vercel (выбрать из списка) \nvercel unlink отменяет привязку текущей директории от проекта Vercel \nvercel env управляет переменными окружения для проекта \nvercel env pull подтягивает переменные окружения с Vercel в локальный .env файл \nvercel env ls показывает список всех переменных окружения для проекта \nvercel env add &lt;key&gt; &lt;environment&gt; добавляет новую переменную окружения для указанного окружения (production, preview, development) \nvercel env rm &lt;key&gt; &lt;environment&gt; удаляет переменную окружения из указанного окружения \nvercel projects управляет проектами Vercel \nvercel projects ls показывает список всех проектов \nvercel projects add добавляет новый проект \nvercel projects rm &lt;project&gt; удаляет указанный проект \nvercel pull подтягивает последние настройки окружения с Vercel \nvercel alias управляет алиасами доменов для проектов \nvercel alias ls показывает список всех алиасов для текущего проекта \nvercel alias set &lt;alias&gt; устанавливает алиас для указанного проекта \nvercel alias rm &lt;alias&gt; удаляет указанный алиас \nvercel domains управляет доменами, привязанными к проекту \nvercel domains ls показывает список всех доменов \nvercel domains add &lt;domain&gt; добавляет новый домен к проекту \nvercel domains rm &lt;domain&gt; удаляет указанный домен \nvercel teams управляет командами и членами команд на Vercel \nvercel teams ls показывает список всех команд \nvercel teams add &lt;team&gt; добавляет новую команду \nvercel teams rm &lt;team&gt; удаляет указанную команду \nvercel logs &lt;deployment&gt; выводит логи для указанного деплоя \nvercel secrets управляет секретами, используемыми в проектах \nvercel secrets add &lt;name&gt; &lt;value&gt; добавляет новый секрет \nvercel secrets rm &lt;name&gt; удаляет указанный секрет \nvercel secrets ls показывает список всех секретов \nvercel switch &lt;team&gt; переключается между командами и аккаунтами Vercel\n\nGitHub API\n$user = \"Lifailon\" \n$repository = \"ReverseProxyNET\" \nInvoke-RestMethod https://api.github.com/users/$($user) получаем информацию о пользователе \nInvoke-RestMethod https://api.github.com/users/$($user)/repos получаем список последних (актуальные коммиты) 30 репозиториев указанного пользователя \nInvoke-RestMethod https://api.github.com/users/$($user)/repos?per_page=100 получаем список последних (актуальные коммиты) 100 репозиториев указанного пользователя \nInvoke-RestMethod https://api.github.com/repos/$($user)/$($repository)/contents получаем содержимое корневой директории репозитория \nInvoke-RestMethod https://api.github.com/repos/$($user)/$($repository)/contents/source/rpnet.cs получаем содержимое файла в формате Base64 \n$commits = Invoke-RestMethod https://api.github.com/repos/$($user)/$($repository)/commits получаем список коммитов \n$commits[0].commit.message читаем комментарий последнего коммита \n$commits[0].commit.committer.date получаем дату последнего коммита \nInvoke-RestMethod https://api.github.com/repos/$($user)/$($repository)/commits/$($commits[0].sha) получаем подробную информацию изменений о последнем коммите в репозитории \n$releases_latest = Invoke-RestMethod \"https://api.github.com/repos/$($user)/$($repository)/releases/latest\" получаем информацию о последнем релизе в репозитории \n$releases_latest.assets.name список приложенных файлов последнего релиза \n$releases_latest.assets.browser_download_url получаем список url для загрузки файлов \n$($releases_latest.assets | Where-Object name -like \"*win*x64*exe*\").browser_download_url фильтруем по ОС и разрядности \n$(Invoke-RestMethod -Uri \"https://api.github.com/repos/Lifailon/epic-games-radar/commits?path=api/giveaway/index.json\")[0].commit.author.date узнать дату последнего обновления файла в репозитории \n$issues = Invoke-RestMethod https://api.github.com/repos/LibreHardwareMonitor/LibreHardwareMonitor/issues?per_page=500 получаем список открытых проблем в репозитории (получаем максимум 100 последних, по умолчанию забираем последние 30 issues) \n$issue_number = $($issues | Where-Object title -match \"PowerShell\").number получаем номер issue, в заголовке которого есть слово “PowerShell” \nInvoke-RestMethod https://api.github.com/repos/LibreHardwareMonitor/LibreHardwareMonitor/issues/$($issue_number)/comments отобразить список комментарием указанного issues \nInvoke-RestMethod https://api.github.com/repos/LibreHardwareMonitor/LibreHardwareMonitor/languages получаем список языков программирования, используемых в репозитории \nInvoke-RestMethod https://api.github.com/repos/LibreHardwareMonitor/LibreHardwareMonitor/pulls получаем список всех pull requests в репозитории \nInvoke-RestMethod https://api.github.com/repos/LibreHardwareMonitor/LibreHardwareMonitor/forks получаем список форков (forks) \nInvoke-RestMethod https://api.github.com/repos/LibreHardwareMonitor/LibreHardwareMonitor/stargazers?per_page=4000 получаем список пользователей, которые поставили звезды репозиторию \nInvoke-RestMethod https://api.github.com/repos/LibreHardwareMonitor/LibreHardwareMonitor/subscribers получаем список подписчиков (watchers) репозитория\n\nGitHub Actions\n\nRunner\nmkdir actions-runner; cd actions-runner \nInvoke-WebRequest -Uri https://github.com/actions/runner/releases/download/v2.316.1/actions-runner-win-x64-2.316.1.zip -OutFile actions-runner-win-x64-2.316.1.zip загрузить пакет с Runner последней версии \nif((Get-FileHash -Path actions-runner-win-x64-2.316.1.zip -Algorithm SHA256).Hash.ToUpper() -ne 'e41debe4f0a83f66b28993eaf84dad944c8c82e2c9da81f56a850bc27fedd76b'.ToUpper()){ throw 'Computed checksum did not match' } проверить валидность пакета с помощью hash-суммы \nAdd-Type -AssemblyName System.IO.Compression.FileSystem ; [System.IO.Compression.ZipFile]::ExtractToDirectory(\"$PWD/actions-runner-win-x64-2.316.1.zip\", \"$PWD\") разархивировать \nRemove-Item *.zip удалить архив \n./config.cmd --url https://github.com/Lifailon/egapi --token XXXXXXXXXXXXXXXXXXXXXXXXXXXXX авторизовать и сконфигурировать сборщика с помощью скрипта (что бы на последнем пункте создать службу для управления сборщиком, нужно запустить консоль с правами администратора) \n./run.cmd запустить процесс (если не используется служба) \nGet-Service *actions* | Start-Service запустить службу \nGet-Process *Runner.Listener* \n./config.cmd remove --token XXXXXXXXXXXXXXXXXXXXXXXXXXXXX удалить конфигурацию\n\nPipeline\n\n\nCI\nСборка Docker образа и отправка в Docker Hub:\n\n\nCD\nРазвертвывание приложения на бессерверной платформе Vercel:\n\n\nLogs\n$(Invoke-RestMethod https://api.github.com/repos/Lifailon/TorAPI/actions/workflows).total_count получить количество запусков всех рабочих процессов \n$(Invoke-RestMethod https://api.github.com/repos/Lifailon/TorAPI/actions/workflows).workflows подробная информации о запускаемых рабочих процессах \n$actions_last_id = $(Invoke-RestMethod https://api.github.com/repos/Lifailon/TorAPI/actions/workflows).workflows[-1].id получить идентификатор последнего события \n$(Invoke-RestMethod https://api.github.com/repos/Lifailon/TorAPI/actions/workflows/$actions_last_id/runs).workflow_runs подробная информация о последней сборке \n$run_id = $(Invoke-RestMethod https://api.github.com/repos/Lifailon/TorAPI/actions/workflows/$actions_last_id/runs).workflow_runs.id получить идентификатор запуска рабочего процесса \n$(Invoke-RestMethod \"https://api.github.com/repos/Lifailon/TorAPI/actions/runs/$run_id/jobs\").jobs.steps подробная информация для всех шагов выполнения (время работы и статус выполнения) \n$jobs_id = $(Invoke-RestMethod \"https://api.github.com/repos/Lifailon/TorAPI/actions/runs/$run_id/jobs\").jobs[0].id получить идентификатор последнего задания указанного рабочего процесса\n\n\nact\nact - пользволяет запускать действия GitHub Actions локально (используется в Gitea).\n\nact --list список доступных действий, указаных в файлах .github/workflows \nact -j build запуск указанного действия по Job ID (имя файла, не путать с названием Workflow) \nact -n -j build пробный запуск (–dry-run), без выполнения команд, для отображения всех выполняемых jobs и steps\n\nact -e event.json -W .github/workflows/build.yml -P ubuntu-24.04=catthehacker/ubuntu:act-latest запустить указанный файл workflow с переданным файлом переменных (предварительно определенных параметров) и указанным сборщиком \nact -e event.json -W .github/workflows/build.yml -P ubuntu-24.04=catthehacker/ubuntu:act-latest --artifact-server-path $PWD/artifacts примонтировать рабочий каталог в контейнер для сохранения артефактов\n\nact --secret-file .secrets \nact -s DOCKER_HUB_USERNAME=username -s DOCKER_HUB_PASSWORD=password передать содержимое секретов \nact push симуляция push-ивента (имитация коммита и запуск workflow, который реагирует на push) \nact --reuse не удалять контейнер из успешно завершенных рабочих процессов для сохранения состояния между запусками (кэширование) \nact --parallel запуск всех jobs одновременно или последовательно (–no-parallel, по умолчанию)\n\n\nGroovy\nБазовый синтаксис языка Groovy:\n\n\nJenkins\ndocker run -d --name=jenkins -p 8080:8080 -p 50000:50000 --restart=unless-stopped -v jenkins_home:/var/jenkins_home jenkins/jenkins:latest \nls /var/lib/docker/volumes/jenkins_home/_data/jobs директория хранящая историю сборок в хостовой системе \ndocker exec -it jenkins /bin/bash подключиться к контейнеру \ncat /var/jenkins_home/secrets/initialAdminPassword получить токен инициализации\n\ndocker exec -u root -it jenkins-remote-agent-01 /bin/bash подключиться к slave агенту под root \napt-get update &amp;&amp; apt-get install -y iputils-ping netcat-openbsd установить ping и nc на машину сборщика (slave)\njenkinsVolumePath=$(docker inspect jenkins | jq -r .[].Mounts.[].Source) получить путь к директории Jenkins в хостовой системе \nsudo tar -czf $HOME/jenkins-backup.tar.gz -C $jenkinsVolumePath . резервная копия всех файлов \n(crontab -l ; echo \"0 23 * * * sudo tar -czf /home/lifailon/jenkins-backup.tar.gz -C /var/lib/docker/volumes/jenkins_home/_data .\") | crontab - \nsudo tar -xzf $HOME/jenkins-backup.tar.gz -C /var/lib/docker/volumes/jenkins_home/_data восстановление\nwget http://127.0.0.1:8080/jnlpJars/jenkins-cli.jar -P $HOME/ скачать jenkins-cli (http://127.0.0.1:8080/manage/cli) \napt install openjdk-17-jre-headless установить java runtime \njava -jar jenkins-cli.jar -auth lifailon:password -s http://127.0.0.1:8080 -webSocket help получить список команд \njava -jar jenkins-cli.jar -auth lifailon:password -s http://127.0.0.1:8080 groovysh запустить консоль Groovy \njava -jar jenkins-cli.jar -auth lifailon:password -s http://127.0.0.1:8080 install-plugin ssh-steps -deploy устанавливаем плагин SSH Pipeline Steps\n\nAPI\n\n\nPlugins\nПлагинОписание\nPipeline: Nodes and ProcessesПлагин, который предоставляет доступ к интерпретаторам sh, bat, powershell и pwsh\nPipeline Utility StepsДобавляет методы readJSON, writeJSON, readYaml, writeYaml, readTOML, writeTOM, untar, unzip, и другие.\nHTTP RequestПростой REST API Client для отправки и обработки GET и POST запросов через метод httpRequest.\nCredentials Binding PluginДобавляет метод withCredentials для доступа к секретам.\nHashiCorp VaultАвтоматизирует процесс получения содержимого значений из Vault с помощью метода withVault\nAnsibleПараметраризует запуск ansible-playbook (требуется установка на агенте) через метод ansiblePlaybook.\nPipeline Stage ViewВизуализация шагов (stages) в интерфейсе проекта с временем их выполнения.\nRebuilderПозволяет перезапускать параметризованную сборку с предустановленными параметрами в выбранной сборке.\nSchedule BuildПозволяет запланировать сборку на указанный момент времени.\nJob Configuration HistoryСохраняет копию файла сборки в формате xml (который хранится на сервере) и позволяет производить сверку.\nExport Job ParametersДобавляет кнопку Export Job Parameters для конвертации все параметров в декларативный синтаксис Pipeline.\nSSH Pipeline StepsПлагин для подключения к удаленным машинам через протокол ssh по ключу или паролю.\nSSH Agent PluginПлагин для подключения к удаленным машинам с использованием ssh-agent и credentials.\nActive Choices ParametersАктивные параметры, которые позволяют динамически обновлять содержимое параметров.\nFile ParametersПоддержка параметров для загрузки файлов (перезагрузить Jenkins для использования нового параметра).\nSeparator ParameterПараметр для разграничения набора параметров на странице сборки задания с поддержкой HTML.\nCustom ToolsПозволяет загружать пакеты из интернета с помощью предустановленного набора команд.\nANSI ColorДобавляет поддержку стандартных escape-последовательностей ANSI для покраски вывода.\nEmail ExtensionОтправка сообщений на почту из Pipeline.\nTest Results AnalyzerПоказывает историю результатов сборки junit тестов в табличном древовидном виде.\nEmbeddable Build StatusПредоставляет настраиваемые значки (like shields.io), который возвращает статус сборки.\nPrometheus MetricsПредоставляет конечную точку /prometheus с метриками, которые используются для сбора данных.\nWeb MonitoringДобавляет конечную точку /monitoring для отображения графиков мониторинга в веб-интерфейсе.\nCloudBees Disk UsageОтображает использование диска всеми заданиями во вкладке Manage-&gt; Disk usage.\n\n\nCredentials\nПримеры использования метода withCredentials для извлечения и использования секретов:\n\n\nconfigFile\nЗагрузка конфигурации из Jenkins:\n\n\nSSH Agent\n\n\nSSH Steps and Artifacts\nДобавляем логин и Private Key для авторизации по ssh: Manage (Settings) =&gt; Credentials =&gt; Global =&gt; Add credentials =&gt; Kind: SSH Username with private key\nСценарий проверяет доступность удаленной машины, подключается к ней по ssh, выполняет скрипт hwstat для сбора метрик и выгружает json отчет в артефакты:\n\n\nUpload File Parameter\nПередача файла через параметр и чтение его содержимого:\n\n\nInput Text and File\nОстанавливает выполнение Pipeline и заставляет пользователя передать текстовый параметр и файл:\n\n\nHttpURLConnection\nЛюбой код Groovy возможно запустить и проверить через Script Console (http://127.0.0.1:8080/manage/script)\nПример API запроса к репозиторию PowerShell на GitHub для получения последней версии и всех доступных версий:\n\n\nhttpRequest\nПример HTTP запроса и чтения json файла с помощью плагинов HTTP Request и Pipeline Utility Steps:\n\n\nActive Choices Parameter\nПример получения списка доступных версий в выбранном репозитории и содержимого файлов для выбранного релиза, а также загрузка указанного файла:\n\n\nVault\nИнтеграция HashiCorp Vault в Jenkins Pipeline через REST API для получения содержимого секретов и использовая в последующих стадиях/этапах сборки:\n\n\nwithVault\nКоманда (скрипт) для загрузки kubectl в Custom tool:\n\nПолучение секретов (на примере содержимого kubeconfig) с помощью метода withVault:\n\n\nEmail Extension\nДля отправки на почту и настроить SMTP сервер в настройках Jenkins (System =&gt; Extended E-mail Notification)\nSMTP server: smtp.yandex.ru\nSMTP port: 587\nCredentials: Username with password (username@yandex.ru и app-password)\nUse TLS\nDefault Content Type: HTML (text/html)\nНастройка логирования в System Log: emailDebug + фильтр hudson.plugins.emailext и уровень ALL\n\n\nParallel\n\n\nAnsible\napt -y update &amp;&amp; apt -y upgrade \napt -y install ansible v2.10.8 \napt -y install ansible-core v2.12.0 \napt -y install sshpass\nansible-galaxy collection install ansible.windows установить коллекцию модулей \nansible-galaxy collection install community.windows \nansible-galaxy collection list | grep windows \nansible-config dump | grep DEFAULT_MODULE_PATH путь хранения модулей\napt-get -y install python-dev libkrb5-dev krb5-user пакеты для Kerberos аутентификации \napt install python3-pip \npip3 install requests-kerberos \nnano /etc/krb5.conf настроить [realms] и [domain_realm] \nkinit -C support4@domail.local \nklist\nansible --version \nconfig file = None \nnano /etc/ansible/ansible.cfg файл конфигурации\n\n\nHosts\nnano /etc/ansible/hosts\n\nansible-inventory --list проверить конфигурацию (читает в формате JSON) или YAML (-y) с просмотром все применяемых переменных\n\nWindows Modules\nansible us -m ping \nansible win_ssh -m ping \nansible us -m shell -a \"uptime &amp;&amp; df -h | grep lv\" \nansible us -m setup | grep -iP \"mem|proc\" информация о железе \nansible us -m apt -a \"name=mc\" -b повысить привилегии sudo (-b) \nansible us -m service -a \"name=ssh state=restarted enabled=yes\" -b перезапустить службу \necho \"echo test\" &gt; test.sh \nansible us -m copy -a \"src=test.sh dest=/root mode=777\" -b \nansible us -a \"ls /root\" -b \nansible us -a \"cat /root/test.sh\" -b\nansible-doc -l | grep win_ список всех модулей Windows \nansible ws -m win_ping windows модуль \nansible ws -m win_ping -u WinRM-Writer указать логин \nansible ws -m setup собрать подробную информацию о системе \nansible ws -m win_whoami информация о правах доступах, группах доступа \nansible ws -m win_shell -a '$PSVersionTable' \nansible ws -m win_shell -a 'Get-Service | where name -match \"ssh|winrm\"' \nansible ws -m win_service -a \"name=sshd state=stopped\" \nansible ws -m win_service -a \"name=sshd state=started\"\n\nwin_shell (vars/debug)\n\nnano /etc/ansible/PowerShell-Vars.yml\n\nansible-playbook /etc/ansible/PowerShell-Vars.yml \nansible-playbook /etc/ansible/PowerShell-Vars.yml --extra-vars \"SearchName='LogLevel|Syslog'\" передать переменную\n\nwin_powershell\n\nnano /etc/ansible/powershell-param.yml\n\nansible-playbook /etc/ansible/powershell-param.yml\n\nwin_chocolatey\n\nnano /etc/ansible/setup-adobe-acrobat.yml\n\nansible-playbook /etc/ansible/setup-adobe-acrobat.yml\nnano /etc/ansible/setup-openssh.yml\n\nansible-playbook /etc/ansible/setup-openssh.yml\n\nwin_regedit\n\nnano /etc/ansible/win-set-shell-ssh-ps7.yml\n\nansible-playbook /etc/ansible/win-set-shell-ssh-ps7.yml\n\nwin_service\n\nnano /etc/ansible/win-service.yml\n\nansible-playbook /etc/ansible/win-service.yml\n\nwin_service_info\n\nnano /etc/ansible/get-service.yml\n\nansible-playbook /etc/ansible/get-service.yml\n\nfetch/slurp\n\nnano /etc/ansible/copy-from-win-to-local.yml\n\nansible-playbook /etc/ansible/copy-from-win-to-local.yml\n\nwin_copy\n\necho \"Get-Service | where name -eq vss | Start-Service\" &gt; /home/lifailon/Start-Service-VSS.ps1 \nnano /etc/ansible/copy-file-to-win.yml\n\nansible-playbook /etc/ansible/copy-file-to-win.yml\ncurl -OL https://github.com/PowerShell/PowerShell/releases/download/v7.3.6/PowerShell-7.3.6-win-x64.msi \nnano /etc/ansible/copy-file-to-win.yml\n\nansible-playbook /etc/ansible/copy-file-to-win.yml\n\nwin_command\n\nnano /etc/ansible/run-script-ps1.yml\n\nansible-playbook /etc/ansible/run-script-ps1.yml\n\nwin_package\n\nnano /etc/ansible/setup-msi-package.yml\n\nansible-playbook /etc/ansible/setup-msi-package.yml\n\nwin_firewall_rule\n\nnano /etc/ansible/win-fw-open.yml\n\nansible-playbook /etc/ansible/win-fw-open.yml\n\nwin_group\n\nnano /etc/ansible/win-creat-group.yml\n\nansible-playbook /etc/ansible/win-creat-group.yml\n\nwin_group_membership\n\nnano /etc/ansible/add-user-to-group.yml\n\nansible-playbook /etc/ansible/add-user-to-group.yml\n\nwin_user\n\nnano /etc/ansible/creat-win-user.yml\n\nansible-playbook /etc/ansible/creat-win-user.yml\nnano /etc/ansible/delete-win-user.yml\n\nansible-playbook /etc/ansible/delete-win-user.yml\n\nwin_feature\n\nnano /etc/ansible/install-feature.yml\n\nansible-playbook /etc/ansible/install-feature.yml\n\nwin_reboot\n\nnano /etc/ansible/win-reboot.yml\n\nansible-playbook /etc/ansible/win-reboot.yml\n\nwin_find\n\nnano /etc/ansible/win-ls.yml\n\nansible-playbook /etc/ansible/win-ls.yml\n\nwin_uri\n\nnano /etc/ansible/rest-get.yml\n\nansible-playbook /etc/ansible/rest-get.yml\n\nwin_updates\n\nnano /etc/ansible/win-update.yml\n\nansible-playbook /etc/ansible/win-update.yml\n\nwin_chocolatey\n\nInstall \nAPI \nDeployment\n\n\nJinja\nЛокальное использование:\npip install jinja2 --break-system-packages\ninventory.j2 шаблон для генерации\n\nenv.json файл с переменными\n\nrender.py скрипт для генерации файла inventory\n\npython render.py\nИспользование в Ansible для обновления файла hosts:\ninventory.ini\n\ntemplates/hosts.j2\n\nplaybook.yml\n\nansible-playbook -i inventory.ini playbook.yml --check --diff отобразит изменения без их реального применения \nansible-playbook -i inventory.ini playbook.yml -K позволяет передать пароль для root\n\nPuppet\n\nBolt\nBolt - это инструмент оркестровки, который выполняет заданную команду или группу команд на локальной рабочей станции, а также напрямую подключается к удаленным целям с помощью SSH или WinRM, что не требует установки агентов.\nDocs: https://www.puppet.com/docs/bolt/latest/getting_started_with_bolt.html\n\nnano inventory.yaml\n\nbolt command run uptime --inventory inventory.yaml --targets bsd выполнить команду uptime на группе хостов bsd, заданной в файле inventory\necho name: lazyjournal &gt; bolt-project.yaml создать файл проекта\nmkdir plans &amp;&amp; nano test.yaml создать директорию и файл с планом работ\n\nbolt plan show вывести список всех планов\nbolt plan run lazyjournal::test --inventory inventory.yaml --targets bsd -v запустить план\n\nSake\nSake - это командный раннер для локальных и удаленных хостов. Вы определяете серверы и задачи в файле sake.yaml, а затем запускаете задачи на серверах.\n\nПример конфигурации:\n\nsake run info --tags bsd запустить набор из 5 заданий из группы info\n\nSecret Manager\n\nBitwarden\nchoco install bitwarden-cli || npm install -g @bitwarden/cli || sudo snap install bw установить bitwarden cli \nbw login &lt;email&gt; --apikey авторизвация в хранилище, используя client_id и client_secret \n$session = bw unlock --raw получить токен сессии \n$items = bw list items --session $session | ConvertFrom-Json получение всех элементов в хранилище с использованием мастер-пароля \necho \"master_password\" | bw get item GitHub bw get password $items[0].name получить пароль по названию секрета \nbw lock завершить сессию\n\n\nInfisical\nnpm install -g @infisical/cli \ninfisical login авторизоваться в хранилище (cloud или Self-Hosting) \ninfisical init инициализировать - выбрать организацию и проект \ninfisical secrets получить список секретов и их SECRET VALUE из добавленных групп Environments (Development, Staging, Production)\n\n\nHashiCorp/Vault\nmkdir vault &amp;&amp; cd vault &amp;&amp; mkdir vault_config\nСоздать конфигурацию:\n\nЗапускаем в контейнере:\n\nПолучить ключи разблокировки и root ключ для первичной инициализации:\n\nВвести любые 3 из 5 ключей для разблокировки после перезапуска контейнера:\n\nПроверить статус (должно быть Sealed: false) и авторизацию по root ключу в хранилище:\n\nSecrets Engines -&gt; Enable new engine + KV \nAPI Swagger: http://192.168.3.101:8200/ui/vault/tools/api-explorer\n\nVault client:\n\n\nHashiCorp/Consul\nConsul используется для кластеризации и централизованного хранения данных Vault, а также как самостоятельное Key-Value хранилище.\nСоздать конфигурацию:\n\nЗапускаем в контейнере:\n\nСоздать root token, который будет использоваться для управления системой ACL и для создания политик доступа и других токенов доступа:\n\nСоздать новую политику доступа:\n\nСоздать новый токен доступа:\n\ncurl http://localhost:8500/v1/health/service/consul?pretty \ncurl --request PUT --data \"ssh-rsa AAAA\" http://localhost:8500/v1/kv/ssh/key записать секрет KV Store Consul \ncurl -s http://localhost:8500/v1/kv/ssh/key | jq -r .[].Value | base64 --decode извлечь содержимое секрета\n\nPrometheus\nПример создания экспортера для получения метрик температуры всех дисков из CrystalDiskInfo и отправки в Prometheus через PushGateway.\nФормат метрик:\n\nТипы данных:\n\ncounter - возрастающее значение (например, количество запросов, ошибок, завершенных задач)\ngauge - переменное значение (может увеличиваться или уменьшаться, например, нагрузка CPU, объем свободной памяти, температура)\nhistogram - разделенные данные на корзины (buckets, с помощью лэйбла le) и подсчет наблюдения в них (автоматически создает три метрики: _bucket, _sum, _count)\nsummary - аналогичен гистограмме, но вычисляет квантили\n\nСтроки метрик содержат имя, лейблы (в фигурных скобках) и значение.\n\nЗапускаем pushgateway в контейнере:\n\ndocker run -d --name pushgateway --restart unless-stopped -p 19091:9091 prom/pushgateway\n\nЗапускаем скрипт в консоли:\n\n\n\nПроверяем наличие метрик на конечной точке шлюза:\n\n\n\nДобавляем конфигурацию в prometheus.yml:\n\n\ndocker-compose kill -s SIGHUP prometheus применяем изменения\n\nСобираем контейнер в среде WSL с помощью dockerfile монтированием системного диска Windows:\n\n\ndocker build -t cdi-exporter . \ndocker run -d -v /mnt/c:/mnt/c --name cdi-exporter cdi-exporter\n\nСобираем стек из шлюза и скрипта в docker-compose.yml:\n\n\ndocker-compose up -d\n\nНастраиваем Dashboard в Grafana:\n\nПеременные для фильтрации запроса: \nhostName: label_values(exported_instance) \ndiskName: label_values(disk) \nМетрика температуры: disk_temperature{exported_instance=\"$hostName\", disk=~\"$diskName\"}\n\nPromQL Functions\nФункцияТип данныхОписаниеПример\nrate()counterСредняя скорость роста метрики за интервал (increase / seconds)rate(http_requests_total[$__rate_interval])\nirate()counterМгновенная скорость роста (использует последние 2 точки)irate(http_requests_total[1m])\nincrease()counterАбсолютный прирост метрики за интервал (end time - start time)increase(http_requests_total[5m])\nresets()counterКоличество сбросов counter-метрики за интервал.resets(process_cpu_seconds_total[1h])\ndelta()gaugeРазница между первым и последним значением метрики за интервалdelta(node_memory_free[[5m]])\nidelta()gaugeРазница между последними двумя точкамиdelta(node_memory_free[1m])\navg_over_time()gaugeСреднее значение за интервалavg_over_time(temperature[5m])\nmax_over_time()gaugeМаксимальное значение за интервалmax_over_time(temperature[5m])\npredict_linear()gaugeПредсказывает значение метрики через N секунд (для прогнозирования)predict_linear(disk_free[1h], 3600)\ncount()counter/gaugeКоличество элементов метрикиcount(http_requests_total) by (status_code)\nsum()counter/gaugeСуммирует значения метрик по указанным labelssum(rate(cpu_usage[5m])) by (pod)\navg()counter/gaugeСреднее значение метрики по указанным labelsavg(node_memory_usage_bytes) by (instance)\nmin() / max()counter/gaugeВозвращает минимальное/максимальное значениеmax(container_cpu_usage) by (namespace)\nround()counter/gaugeОкругляет значения до указанного числа дробных знаковround(container_memory_usage / 1e9, 2)\nfloor() / ceil()counter/gaugeОкругляет вниз/вверх до целого числаfloor(disk_usage_percent)\nabsent()counter/gaugeВозвращает 1, если метрика отсутствует (для алертинга)absent(up{job=\"node-exporter\"})\nclamp_min() / clamp_max()counter/gaugeОграничивает значения минимумом/максимумом (уменьшает если больше)clamp_max(disk_usage_percent, 100)\nlabel_replace()counter/gaugeИзменяет или добавляет labels в метрикеlabel_replace(metric, \"new_label\", \"$1\", \"old_label\", \"(.*)\")\nsort() / sort_desc()counter/gaugeСортирует метрики по возрастанию/убываниюsort(node_filesystem_free_bytes)\n\n\nGraylog\nGraylog Docker Image\n\nУстанавливаем MongoDB:\n\n\n\nИспользуем прокси для установки Elassticsearch:\n\n\n\nУказываем статический IP адрес для подключения к API\n\n\n\nНастройка Syslog на клиенте Linux:\n\nnano /etc/rsyslog.d/graylog.conf\n\nsystemctl restart rsyslog\n\nСоздать входящий поток (inputs) для Syslog на порту 514 по протоколу TCP:\n\nhttp://192.168.3.101:9000/system/inputs\n\nПример фильтра для логов:\n\nfacility:\"system daemon\" AND application_name:bash AND message:\\[ AND message:\\]\n\nНастройка Winlogbeat на клиенте Windows\n\nУстановка агента:\n\nДобавить отправку в Logstash:\ncode winlogbeat.yml\n\nИ закомментировать отправку данных в Elasticsearch (output.elasticsearch)\n.\\winlogbeat.exe -c winlogbeat.yml запустить агент с правами администратора в консоли\n\n\nНастроить Inputs для приема Beats на порту 5044\n\n\nHAProxy\nЗапускаем HAProxy в контейнере Docker:\n\nКонфигурация с проверкой тела ответа:\n\n\noptions:\n\nmaxconn максимальное количество одновременных соединений \nnbproc количество процессов HAProxy \noption httplog включает журналирование HTTP-трафика, полезно для отладки и мониторинга прохождения трафика через HAProxy и дает возможность просматривать HTTP-трафик в журнале, чтобы отслеживать запросы и ответы \noption httpchk отправлять HTTP-запросы к серверам в бэкенде, чтобы определить, работают ли они, это позволяет выявлять неработающие сервера и перераспределять запросы на работающие \noption httpchk GET / HTTP/1.1\\r\\nHost:\\ localhost отправляет GET-запрос на корневой путь (/) используя версию протокола HTTP 1.1, Host:\\ localhost - это часть заголовка Host, который также включается в HTTP-запрос и указывает на целевой хост, который проверяется \noption tcp-check активирует общую функцию TCP-проверок для всего бэкэнда, без необходимости указывать порт явно \ntcp-check connect port 443 HAProxy будет устанавливать соединение с серверами в бэкенде на порту 443 для проверки, что серверы доступны и способны принимать соединения на этом порту\n\nbalance:\n\nRound Robin (roundrobin) алгоритм используемый по умолчанию, отправляет запросы на сервера по очереди \nstatic-rr похож на roundrobin, но он сохраняет порядок серверов в конфигурации \nLeast Connections (leastconn) выбирает сервер с наименьшим количеством активных соединений, это полезно, если у серверов разная производительность или загруженность, так как запросы будут отправляться на менее загруженные серверы \nsource использует IP-адрес источника (клиента) для привязки к одному и тому же серверу, это означает, что клиент всегда будет направляться к одному и тому же серверу, это полезно для сохранения состояния сеанса \nuri запросы с одним и тем же URL (до знака вопроса) будут переправляться на один и тот же сервер, это полезно для балансировки запросов к разным частям приложения \nrdp-cookie используется для балансировки запросов RDP (Remote Desktop Protocol), он анализирует cookie-заголовок RDP для принятия решений о направлении запросов\n\nserver:\n\nssl использование SSL \nverify none отсутствие проверки сертификата \nweight распределение запросов по весу, если необходимо на определенный сервер отправлять больше запросов \ninter изменяет интервал между проверками, по умолчанию две секунды \nfall устанавливает допустимое количество неудачных проверок, по умолчанию три \nrise задает, сколько проходных проверок должно быть, прежде чем вернуть ранее отказавший сервер в ротацию, по умолчанию два \ncheck port 443 указать явную проверку порта для конкретного сервера \ncheck backup параметр означает, что сервер будет использоваться только в случае, если все основные серверы становятся недоступными и не будет участвовать в балансировке, пока основные серверы функционируют\n\nKeepalive\nVRRP (Virtual Router Redundancy Protocol) - сетевой протокол, предназначенный для увеличения доступности маршрутизаторов, выполняющих роль шлюза \nVRRP-пакеты - это специальные сообщения, которые узлы (маршрутизаторы/сервера) в VRRP-группе рассылают для сообщения своего состояния \nVIP (Virtual IP) - виртуальный IP адрес, который может автоматически переключаться между серверами в случае сбоя (frondend для haproxy/dns-rr), у кого в данный момент в сетевом интерфейсе прописан VIP, тот сервер и работает \nMaster - сервер, на котором в данный момент активен VIP (отправляет VRRP-пакеты на backup nodes) \nBackup - сервера на которые переключится VIP, в случае сбоя мастера (следим за мастером) \nVRID (virtual_router_id) - сервера, объединенные общим виртуальным IP (VIP) образуют виртуальный роутер, уникальный идентификатор которого, принимает значения от 1 до 255. Сервер может одновременно состоять в нескольких VRID, при этом для каждой VRID должны использоваться уникальные виртуальные IP адреса. \nMaster сервер с заданным интервалом отправляет VRRP пакеты на зарезервированный адрес multicast (многоадресной) рассылки или unicast на указанные ip-адреса, а все backup/slave сервера слушают этот адрес. Если Slave сервер не получает пакеты, он начинает процедуру выбора Master в соответствии с приоритетом, и если он переходит в состояние Master, то у него активирует VIP (поднимается виртуальный интерфейс) и отравляет gratuitous ARP. \nGratuitous ARP - это вид ARP ответа, который обновляет MAC таблицу на подключенных коммутаторах, чтобы проинформировать о смене владельца виртуального IP-адреса и MAC-адреса для перенаправления трафика. При настройке VRRP, в качестве адреса для виртуального IP не используется реальный адрес сервера, так как, в случае сбоя, его адрес переместится на соседний, и при восстановлении, он окажется изолированным от сети, и чтобы вернуть свой адрес, нужно отправить в сеть VRRP пакет, но не будет IP адреса, с которого это возможно сделать.\nnano /etc/keepalived/keepalived.conf\n\nstate &lt;MASTER|BACKUP&gt; начальное состояние при запуске, в режиме nopreempt единственное допустимое значение - BACKUP \ninterface интерфейс, на котором будет работать VRRP и подниматься VIP \nvirtual_router_id &lt;0-255&gt; уникальный идентификатор VRRP экземпляра, должен совпадать на всех серверах одной группы \npriority &lt;0-255&gt; задает приоритет при выборе MASTER, сервер с большим числом приоритета становится MASTER \nadvert_int &lt;число секунд&gt; определяет, с какой периодичностью мастер должен сообщать остальным о себе, и если по истечению данного периода сервера не получат от мастера широковещательный пакет, то они инициируют выборы нового мастера \nnopreempt если мастер пропал из сети, и был выбран новый мастер с меньшим приоритетом, то по возвращении старшего мастера, он останется в состоянии BACKUP, пока новый мастер не отвалится \npreempt_delay что бы мастером был конкретный сервер, то заменить настройку nopreempt на preempt_delay \nnotify скрипт, который будет выполняться при каждом изменении состояния сервера, и имя пользователя, от имени которого данный скрипт будет выполняться (логирование или отправка на почту) \nvirtual_ipaddress виртуальный IP-адрес (VIP), которые будет активирован на сервере в состоянии MASTER, должны совпадать на всех серверах внутри VRRP экземпляра \ntrack_interface мониторинг состояния интерфейсов, переводит VRRP экземпляр в состояние FAULT, если один из перечисленных интерфейсов находится в состоянии DOWN \ntrack_script мониторинг с использованием скрипта, который должен возвращать 0 если проверка завершилась успешно или 1, если проверка завершилась с ошибкой \nfall &lt;число&gt; количество раз, которое скрипт вернул не нулевое значение, при котором перейти в состояние FAULT \nrise &lt;число&gt; количество раз, которое скрипт вернул нулевое значение, при котором выйти из состояния FAULT \ntimeout &lt;число&gt; время ожидания, пока скрипт вернет результат, после которого вернуть ненулевое значение\njournalctl -u keepalived \ncat /var/log/messages | grep -i keepalived \ntail /var/run/keepalived.INSTANCE.web.state\n\nGlusterFS\nGlusterFS — это распределенная и масштабируемая файловая система, которая объединяет хранилища с разных серверов в единое виртуальное сетевое хранилище, обеспечивая отказоустойчивость и высокую производительность без необходимости отдельного сервера для метаданных. Работает поверх обычных файловых систем (например, ext4) с помощью технологии FUSE (в пользовательском пространстве).\n\n","path":null},{"url":"https://lifailon.github.io/linux/","title":"Linux","description":null,"body":"\n    \n\n\n    Заметки по работе с системными командами и консольными утилитами 🐧 Linux.\n\n\n\nbash\n\nПеременные\n\n\nМассивы\n\n\nЦиклы\n\n\nУсловия\nОператорОписание\n-zстрока пуста\n-nстрока не пуста\n=, (==)строки равны\n!=строки неравны\n-eqравно\n-neнеравно\n-lt, (&lt;)меньше (для арифметических вычислений)\n-le, (&lt;=)меньше или равно (для арифметических вычислений)\n-gt, (&gt;)больше (для арифметических вычислений)\n-ge, (&gt;=)больше или равно (для арифметических вычислений)\n!отрицание логического выражения\n-aлогическое и (&amp;&amp;, первая команда исполняется всегда, вторая - только в случае успешного завершения первой)\n-oлогическое или (||, первая команда исполняется всегда, вторая - только в случае неудачного завершения первой)\n\n\n\nФункции\n\ncalc 3 + 2 \ncalc 3 - 2\n\nПараметры\nnano script.sh\n\nchmod +x script.sh сделать скрипт исполняемым\nbash script.sh 1 2 3 4 5 передать параметры в скрипт\n-e file проверяет, существует ли файл \n-d file проверяет, существует ли файл, и является ли он директорией \n-f file проверяет, существует ли файл, и является ли он файлом \n-r file проверяет, существует ли файл, и доступен ли он для чтения \n-w file проверяет, существует ли файл, и доступен ли он для записи \n-x file проверяет, существует ли файл, и является ли он исполняемым \n-s file проверяет, существует ли файл, и не является ли он пустым\nПолучить список директорий и исполняемых файлов в дочерних директориях:\n\n\nfilesystem\nfile Console-Performance.sh узнать тип файла (текстовый, исполняемый файл, архив или другой) \nstat Console-Performance.sh узнать размер файла, количество блоков, занятых файлом на диске, количество жестких ссылок, права доступа и временные метки  \npwd текущая директория \nls -lh * отобразить содержимое каждого подкаталога отдельно \nls -lhaF отобразить скрытые директории (-a) с точкой и выделит директории (/) \nwhich top узнать путь до исполняемого файла \nstat $(which top) узнать дату последнего доступа к файлу  \ncat -n /etc/passwd просмотр содержимого файла с отображением номеров строк \nmkdir создать директорию \nmktemp -d создать временный файл/каталог (-d) \ntouch -t 202106222200.15 test.file создать файл и указать дату создания \ncp test.file test.file2 копировать файла/каталог \nmv test.file2 test.file3 переименовать/переместить файл/каталог \nrm -r test.file удалить каталог с файлами (-r)\n\nln\necho \"test\" &gt; testfile \nln /test/testfile /test/testlink создать жестку (hard) ссылку, которая указывает на один и тот же inode, т.е. они делят одно и то же физическое местоположение на диске \nrm testfile при удалении одного из файлов не приводит к удалению содержимого, пока существует хотя бы одна жесткая ссылка \nln -s /test/testfile /test/testlink создать символическую (-s - soft) ссылку, которая ссылается на файл testfile \necho \"test\" &gt;&gt; testfile при добавлении в оригинальный файл, все изменения будут отражены в testlink \nrm testfile при удалении исходного файла у ссылки будет ошибка (No such file or directory)\n\nzip\nrar a test.rar filename filename2 создать архив test.rar и добавить туда два файла (файлы копируются в архив) \nunrar x test.rar разархивировать \nzip -r test.zip filename архивировать (файлы копируются в архив) \nunzip test.zip разархивировать \nbzip2 filename архивировать в filename.bz2 (файлы перепещаются в архив) \nbunzip2 filename.bz2 разархивировать \ngzip filename архивировать в filename.gz (файлы перепещаются в архив) \ntar --totals -cvf archive.tar file1 file2 file3 архивировать три файла \nwget https://github.com/librespeed/speedtest-cli/releases/download/v1.0.10/librespeed-cli_1.0.10_linux_amd64.tar.gz загрузить архив \ngunzip librespeed-cli_1.0.10_linux_amd64.tar.gz извлечь из gz в tar \ntar -tf librespeed-cli_1.0.10_linux_amd64.tar отобразить содержимое архива \ntar -xvf librespeed-cli_1.0.10_linux_amd64.tar разархивировать \n./librespeed-cli --help \n./librespeed-cli --json\n\ngpg\ngpg -c filename зашифровать данные \ngpg filename.gpg расшифровать данные \ngpg --gen-key создавать пару ключей (публичный и приватный ключи) \ngpg --export -a 'User Name' &gt; publickey.asc экспорт публичного ключа \ngpg --import publickey.asc импорт на второй стороне \ngpg --encrypt --recipient 'Recipient Name' filename зашифровать данные с использованием публичного ключа получателя, только владелец приватного ключа сможет расшифровать эти данные \ngpg --decrypt encryptedfile.gpg расшифровать данные можно с помощью приватного ключа \ngpg --sign filename подписывать данные с использованием приватного ключа для подтверждения их подлинности и целостности \ngpg --verify signedfile.gpg проверка подписи с использованием публичного ключа отправителя\n\napi\n\ncurl\ncurl ifconfig.me узнать внешний ip \ncurl -v telnet://192.168.3.100:22 првоерить доступность порта и отобразить кому он принадлежит \ncurl -s -o /dev/null http://google.com подавить весь вывод (статистику –silent и –output) \ncurl -s -o /dev/null --show-error --fail http://google.com оставить вывод ошибок \ncurl http://192.168.3.101:8081/api/ --connect-timeout 5 задать timeout ожидания ответа в секундах \ncurl -IL https://github.com/Lifailon/hwstat/archive/refs/tags/hwstat-0.0.8.zip получить информацию о файле перед скачиванием (–head/–location) \ncurl -O https://raw.githubusercontent.com/Lifailon/hwstat/rsa/hwstat.sh скачать файл \ncurl -o /tmp/hwstat.sh https://raw.githubusercontent.com/Lifailon/hwstat/rsa/hwstat.sh указать путь \ncurl -Ik https://192.168.3.104:9443/ игнорировать ошибку самоподписанного сертификата SSL (–insecure) \ncurl -u &lt;user:password&gt; https://test.com/endpoint авторизация \ncurl -x \"http://Proxy:Proxy@192.168.3.100:9090\" \"https://kinozal.tv/rss.xml\" использовать Proxy-сервер \ncurl --insecure --ssl-reqd \"smtps://smtp.yandex.ru\" --mail-from \"src@yandex.ru\" --mail-rcpt \"dst@yandex.ru\" --user \"src@yandex.ru\" --upload-file out.txt отправка email через SMTPS (SMTP over SSL/TLS) сервер\n\ninfluxdb\n\n\nwget\nwget --spider https://download.nextcloud.com/server/releases/nextcloud-21.0.1.tar.bz2 проверить (–spider) работоспособность URL и узнать размер файла (Length) \nwget -O nextcloud.tar.bz2 https://download.nextcloud.com/server/releases/nextcloud-21.0.1.tar.bz2 скачать с указанным именем (-O)  \nwget -P /tmp https://download.nextcloud.com/server/releases/nextcloud-21.0.1.tar.bz2 скачать в указанную директорию (-P) \nwget -b -o ~/wget.log https://download.nextcloud.com/server/releases/nextcloud-21.0.1.tar.bz2 загрузить в фоновом режиме (-b) и записать вывод в лог-файл (-o)\n\ncurlie\ncurl -sS https://webinstall.dev/curlie | bash альтернатива curl и httpie (https://github.com/rs/curlie) \ncurlie get https://jsonplaceholder.typicode.com/posts возвращает заголовки ответа и отформатированный вывод JSON \ncurlie get https://jsonplaceholder.typicode.com/posts/1 \ncurlie get https://jsonplaceholder.typicode.com/posts -H \"Authorization: Bearer YOUR_TOKEN\" \ncurlie post https://jsonplaceholder.typicode.com/posts -d '{\"title\": \"foo\", \"body\": \"bar\", \"userId\": 1}'\n\nhttpie\nsudo snap install httpie HTTP-клиент командной строки (https://github.com/httpie/cli) \nhttps httpie.io/hello \nhttps POST pie.dev/post X-API-Token:123 name=John\n\njson\n\njq\napt install jq установить jq (https://github.com/jqlang/jq) \nnodes=$(curl -s -H \"Accept: application/json\" https://check-host.net/nodes/ips) получить список node \necho $nodes | jq обработка входных данных командой jq (вывод отображается в правильно структурированном формате, а все элементы подсвечиваются соответствующим цветом) \necho $nodes | jq '.nodes | length' количество дочерних объектов в блоке node[] \necho $nodes | jq -r .nodes[1] получить значение второго объекта массива в формате raw string (not JSON) \necho $nodes | jq -r .nodes[-1] получить значение последнего объекта массива \nhosts=$(curl -s -H \"Accept: application/json\" https://check-host.net/nodes/hosts) получить список всех хостов \necho $hosts | jq -r '.nodes | to_entries[].key' получить список всех вложенных ключей (адреса хостов) из объека (не является массивом) \necho $hosts | jq -r '.nodes | to_entries[].value' получить только значения всех вложанных ключей \necho $hosts | jq '.nodes.\"bg1.node.check-host.net\"' получить значение дочернего ключа nodes по имени \necho $hosts | jq '.nodes | [.[]] | last' преобразовать отдельные объекты внутри nodes в массив, и передать полученный вывод в функцию last для получения значений последнего объекта \necho $hosts | jq '.nodes | to_entries[].value.location[0] == \"ru\"' проверить каждый элемент объекта в условии на true/false (вернет массив) \necho $hosts | jq '.nodes | to_entries[] | {Host: .key, Country: .value.location[1], City: .value.location[2]}' получить данные key-value из объекта nodes и пересобрать массив с новыми значениями ключей \necho $hosts | jq -r '.nodes | to_entries[] | \"\\(.key) (\\(.value.location[1]), \\(.value.location[2]))\"' собрать массив строки из содержимого ключей \nvar=\"-\" &amp;&amp; echo $hosts | jq --arg v \"$var\" -r '.nodes | to_entries[] | \"\\(.key) \\($v) \\(.value.location[1]) \\($v) \\(.value.location[2])\"' передать внешнюю переменную, которая будет использоваться внутри запроса \necho $hosts | jq -r '.nodes | to_entries[] | select(.value.location[0] == \"ru\") | .key' произвести фильтрацию (select), что бы получить только нужные объекты \necho $hosts | jq '.nodes | to_entries[] | select(.value.location[0] != \"ru\") | .key' вывести объекты, которые не равны значению \necho $hosts | jq '.nodes | length' вывести общее количество объектов \necho $hosts | jq '.nodes | to_entries | map(select(.value.location[0] != \"ru\")) | length' создать массив функцией map() (объеденяет отдельные объекты {}{} группируются в один массив [{},{}]) только из тех объектов, которые соответствуют условию select() и вывести количество найденных объектов \necho $hosts | jq -r '.nodes | to_entries[] | select(.value.location[0] == \"ru\" or .value.location[0] == \"tr\") | .key' проверить два условия через or или and (для проверяемого типа данных int кавычки не используются) \necho $hosts | jq -r '.nodes | to_entries[] | select(.key | index(\"jp\")) | .key' вывести список хостов региона Japan, которые в названии ключа содержат ключевое слово jp (частичное совпадение в значении)\n\necho '{\"iso\": [{\"name\": \"Ubuntu\", \"size\": 4253212899}, {\"name\": \"Debian\", \"size\": 3221225472}]}' | jq '.iso[] | {name: .name, size: (.size / 1024 / 1024 / 1024 | tonumber * 100 | floor / 100 | tostring + \" GB\")}' получить ГБ из байт и округлить вывод до 2 символом после запятой \necho '{\"iso\": [{\"name\": \"Ubuntu\", \"progress\": 0.333}]}' | jq '.iso[] | {name: .name, progress: (.progress * 100 | floor / 100 * 100 | tostring + \" %\")}' получить процент из дробной части (33%) \necho '[{\"name\": \"Ubuntu\", \"added_on\": 1625072400}, {\"name\": \"Debian\", \"added_on\": 1625158800}]' | jq '.[] | {name: .name, date: (.added_on + 3 * 3600 | strftime(\"%H:%M:%S %d.%m.%Y\"))}' получить дату\n\nnetcheck\n\nnetcheck -t ping yandex.ru \nnetcheck -n \nnetcheck -t ping yandex.ru ru1.node.check-host.net \nnetcheck -t dns yandex.ru \nnetcheck -t http yandex.ru:443 5 \nnetcheck -t tcp yandex.ru:443\n\njc\napt install jc установить jc (https://github.com/kellyjonbrazil/jc) для преобразования вывода популярных инструментов командной строки, типов файлов и общих строк в JSON, YAML или словари Python, что позволяет передавать вывод в инструменты, такие как jq \ndig google.com | jc --dig \ndig example.com | jc --dig | jq -r '.[].answer[].data' \njc --pretty /proc/meminfo \nsystemctl list-units --all --plain --no-legend --no-pager | jc --systemctl -p\n\nbrew\n\n\nfx\nbrew install fx || snap install fx установить fx (https://github.com/antonmedv/fx) TUI интерфейс для JSON на GoLang \nhosts=$(curl -s -H \"Accept: application/json\" https://check-host.net/nodes/hosts) \necho $hosts | fx доступна навигация с раскрытием блоков и отображает ключи доступа для jq \nsource &lt;(fx --comp bash) добавить autocomplete в интерпритатор bash \necho $hosts &gt; hosts.json \nfx hosts.json .nodes .\\[\\\"ru1.node.check-host.net\\\"\\] .ip происходит автоматический вывод ключей и подстановка\n\njid\nbrew install jid установить jid (https://github.com/simeji/jid) для интерактивной фильтрации JSON данных с использованием автозавершения на GoLang \necho '{\"info\":{\"date\":\"2016-10-23\",\"version\":1.0},\"users\":[{\"name\":\"simeji\",\"uri\":\"https://github.com/simeji\",\"id\":1},{\"name\":\"simeji2\",\"uri\":\"https://example.com/simeji\",\"id\":2},{\"name\":\"simeji3\",\"uri\":\"https://example.com/simeji3\",\"id\":3}],\"userCount\":3}}' | jid .users[1].uri\n\njqp\nbrew install noahgorstein/tap/jqp установить jqp (https://github.com/noahgorstein/jqp) TUI интерфейс для отображения jq запросов на GoLang \ncurl -s https://api.github.com/repos/Lifailon/rudocs/contents | jqp слева отображается исходный файл, справа отфильтрованный вывод \ncurl -s https://check-host.net/nodes/hosts | jqp # пример для фильтрации: .nodes | to_entries[] | select(.value.location[0] == \"ru\") | .key\n\nxmllint\napt-get install libxml2-utils || snap install libxml2 || brew install libxml2 \ncurl -s https://kinozal.tv/rss.xml -x kinozal:proxy@192.168.3.100:9090 | xmllint --xpath '//rss/channel/item/link/text()' - \ncurl -s https://kinozal.tv/rss.xml -x kinozal:proxy@192.168.3.100:9090 | xmllint --xpath '//rss/channel/item[1]/link/text()' -\n\ndasel\nbrew install dasel установить dasel (https://github.com/TomWright/dasel) для обработки JSON, YAML, TOML, XML и CSV (поддерживает преобразование между форматами) на GoLang \necho '{\"name\": \"Tom\"}' | dasel -r json 'name' \necho '{\"name\": \"Tom\"}' | dasel -r json -w yaml конвертировать json в yaml \necho '{\"name\": \"Tom\"}' | dasel -r json -w xml конвертировать json в xml \necho '{\"name\": \"Tom\"}' | dasel put -r json -t string -v 'contact@tomwright.me' 'email' добавить свойство \necho '{\"email\": \"contact@tomwright.me\",\"name\": \"Tom\"}' | dasel delete -r json '.email' удалить свойство\n\ndasel -f users.json -r json \".users.[0].email\"\n\ndasel -f users.yaml -r yaml \".users.[1].email\"\n\ndasel -f users.toml -r toml \".users.[1].email\"\n\ndasel -f users.xml -r xml \".users.user.[0].email\"\n\nxq\napt-get install xq || brew install xq установить xq (https://github.com/sibprogrammer/xq) для XML и HTML на GoLang \ncurl -s https://kinozal.tv/rss.xml -x kinozal:proxy@192.168.3.100:9090 | xq -nx /rss/channel/item вывод содержимого дочерних элементов с тегами \ncurl -s https://kinozal.tv/rss.xml -x kinozal:proxy@192.168.3.100:9090 | xq -x /rss/channel/item/link вывести только содержимое (массив ссылок) \ncurl -s https://kinozal.tv -x kinozal:proxy@192.168.3.100:9090 | xq -nq \"head\" вывести блок head целиком (с тегами) \ncurl -s https://kinozal.tv -x kinozal:proxy@192.168.3.100:9090 | xq -q \"head\" вывести только текст из дочерних элементов выбранного тега (содержимое title) \ncurl -s https://kinozal.tv/browse.php?s=the+rookie -x kinozal:proxy@192.168.3.100:9090 | xq -nq \"body &gt; div &gt; div &gt; div &gt; div &gt; table &gt; tbody &gt; tr &gt; td\" \ncurl -s -X POST -u \"Login:Password\" \"http://localhost:9091/transmission/rpc\" | xq -q a -a href забрать X-Transmission-Session-Id для дальнейших запросов к API (обратиться к тэгу a и атрибуту href)\n\nhtmlq\nbrew install htmlq установить htmlq (https://github.com/mgdm/htmlq) like jq for HTML \ncurl -s https://kinozal.tv/browse.php?s=the+rookie -x kinozal:proxy@192.168.3.100:9090 | htmlq table tr td a -t получить содержимое таблицы (вывести только текст содержимого) \ncurl -s https://kinozal.tv/browse.php?s=the+rookie -x kinozal:proxy@192.168.3.100:9090 | htmlq table tr td a -a href получить только ссылки \ncurl -s -X POST -u \"Login:Password\" \"http://localhost:9091/transmission/rpc\" | htmlq a -a href забрать X-Transmission-Session-Id для дальнейших запросов к API (обратиться к тэгу a и атрибуту href)\n\nyq\nsnap install yq установить yq (https://github.com/mikefarah/yq) для YAML, JSON, XML, CSV и TOML \ncat /etc/netplan/*.yaml | yq .network.ethernets список адаптеров netplan \ncat /etc/netplan/*.yaml | yq .network.ethernets.eth0.nameservers.addresses[] вывести массив dns адресов, настроенные на адаптере \ncurl -s https://kinozal.tv/rss.xml -x kinozal:proxy@192.168.3.100:9090 | yq -p xml .rss.channel.item[1].link вывести ссылку из первого элемента \ncurl -s https://raw.githubusercontent.com/JingWangTW/dark-theme-editor/main/hugo.toml | yq -p toml .params.footer.socialLink прочитать конфигурацию Hugo\n\nyamllint\napt install yamllint установить yamllint (https://github.com/adrienverge/yamllint) для проверки синтаксических ошибки YAML-файла \nyamllint /etc/netplan/*.yaml\n\njsonlint\napt-get install -y nodejs установить Node.js \nnpm install jsonlint -g установить jsonlint (https://github.com/zaach/jsonlint) для проверки синтаксических ошибок JSON \necho '{\"name\":\"example\",\"value\":\"test\",}' | jsonlint \necho '{\"name\":\"example\",\"value\":\"test\"}' | jsonlint\n\ncsv\nbrew install csvlens установить csvlens (https://github.com/YS-L/csvlens) для взаимодестия в csv через TUR на Rust \npwsh -Command \"Get-Process | ConvertTo-Csv | Out-File process.csv\" \ncsvlens process.csv\n\nsttr\nsnap install sttr установить sttr (https://github.com/abhimanyu003/sttr) для конвертации и работы данными на GoLang \ncurl -s curl -s -H \"Accept: application/json\" https://check-host.net/nodes/hosts | sttr json-yaml конвертировать JSON в YAML \ncat /etc/netplan/*.yaml | sttr yaml-json | jq конвертировать YAML в JSON \ncurl -s https://raw.githubusercontent.com/Lifailon/hwstat/rsa/README.md | sttr markdown-html конвертировать Markdown в HTML \necho \"test\" | sttr hex-encode кодировать в HEX формат \necho \"74657374\" | sttr hex-decode декодировать HEX \necho \"Test\" | sttr upper поднять регистр (TEST) \necho \"Test\" | sttr lower опустить регистр (test) \necho -e \"test1\\ntest1\\ntest2\" | sttr unique-lines получить уникальные строки \necho -e \"a\\nz\\nb\" | sttr sort-lines сортировать строки по алфавиту \necho -e \"test1 \\ntest2\" | sttr remove-newlines удалить новые строки \necho -e \"test1\\ntest2\" | sttr count-chars посчитать количество символов \necho -e \"test1\\ntest2\" | sttr count-lines посчитать количество строк\n\ngrep\ncat /var/log/auth.log | grep sshd логи всех SSH-подключений \ncat /etc/passwd | grep -w sys поиск целого слова, окруженное пробелами (-w) \ncat /etc/ssh/sshd_config | grep -win port не учитывать регистр (-i) и отобразить номера строк (-n) \nss -n | grep -P \":22|:80|:443|:8080\" искать по нескольким шаблонам, использовать Regex (-E) \nss -n | grep -Pc \":22|:80\" вывести кол-во (--count) совпадений \nss -n | grep \"192.168.3...:\" поиск любых двух символов (.) \nss -n | grep \"192.168.3.*:\" поиск любого кол-ва (*) \ncat /etc/ssh/sshd_config | grep -v \"#\" вывести значения, не подходящие под критерии поиска (-v) \ncat /etc/zabbix/zabbix_agentd.conf | grep -v \"^#\" отсеить только в начале строки (^) \ncat /etc/zabbix/zabbix_agentd.conf | grep \"=$\" найти строки, которые кончаются $ на символ = (получить все параметры) \ncat /etc/zabbix/zabbix_agentd.conf | grep -Pv \"^$|^#\" удалить пустые строки ^$ и комментарии (^#) \ncat /etc/zabbix/zabbix_agentd.conf | grep -E \"#+{5}\" регулярное выражение (-E), где последний символ # повторяется 5 или более раз \necho -e \"Test\\ntest\\n123-45\" | grep -E \"[a-zA-Z\\-]\" искать только текст (где есть буквы и тире) \necho 'test&lt;version&gt;1.2.3&lt;/version&gt;test' | grep -P -o \"(?&lt;=&lt;version&gt;).*(?=&lt;/version&gt;)\" найти неизвестное значение (.*) между известными и вывести только найденное (-o) \necho \"test&lt;version&gt;3.6.4&lt;/version&gt;test\" | grep -Eo '[0-9.]+' найти любую цифру и точку на конце, которые повторяются любое кол-во раз подряд \necho $(lshw -class bus) | grep -P -o \"(?&lt;=Motherboard product: ).*(?=serial)\" с применение группировки (-P) \nzabbix_path=$(systemctl status zabbix-agent | grep -Po \"(?&lt;=-c ).*(?=.conf)\" | sed \"s/$/.conf/\") забрать путь до конфигурационного файла Zabbix агента \ncat $zabbix_path | grep -E \"^Server=|^ServerActive=\" найти имя сервера \ncat $zabbix_path | grep -Po \"(?&lt;=^Server=).+\" вывести только имя сервера \nresolvectl | grep \"DNS Servers\" -m 1 напечатать только первое совпадение (-m int) \nnetworkctl status | grep -A 3 \"DNS:\" найти строку и напечатать три строки после нее (-A) \nnetworkctl status | grep -B 3 \"DNS:\" найти строку и напечатать три строки до нее (-B) \nnetworkctl status | grep -C 1 \"DNS:\" найти строку и напечатать одну строки до нее и одну после (-C) \nresolvectl | grep -Ex \".+DNS Servers:.+\" вывести строки с точным совпадение (-x/like), сопоставлять только целые строки \nif echo \"GET\" | grep -Eq \"^GET\"; then echo da; else echo net; fi подавлять вывод (-q) для проверки условия \ncurl https://api.github.com/repos/PowerShell/PowerShell/releases/latest | grep -Eom 1 \"https://.+.deb\" забрать только первый подходящий под поиск\n\nripgrep\napt-get install ripgrep установить ripgrep, аналог grep на Rust \ncat /var/log/auth.log | rg sshd вывести журнал логов аудентификации фильтрацией по названию \ncat /var/log/auth.log | rg \"Accepted password for \\w+ from \\d+\\.\\d+\\.\\d+\\.\\d+\" вывести строки, где указано Accepted password for, далее любое слово (имя пользователя) и IP-адрес в формате x.x.x.x \ncat /var/log/auth.log | rg \"user \\w+\\(uid=\\d+\\)\" вывести строки с текстом user, затем имя пользователя (любое слово), и далее uid с числовым значением в скобках \ncat /var/log/auth.log | rg \"192\\.168\\.\\d+\\.\\d+\" вывести строки, где первые два октета соответствуют 192.168 \ncat /var/log/auth.log | rg \"sshd\\[\\d+\\]: .* port \\d+\" вывести строки, содержащие sshd с идентификатором процесса (например, sshd[4188420]), а затем текст port и номер порта \ncat /var/log/auth.log | rg \"\\b12:\\d{2}:\\d{2}\\b\" фильтрация по времени за последние 12 часов (время начинается с 12:, затем две цифры для минут и две для секунд)\n\nrga\napt install ripgrep fzf pandoc ffmpeg poppler-utils установить зависимости \nbrew install rga установить ripgrep-all и rga-fzf - инструмент для быстрого поиска в файлах по содержимому \nrga-fzf token поиск ключевого слова token во всех файлах\nrga \"fatal\" /var/log/syslog* поиск строк по слову fatal во всех файлах syslog (включая архивные)\n\nsig\nbrew install ynqa/tap/sigrs установить sig интерактивный grep на Rust \ncurl -s https://raw.githubusercontent.com/Lifailon/hwstat/rsa/README.md &gt; README.md \ncat README.md |&amp; sig -a\n\nsed\ncat /etc/passwd | sed -n \"1,5p\" отобразить с первой по пятую строку (p) \ncat /etc/passwd | sed \"$ d\" удалить (d) последнюю строку \ncat /etc/passwd | sed \"1,3d\" удалить c первой по третью строку (2,3d) \necho \"One 1\" | sed \"s/One/Two/; s/1/2/\" заменить One на Two и 1 на 2 \ncat /etc/zabbix/zabbix_agentd.conf | sed \"s/127.0.0.1/192.168.3.102/\" #  &gt; /etc/zabbix/zabbix_agentd.conf заменить (s) ip-адрес \ncat /etc/zabbix/zabbix_agentd.conf | sed \"/^#\\|^$/d\" удалить пустые строки ^$ и комментарии ^# \ntimedatectl | grep zone | sed -E \"s/.+zone: //\" удалить любое кол-во лимволов до слова “zone: “ включительно, используя Regex (-E/-r) \necho -e \"test\\ntest\" | sed \"2s/test/test2/\" заменить во второй строке (2s) \necho -e \"test\\ntest\\ntest\\ntest\" | sed \"2,3s/test/test2/\" заменить во второй и третей строке (2,3s) \necho -e \"test\\ntest\\ntest\\ntest\" | sed \"2ctest2\" заменить вторую строку (2c) \necho \"The test and test\" | sed \"s/test/test2/g\" заменить для каждого совпадения (/global) \necho \"The test and test\" | sed \"s/test/test2/2\" заменить для второго совпадения (/2) \necho \"line2\" | sed \"i\\line1\" добавить строку в начало (i) \necho \"line1\" | sed \"a\\line2\" добавить строку в конец (a) или в после указанной строки (2a) \necho \"11 22 33 34\" | sed \"y/123/234/\" заменить 1 на 2, 2 на 3, 3 на 4 (y) \nls -R | grep ':' | sed \"s/:$//; s/[^\\/]*\\// - /g\" удалить : в конце и заменить вначале строки \"/любое кол-во символов между/\" на \" - \" для всех (/g global) \necho \"test&lt;version&gt;3.6.4&lt;/version&gt;test\" | sed -r 's/[^&lt;]*&lt;(.*)&gt;.*/\\1/;s/&lt;.*//;s/.*&gt;//' использовать regex (-r) \nps aux | grep -E \"^zabbix .+ -c\" | sed -E \"s/^zabbix.+-c //\" найти процесс zabbix с ключем -c и оставить путь conf \necho \"MPEG-H HEVC, 88.5 Мбит/с, 3840x2160, 23.976 кадр/с, 10 бит\" | sed -nr 's/.* ([0-9]+x[0-9]+).*/\\1/p' выводить только найденные строки (-n) с заменой (s/), ищем только цифры [0-9] где одно или более вхождений (+) и между ними x, вывести только первую группу поиска (то, что в скобках) на печать (/p)\n\nawk\ncat /etc/passwd | awk -F: '{print \"name: \" $1 \" \\t Dir: \" $NF}' вывести содержимое первого и последнего $NF элемента в строке, используя разделитель “:” и табуляцию (\\t) \necho 'one two three four' | awk '{print $(NF-1)}' вывести содержимое преподследнего элемента \necho 'one two three four five' | awk '{print $((NF/2)+1)}' вывести содержимое из середины \necho \"One Two Three\" | awk '{$3=\"Four\"; print $0}' заменить третье значение/переменную в строке \ncat /etc/passwd | awk 'BEGIN{FS=\":\"; OFS=\" - \"} {print $1,$7}' указать разделитель послей (элементов) на вход (FS) и заменить его на выходе (OFS) \nuptime | awk 'BEGIN{RS=\" \"; ORS=\"\\n\"} {print $0}' указать разделитель записей (строк) на входе (RS) и заменить его на выходе (ORS) \necho -e \"12345\\n54321\" | awk 'BEGIN{FIELDWIDTHS=\"2 3\"}{print $1,$2}' указать фиксированное кол-во символов для разделения \nlsof | awk '{if($7==\"REG\")print $0}' условие для выборки по столбцу \ncat /etc/ssh/sshd_config | awk '/Port / {print $2}' условие поиска для вывода \ncat /etc/ssh/sshd_config | awk 'length $0 &gt; 1' вывести строки, которые длиннее, чем 1 символ (удалить пустые строки) \ncat /var/log/syslog | grep \"$date\" | awk '{print length($6)}' вывести длинну значения \nawk 'BEGIN{x = \"low\"; print toupper(x)}' использовать функцию для перевода в вверхний регистр \nawk 'BEGIN{x = \"LOW\"; print tolower(x)}' использовать функцию для перевода в нижний регистр \necho \"1 2 3 4:5:6\" | awk '{item=$4; split(item,array,\":\"); print array[2]}' разбить 4 значение на массив (используя функцию split) и забрать значение по 2-му индексу \nfree | awk '{if (NR == 2) print $0}' вывести только вторую строку \nfree | awk '{if (NR &gt;= 2) print $0}' вывести втроую и последующие строки \nfree | awk '{if (NF &gt;= 5) print $0}' вывести строки, где 5 или больше значений \ncat /etc/passwd | awk '{ if (NR &gt;= 10 &amp;&amp; NR &lt;= 20) print $0}' вывести с 10 по 20 строки \nlast | sed -n 1p | awk '$2=\" \",$4=\" \"{print $0}' вывести все, кроме 2 и 4 значения (заменить) \nps -A | awk '{sum=\"\"; for(i=1;i&lt;=NF;i++) { if (i != 2) {sum=sum\" \"$i} } print sum}' вывести все, кроме 2-го значения\ncut -d',' -f2,4 file.csv взять второй и четвертый столбцы \nawk -F',' '{if (NF &gt;= 4) print $2, $4}' file.csv\ngrep \"Error\" logs.txt \nawk '/Error/' logs.txt \nawk '/^Error [0-9]{3}:/' logs.txt\ngrep -c \"Success\" logs.txt посчитать количество совпадений \nawk '/Success/ {count++} END {print count}' logs.txt\nsed 's/Error/Success/g' file.txt замена слов \nawk '{gsub(/Error/, \"Success\"); print}' file.txt\nsort file.txt | uniq \nawk '!seen[$0]++' file.txt заполняем уникальный массив строк\nwc -w file.txt посчитать количество слов в файле \nawk '{count += NF} END {print count}' file.txt\nsed -n '10,20p' file.txt вывести с 10 по 20 строку \nawk 'NR&gt;=10 &amp;&amp; NR&lt;=20' file.txt\nawk '{sum += $1} END {print sum/NR}' numbers.txt получить среднее значение чисел в первом столбце \nawk '{ if ($2 &gt; 50000) print $1, \"&gt; 50K\"; else print $1, \"&lt; 50K\" }' data.txt вывести значение первого столбца, если значение второго столбца выше или ниже 50 тысяч \nawk '{ sum = 0; for (i = 1; i &lt;= NF; i++) sum += $i; print \"сумма:\", sum }' data.txt посчитать сумму числе в каждой строке \nawk '{ for (i = 1; i &lt;= NF; i++) sum[i] += $i } END { for (i in sum) print \"Столбец\", i, \"сумма:\", sum[i] }' data.txt посчитать сумму числе в каждом столбце\n\nprintf\ntop=$(top -bn1) \nprintf \"%s\\n\" \"${top[@]}\" вывести вывод массива построчно \nprintf \"%.2f \\n\" 1.1111 округлить до 2 символов после запятой \nprintf \"%.0f \\n\" 1.6 удалить дробную часть (округлить до 2) \nprintf \"Arg1: %s\\nArg2: %s\\n\" \"10\" \"20\" принимает и выводит аргументы (%s) в виде строки\n\ncut\necho \"1 2 3\" | cut -c 1,5 вывести первый и пятый симов (--bytes/--characters) \necho \"1 2 3\" | cut -c 1-3 вывести с первой по третий символ \necho \"1 2 3\" | cut -c3- удалить первые 2 символа \necho -e \"test1,test2,test3\\ntest1,test2,test3\" | cut -d , -f 2-100 указать разделитель полей/столбцов (--delimiter) и какие столбцы вывести (--fields) с 2 по 100 \necho -e \"test1,test2,test3\\ntest1,test2,test3\" | cut -d , -f 1,3 | sed \"s/,/ /\" вывести 1 и 3 \necho -e \"test1,test2,test3\\ntest1 test2 test3\" | cut -d , -f 1,3 -s печатать строки, где есть разделитель (-s)\n\nrev\necho \"D:\\plex-content\\Rick.and.Morty.S07.2023.WEBDLRip.MegaPeer\" | rev | cut -d \\\\ -f 1 | rev забрать последний элемент в пути (вначале разворачивает всю строку, забирает первый элемент и разворачивает строку обратно) \necho \"D:\\plex-content\\Rick.and.Morty.S07.2023.WEBDLRip.MegaPeer\" | sed -r 's/.+\\\\//' удалить все до последнего слеша \necho \"D:\\plex-content\\Rick.and.Morty.S07.2023.WEBDLRip.MegaPeer\" | sed 's/.*\\\\\\(.*\\)/\\1/' удаляет все до последнего слеша и забирает одну группу захвата, что остается после удаления, и заменяет вывод на первую группу (1) \necho \"D:\\plex-content\\Rick.and.Morty.S07.2023.WEBDLRip.MegaPeer\" | awk -F '\\\\' '{print $NF}' забрать последний элемент массива (NF)\n\ntr\necho \"10 20 100 200\" | tr 1 2 translate заменяет 1 на 2 для всех подходящих сомволов (20 20 200 200) \necho \"1 2 3\" | tr \" \" \",\" заменить пробелы на запятые (1,2,3) \necho \"1 2 3\" | tr -d \" \" удалить пробелы (123)\n\nman\n\ncheat sh\ncurl cheat.sh/curl \ncurl cheat.sh/grep \ncurl cheat.sh/sed \ncurl cheat.sh/awk \ncurl cheat.sh/jq \ncurl cheat.sh/iptables \ncurl cheat.sh/find\n\ntldr\npip3 install tldr упрощенный вариант man с примерами использования \ntldr curl веб-версия: https://manned.org/man/curl\n\ndebug\ntrap 'echo \"$BASH_COMMAND\"' DEBUG построчная отладка скриптов bash, команда trap перехватывает сигнал DEBUG, посылаемый перед выполнением команды и выводит команду на экран \ntrap 'echo \"$BASH_COMMAND\";read' DEBUG read ожидает ввода с клавиатуры (Enter или Ctrl+C) перед выполнением каждой командой \nbash -x script.sh отладка (печать команд и их аргументов по мере их выполнения) \nbash -x -c \"ls -l\" | grep *.sh | awk '{print $5,$NF}' запуск команды через интерпритатор bash и вывод отладки \nbash --debug script.sh проверка на ошибки \napt-get install shellcheck установить shellcheck \nshellcheck -S error hwstat.sh error/warning/info/style \npip3 install thefuck установить thefuck \nbas hwstat.sh запустить команду с ошибкой \nfuck автоматически исправляет последнюю ошибочную команду из выпадающего списка (up/down)\n\ntools\npip install toolong \ntl /var/log/auth.log интерактивный просмотр логов в консоли с фильтрацией \ntl access.log* --merge просмотр нескольких файлов\napt install bat аналог cat (https://github.com/sharkdp/bat) с подсветкой синтаксиса\nbat /etc/netplan/*.yaml\ntree /var/log/ древовидный просмотр директорий и дочерних файлов\ncargo install --locked broot установить broot (https://github.com/Canop/broot), аналог tree \nbroot kinozal-bot/\necho 'deb http://cz.archive.ubuntu.com/ubuntu jammy main universe' &gt;&gt; /etc/apt/sources.list &amp;&amp; apt update \napt install exa установить аналог ls (https://github.com/ogham/exa) \nexa $(pwd) -l --icons отобразить иконки с подсветкой прав доступа\ncargo install eza аналог ls (https://github.com/eza-community/eza) на базе exa \neza -l --icons \neza --tree kinozal-bot/\ncargo install lsd аналог ls (https://github.com/lsd-rs/lsd) \nlsd -l kinozal-bot/\ncolumn /etc/passwd -t -s \":\" \nnetcheck -t ping yandex.ru us1.node.check-host.net | sed -r 's/\"//g; s/,$//; s/\\{|\\}|\\[|\\]//' | column -t -s \":\" распарсить JSON и добавить отступ (табуляцию) для колонок\nls /home | wc -l word count выводит количество строк (--line) \nls /home | wc -w количество слов (--words) \nls /home | wc -m количество символом (--chars) \nls /home | wc -c количество символов/байт (--bytes)\necho \"(5.5-2.2)\" | bc математические вычисления \necho \"(5.5-2.2)\" | bc | sed -E \"s/\\..+//\" удалить дробную часть \necho \"1 &lt; 2\" | bc возвращает булевое значение (1 - да или 0 - нет) \necho \"1 &gt; 2\" | bc false (0) \nicmp_ignore=$(cat /proc/sys/net/ipv4/icmp_echo_ignore_all) забрать значение \nif (( $(echo \"$icmp_ignore == 1\" | bc) )); then echo \"true\"; else echo \"false\"; fi проверить в условии арефметическое значение на равенство (возвращает 0 - false или 1 - true)\na=1 \nb=0.55 \necho $(bc &lt;&lt;&lt; \"scale=2; $a+$b\") \necho \"print $a+$b\" | perl \necho \"print($a+$b)\" | python3 \necho \"print($a+$b)\" | lua \necho \"puts $a+$b\" | ruby \npwsh -Command $a+$b\necho -e \"key1\\nkey2\\nkey3\" &gt; 1.txt \necho -e \"value1\\nvalue2\\nvalue3\" &gt; 2.txt \npaste 1.txt 2.txt -d : объединяет два файла в один многоколоночный вывод \ncat /etc/passwd | paste -s -d + объеденить (join) многострочный файл, используя указанный delimiter\necho -e \"test1\\ntest2\" &gt; 1.txt \\ echo -e “test\\ntest2\\ntest3” &gt; 2.txt \ndiff 1.txt 2.txt -c ! есть изменения, + есть новая строка \ndiff 1.txt 2.txt -yi сравнивает в две колонки (| есть изменения, + есть новая строка) и игнорировать регистр (-i) \ndiff 1.txt 2.txt -u объеденяет два файла в один вывод с отображением изменений (+/) \ndiff 1.txt 2.txt -ibBEt не учитывать пробелы (-b) и пустые строки (-B), игнорировать изменения в табуляциях (-E) и заменить табуляции на пробелы в выводе (-t) \ndiff -c &lt;(echo \"$predu\") &lt;(echo \"$du\") сравнить содержимое переменных\nsnap install diff-so-fancy \ndiff -u file-1.txt file-2.txt | diff-so-fancy\napt install jdupes \njdupes . поиск дубликатов\ncat /etc/passwd | sort -r отсортировать вывод по алфовиту в обратном порядке (-r) \ndu -h ~ | sort -n сортировать по арифметическому значению (-n) размер файлов и директорий \nls -l | sed 1d | sort -nk5 сортировка по пятой колонке (-k) \ncat $tmp | sort -t \".\" -nk4 сортировать по четвертой колонке, используя разделитель (-t) точку\necho -e \"1 2\\n1 2\\n2 1\\n1 2\" | uniq удаляет соседние одинаковые строки \necho -e \"1 2\\n1 2\\n2 1\\n1 2\" | sort | uniq удалить все дубликаты \necho -e \"1 2\\n1 2\\n2 1\\n1 2\" | sort | uniq -c добавляет в начало каждой строки кол-во повторений \necho -e \"1 2\\n1 2\\n2 1\\n1 2\" | sort | uniq -u отобразить только уникальные строки, без строк с повторениями\nls -l | fold -w 50 задать ширину вывода каждой строки, выпадающее за указанный предел переносится на новую строку \nls -l | fold -w 50 -s разбивать строки только на символах пробела (–space)\ncat /var/log/syslog | head -n 5 выводит первые 5 строк файла\ncat /var/log/syslog | tail -n 5  просмотр последних 5 строк файла \ntail -f /var/log/syslog просмотр содержимого файла в реальном времени\napt install multitail \nmultitail -f /var/log/auth.log -f /var/log/kern.log \nmultitail -l \"journalctl -fu ssh\" -l \"journalctl -fu cron\"\nless /var/log/dmesg вывести лог ядра с возможностью пролистывания\nwatch df -h выводит на экран и обновляет состояния подключенных устройств каждые 2 секунды\necho \"line1\" | tee test.txt перезаписать файл (&gt;) \nls &gt; /dev/null перенаправить вывод в null \necho \"line2\" | tee -a test.txt добавить (&gt;&gt;) текст новой стройокй в конец файла \necho -e \"line3\\nline4\" &gt;&gt; test.txt добавить две новые строки\nsplit -l 100 input_file.txt output_prefix разделить файл на части по 100 строк в каждой \nsplit -b 10M input_file.txt output_prefix разделить файл на части по указанному размеру (например, 10MB)\nyes предназначена для автоматического вывода строки или символа, повторяющегося бесконечно (для нагрузки системы), либо для автоматического подтверждения запросов в других командах\n\ndust\nsnap install dust установить dust - альтернатива du на Rust \ndust /home/lifailon выводит график используемого пространства по директориям и файлам для анализа занятого пространства \ndust -s показывает размер файла, а не объем используемого им дискового пространства \ndust -n 30 выводит 30 каталогов (по умолчанию — высота терминала) \ndust -d 3 показывает 3 уровня подкаталогов \ndust -D отобразить только директории \ndust -F отобразить только файлы \ndust -f считайте файлы вместо дискового пространства \ndust -i не показывать скрытые файлы \ndust -z 10M минимальный размер, включать только файлы размером более 10 МБ \ndust -z 40000/30MB/20kib исключить выходные файлы/каталоги размером менее 40 000 байт/30 МБ/20 КБ \ndust -o si/b/kb/kib/mb/mib/gb/gib формат вывода \ndust -e \"\\.png$\" включать только те файлы, которые соответствуют регулярному выражению (например, только файлы png) \ndust -v \"\\.png$\" регулярное выражение для игнорирования файлов с разрешением png \ndust -j  | jq вывод в формате JSON \ndust -P отключить индикатор прогресса\n\nfd\napt install fd-find установить fd  быстрая альтернатива find на Rust \nfdfind без аргументов заменяет ls -R для рекурсивного поиска в текущем каталоге \nfdfind log /var ищет в указанной директории по частичному совпадению \nfdfind -tf \"\\.yaml$\" / | fzf ищет все файлы (--type file или директории --type directory) с расширением .yaml с корня с выводов в fzf \nfdfind --type file -H pre-commit поиск скрытых файлов \nfdfind --type f -e pdf . $HOME | rofi -keep-right -dmenu -i -p FILES -multi-select | xargs -I {} xdg-open {} интеграция с rofi (графическое меню) \nfd -e zip -x unzip рекурсивно найти все zip-архивы и распаковать их\n\nfd-fzf\n\n\nfindutils\n\nfind\nfind / -name \"*.sql\" найти файлы, начать поиск с корня (/) \nfind / -iname \"mysql\" найти файлы не учитывая регистр (-i) \nfind ~ -name \"test.*\" -not -name \"*.conf\" найти все файлы с наименование test, которые имеют любое расширение, за исключением (-not) расширения .conf \nfind ~ -amin -10 поиск файлов по дате последнего чтения (-amin) которые просматривались (cat/nano) за последние 10 минут \nfind ~ -type f -mmin -10 найти файлы (-type f), которые были модифицированны за последние 10 минут (-nmin) \nfind ~ -type f -mtime +1 -mtime -7 найти все файлы, модифицированные между 1 и 7 днями назад \nfind ~ -type d -mtime +1 -mtime -7 поиск директорий \nfind ~ -size +50M -size -100M поиск файлов в Linux по их размеру, от 50 до 100 мегабайт \nfind / -perm 444 поиск файлов по режиму доступа (только чтение для всех) \nfind /home/lifailon/ -user root поиск файлов по владельцу \nfind /home/lifailon/ -group root поиск по группе \nfind /root/ -empty поиск пустых файлов или директорий\n\nexec\ntouch -t 202306222200.15 /tmp/test.txt создать файл с указанной датой создания \nfind /tmp -type f -mtime +30 -exec rm -f {} \\; удалить все файлы, котоыре не изменялись больше 30 дней \nfind /tmp -type f -name \"*.txt\" -exec rm -f {} \\; удалить все текстовые файлы в директории tmp \ndd if=/dev/zero of=/var/log/test.log count=11 bs=1M создать файл заполненный нулями указанного размера \nfind /var/log -type f -name \"*.log\" -size +10M -exec rm -f {} \\; удалить все лог-файлы, объёмом больше 10 Мбайт\n\nlocate\napt install plocate альтернатива стандартного mlocate с более быстрым и меньшим по размеру индексом \nupdatedb обновить индексы базы данных \nls -lh /var/lib/[mp]locate/*.db проверить размер базы данных \nlocate .torrent найти по частичному совпадению в имени или расширению \nlocate .torrent -c отображает количество найденных результатов \nlocate -n 10 .torrent вывести 10 результатов \nlocate -i Kinozal-Bot игнорировать регистр \nlocate -r \"\\.log$\" использовать регулярные выражения\n\nlocate-linux -p /home/lifailon/ -q /qbittorrent \nlocate-linux -p /home/lifailon/.bash_history -q /qbittorrent\n\nxargs\necho {1..10} | xargs -n1 -P4 bash -c 'echo Start task $1 &amp;&amp; sleep $1 &amp;&amp; echo Complate task $1' _ принимает 1 аргумент и запускат до 4-х потоков за раз\ndu -a /var/log | awk '{print $2}' | xargs fincore передать вывод первой команды (построчно) в аргументы следующей\n\nfincore\nsudo apt install util-linux-extra \nfincore /var/log/* отобразить все файлы, которые находятся в кэше страниц оперативной памяти (page cache) \nfincore /var/log/syslog 4.3M (данные файла, хранящиеся в памяти) 1100 (кол-во страниц хранящиеся в памяти PageCache) 199.7M (размер файла) \nfincore /var/log/syslog -J вывод в JSON (–raw вывод без табулияции, –noheadings без заголовков, –byte размер файла в байтах) \napt install vmtouch \nvmtouch /var/log/syslog узнать какой процент указанного файла находится в страничном кеше (Resident Pages: 1100/51119  4M/199M  2.15%)\n\nlspage\n\n\nbashrc\nnano ~/.bashrc\n\nsource ~/.bashrc применить политики (перечитать профиль)\n\noh-my-bash\nУстановить oh-my-bash (обновляет профиль, делая рядом резервную копию старого файла в .bashrc.omb-TIMESTAMP):\nbash -c \"$(curl -fsSL https://raw.githubusercontent.com/ohmybash/oh-my-bash/master/tools/install.sh)\"\nls ~/.oh-my-bash/themes/ список доступных тем \nsed -iE \"s/^OSH_THEME=.*/OSH_THEME=powerline/\" ~/.bashrc &amp;&amp; source $HOME/.bashrc изменить тему\nНастроить динамический профиль:\n\n\nfzf\napt install fzf установить fzf \nhistory | fzf интерактивный поиск с фильтрацией \neval $(history | fzf | awk '{print $2}') выполнить (eval) выбранную команду из списка (добавить в макрос) \nfind / -name \"*.yaml\" | fzf | xargs cat найти в системе все файлы yaml, запустить по ним поиск и передача в cat для чтения выбранного файла\nПоиск, чтение и фильтрация системных логов и контейнеров Docker через fzf с покраской вывода в tailspin:\n\n\nfzf-obc\nУстановить fzf over bash complete (выпадающий список автодополнения команд) и добавить в профиль bash:\n\n\nhstr\nsudo apt install hstr установить hstr (https://github.com/dvorka/hstr) \nhstr -f избранное (Ctrl+F добавить в избранное) \nhstr -n bash log вывести на экран отфильтрованную историю\n\n\nhstr-fzf\nПоиск по истории команд с помощью функции hstr или псевдонима h и комбинации Ctrl+R через fzf:\n\n\nmcfly\nУстановить homebrew и mcfly, который заменяет поиск истории через Ctrl-R на интеллектуальную поисковую систему, которая учитывает рабочий каталог и контекст недавно выполненных команд:\n\n\ncompgen\ncompgen -c выводит все команды, доступные в текущей оболочке \ncompgen -a выводит все алиасы, определенные в текущей оболочке \ncompgen -b выводит все встроенные команды Bash \ncompgen -k выводит все зарезервированные слова Bash \ncompgen -v выводит все переменные, определенные в текущей оболочке \ncompgen -A export выводит все экспортированные переменные \ncompgen -A function выводит все функции, определенные в текущей оболочке \ncompgen -A arrayvar выводит все массивы, определенные в текущей оболочке (echo ${BASH_ALIASES[@]}) \ncompgen -A hostname выводит все известные хосты \ncompgen -A job выводит все активные задания (ping ya.ru &gt; /dev/null &amp;) \ncompgen -A service выводит все службы (для систем, поддерживающих службы, например, через systemd) \ncompgen -d выводит все директории в текущем каталоге \ncompgen -f выводит все файлы и директории в текущем каталоге \ncompgen -u выводит всех пользователей системы \ncompgen -g выводит все группы системы \ncompgen -W \"start stop status restart\" st выводит список слов из wordlist, которые начинаются с prefix “st”\n\ncron\nls /etc/cron.d/ директория хранения задач различных пакетов (atop, sysstat) \nls -l /etc/cron.hourly &amp;&amp; ls -l /etc/cron.daily &amp;&amp; ls -l /etc/cron.weekly &amp;&amp; ls -l /etc/cron.monthly директории для скриптов, которые надо выполнять раз в час, день, неделю и месяц \ncrontab -l просмотр задач \ncrontab -l | grep -Pv \"^$|^#\" отобразить только активные задания \ncrontab -u lifailon -l отобразить задачи пользователя root \ncrontab -e создать задачу от текущего пользователя \nsudo crontab -u root -e создать задачу от пользователя root \ncrontab -r очистить все задачи\ncat /etc/crontab\n\n0,14,29,44 * * * * каждые 15 минут \n*/15 * * * * каждые 15 минут\n00 23 * * * systemctl restart zabbix-agent &amp;&amp; echo $(date): Reboot Zabbix Agent use cron &gt;&gt; /var/log/reboot.log выполнять перезапуск службы каждый день в 23:00 и писать в лог \n00 03 * * 6 echo $(date): Reboot Operating System use cron &gt;&gt; /var/log/reboot.log &amp;&amp; /sbin/reboot выполнять перезагрузку системы один раз в субботу в 3 часа ночи \n@reboot date &gt;&gt; ~/date-reboot.log выполнять один раз после перезагрузки\njournalctl -eu cron \ncat /var/log/syslog | grep -i cron\n\necho \"*/1 * * * * bash /root/google-icmp-test.sh\" &gt;&gt; /var/spool/cron/crontabs/root добавить задачу в планироващик на выполнение скрипта каждую минуту\ncp /etc/hosts /etc/hosts.bak backup файла \necho \"11.11.11.11 google.com\" &gt;&gt; /etc/hosts изменить адрес для недоступности хоста \ncp /etc/hosts.bak /etc/hosts восстановить файл \ncat /var/log/icmp-test.log | grep unavailable отфильтровать лог по unavailable\n\nsystemctl\nsystemctl reload ssh обновить конфигурацию сервиса из файла юнита (если у юнита есть эта функция) \nsystemctl status ssh отображает состояние системы, юнитов (в том числе Failed) и запущенные процессы пользователей \nsystemctl status sshd | grep -P \"Active.+;\" | sed -r \"s/.+; | ago//g\" время работы службы \nsystemctl start ssh запустить юнит (до перезагрузки) \nsystemctl stop ssh остановить юнит (до перезагрузки) \nsystemctl restart ssh перезапустить сервис \nsystemctl enable ssh добавить в автозагрузку \nsystemctl disable ssh удалить из автозагрузки \nsystemctl mask ssh выключить юнит, который нельзя будет запустить вручную или как зависимость (создает симлинк на /dev/null) \nsystemctl unmask ssh включить юнит (удалить симлинк) \nsystemctl daemon-reload перезапустить юнит systemd \nsystemctl cat ssh отобразить путь и содержимое unit-файла \nsystemctl edit --full ssh открыть для редактирования файл юнита \nsystemctl list-dependencies ssh дерево зависимостей \nsystemctl list-dependencies ssh --reverse зависящие сервисы от указанного юнита \nsystemctl list-units --type service --all отображение статуса всех сервисов \nsystemctl list-unit-files | sed \"1d;$ d\" | sed \"$ d\" | wc отобразить кол-во всех файлов конфигурации сервисов на диске \nsystemctl list-unit-files | grep zabbix отфильтровать по имени \nsystemctl list-unit-files --type=service список всех сервисов \nsystemctl list-unit-files --type=service --state=enabled список сервисов, добавленных в автозагрузку \nsystemctl list-units --all --type=service --plain --no-legend --no-pager --output=json \n--all выводить все типы юнитов, включая активные, неактивные и остановленные \n--type=service выводить только системные службы управляемые systemd (не ключает в вывод другие типы юнитов, такие как socket или device) \n--plain вывод в текстовом формате без форматирования \n--no-legend отключает вывод заголовков для столбцов \n--no-pager отключает использование постраничного вывода (less) \nls /usr/lib/systemd/system юниты поставляемые вместе с системой и устанавливаемыми приложениями \nls /run/systemd/system юниты созданные динамически в runtime \nls /etc/systemd/system юниты системного администратора\n\nsystemctl-tui\ncargo install systemctl-tui --locked быстрый и простой TUI-интерфейс для взаимодействия с службами и журналами systemd на Rust (https://github.com/rgwood/systemctl-tui), от создателя NuShell \nsystemctl-tui\n\nunit\n\nnano /etc/systemd/system/icmp-test-log.service\n\nsystemctl daemon-reload \nsystemctl enable icmp-test-log.service \nsystemctl start icmp-test-log \nsystemctl status icmp-test-log \ntail -f /var/log/icmp-test.log\n\njournalctl\njournalctl --system отобразить системный журнал \njournalctl --user отобразить пользовательский журнал текущего пользователя \njournalctl -m отобразить записи из всех доступных журналов (–merge) \njournalctl -ek отобразить только сообщения ядра (kernel, –dmesg) из текущей загрузки \njournalctl -t systemd показать записи с указанным идентификатором системного журнала \njournalctl _PID=3972315 отобразить сообщения по PID процесса \njournalctl -eu ssh отобразить сообщения с конца (–pager-end) для выбранного сервиса (–unit)\ng перейти в начало листинга \nG перейти в конец\njournalctl -fu ssh выводить новые сообщения в реальном времени (-f/–follow) \njournalctl -fu ssh выводить новые сообщения в реальном времени (-f/–follow) \njournalctl -ru ssh вывести сообщения с конца (сверху новые записи, –reverse) \njournalctl -n 100 -u ssh --no-pager вывести 100 строк (–lines) из журнала и не передавать вывод на автоматический скроллинг \njournalctl -p 3 вывести записи с указанным приоритетом, например, только ошибки и выше по важности: неработоспособность(0), alerts(1), critical(2), errors(3), warning(4), notice(5), info(6), debug(7) \njournalctl -S \"2023-09-01 12:00:00\" -U \"2023-09-01 15:00:00\" отобразить сообщения от (–since) 1 сентября c 12:00:00 по (–until) 15:00:00 \njournalctl --since today отобразить сообщения за сегодня \njournalctl -b отобразить сообщения с момента последней загрузки системы (boot) \njournalctl --list-boots показать список сохраненных загрузок системы \njournalctl -b ba6b2292a0e84d83a81cedfaa221926f показать сообщения с момента конкретной загрузки системы (–boot) \njournalctl --quiet не показывать информационные сообщения и предупреждения о привилегиях \njournalctl --no-hostname подавить вывод поля имени хоста \njournalctl -n 1 --no-pager --output=json-pretty вывод в формате JSON (json-sse, json-seq) \njournalctl -n 1 --no-pager --output=json-pretty --output-fields=PRIORITY,MESSAGE отфильтровать вывод\njournalctl --fields вывести список всех используемых полей (UNIT, USER_UNIT, _SYSTEMD_UNIT, _SYSTEMD_USER_UNIT и т.д.)\njournalctl --field=UNIT &gt; system_units.log вывести список всех юнитов в системе \njournalctl --field=USER_UNIT &gt; user_units.log вывести список всех пользовательских юнитов в системе \ncomm -12 &lt;(sort system_units.log) &lt;(sort user_units.log) построчное сравнение двух отсортированных файлов со списком журналов без вывода общих строк в 1 и 2 файлах (-12)\njournalctl --disk-usage вывести общее использование диска всеми файлами журнала (Archived and active journals take up 2.3G in the file system) \njournalctl --flush очистить все данные журнала из директорий /run в /var \njournalctl --vacuum-time=1month удалить файлы журнала, старше указанного времени (1-го месяца) \njournalctl --vacuum-size=100M очистить логи, чтобы размер хранилища соответствовал указанному размеру \njournalctl --vacuum-files=100 оставить только указанное количество файлов журнала \njournalctl --rotate запустить немедленную ротацию файлов журнала \njournalctl --sync синхронизировать незаписанные сообщения журнала на диск \njournalctl --relinquish-var прекратить запись на диск, войти во временную файловую систему \njournalctl --verify проверить целостность файла журнала\njournalctl --header вывести список журналов \nFile path - путь к файлу журнала на диске \nIncompatible flags - несовместимые флаги с этим журналом \nRotate suggested - применяется ли ротация к журналу \nTail sequential number - последовательный номер для конца журнала (указывает на последнее событие в журнале) \nHead realtime timestamp - время первого события в журнале \nTail realtime timestamp - время последнего события в журнале \nObjects - количество объектов, находящихся в журнале (таких как записи, и не только) \nEntry objects - количество объектов, представляющих записи в журнале \nData objects - количество объектов данных, хранящихся в журнале \nField objects - Количество объектов полей (список полей можно получить через –fields) \nDisk usage - используемое пространство на диске для этого журнала\nnano /etc/systemd/journald.conf\n\nsudo systemctl restart systemd-journald\n\ndmesg\ndmesg -Tx прочитать логи буфера сообщений ядра (/var/log/dmesg), используется для записи во время загрузки системы пока сервис Syslog ещё не запущен \ndmesg -Tx -l crit,err отфильтровать вывод \ndmesg -E включить логирвоание ядра в консоль (–console-on) \ndmesg -D отключить (–console-off)  \ndmesg -n 1 изменить уровень логирования для печати в консоль \ndmesg -u отображать вывод из программ окружения пользователя \ndmesg -w выводить журнал в реальном времени (ждать новых сообщений)\n\nhardware\nsystemd-analyze отображает статистику времени загрузки ОС (Kernel - время загрузки ядра) и userspace \nsystemd-analyze blame отобразить все процессы и отсортировать по времени загрузки \nsystemd-analyze blame | grep zabbix \nsystemd-analyze plot &gt; graph.svg создать векторный отчет в формате Scalable Vector Graphics описанный XML\nhistory история команд \nhistory -c очистить историю\nwho -b время последнего включения \nlast история авторизации \nlast -n 5 reboot история перезагрузки \nlast shutdown история выключений\narch архитектура системы \nlsb_release -a версия дистрибутива \nuname -srv версия ядра \ncat /proc/version версия ядра и дистрибутива \ncat /etc/os-release описание дистрибутива и версия ОС \nhostnamectl подробная информация (Operating System, Kernel, Architecture, Hardware Vendor/Model)\nuptime время работы системы, кол-во залогиненных пользователей, Load average - средняя загрузка системы за последние 1, 5 и 15 минут (2.00 - это 100% на два ядра) \ndmidecode -t bios информация о системе (system/baseboard/processor/memory) \ndmidecode -s bios-vendor информация о системе (bios-version/bios-release-date/baseboard-manufacturer/system-manufacturer/processor-version) \ndmidecode -t baseboard версия материнской платы, Video и Sound и их статус\nnproc кол-во ядер \nlscpu информация о процессоре \ncat /proc/cpuinfo информация о процессоре \ncat /proc/cpuinfo | grep \"core id\" | wc -l количество уникальных ядер (без учета потоков) \ncat /proc/partitions перечисляет все устройства хранения и разделы на этих устройствах хранения \ncat /proc/asound/cards Audio PCI \ncat /proc/cmdline содержит имя файла образа ядра и его параметры запуска, которые были указаны в приглашении загрузчика GRUB (позволяет идентифицировать параметры загрузки, которые были введены вручную) \ncat /etc/default/grub содержит конфигурацию, которую использует команда update-grub для создания файла /boot/grub/grub.cfg \ncat /boot/grub/grub.cfg команда update-grub генерирует этот файл автоматически в соответствии с настройками, заданными в файле /etc/default/grub \ncat /proc/loadavg среднее количество процессов или потоков, которые выполняются, находятся в очереди на выполнение или ждут завершения операций ввода/вывода за последние 1, 5 и 15 минут. 4-е значение, это количество процессов выполняемых в данный момент/общее количество процессов в системе. Последнее значение, это PID последнего созданного процесса.\nlspci информация о устройствах, подключенные к материнской плате компьютера по шине PCIe \nlspci | grep -i vga узнать какая используется видеокарта (VGA controller) \nlspci | grep -i audio Audio controller \nlspci | grep -i ethernet Ethernet controller \nlspci | grep -i scsi SCSI storage controller \nlspci | grep -i sata SATA storage controller \nlspci | grep \"USB controller\" \nlspci | grep 02:00.0 фильтровать информацию по слоту устройства \nlspci -vv | grep -iE \"driver\" отобразить список загруженных драйверов ядра для устройств \nlsusb -vt информация о USB устойствах (принтеры, Bluetooth адаптер, мышка, клавиатура)\nlshw -short информацию по каждому устройству \nlshw -class bus Motherboard/USB \nlshw -class display VGA controller \nlshw -class network \nlshw -class disk информация о жестком диске (product, vendor, size, capabilities: 7200rpm) \nlshw | grep product\nls /sys/class/net список сетевых интерфейсов \ncat /proc/net/dev список сетевых интерфейсов и их статистика (bytes, packets, errs, drop) для Receive (Прием) и Transmit (Передача) \nethtool -S ens33 статистика сетевого интерфейса (для сброса статистики нужно ip down и выгрузить модуль ядра с драйверов modprobe -r module и вернуть обратно) \nethtool ens33 | grep -Ei \"wake-on|speed\" поддержка Wake-on-Lan и скорость сетевого интерфейса \nethtool -i ens33 драйвер сетевой карты \nethtool ens33 -p 100 включить светодиод на сетевой карте на 100 секунд\ncat /sys/block/sda/stat статистика диска sda \nlsmod список всех загруженных модулей ядра вместе с зависимостями \n/proc/modules содержится список всех загруженных модулей ядра \nmodinfo ip_tables информация о конкретном модуле \nls /etc/*modprobe* содержит конфигурационные файлы со списками модулей ядра \ncat /etc/modprobe.d/mdadm.conf \\ /etc/modules-load.d/` директория, которая содержит файлы со списками модулей, которые должны быть загружены при запуске системы\nls -l /var/lib/apt/periodic/update-success-stamp дата последнего выполнения apt update \nls -l /var/cache/apt/pkgcache.bin местоположение кэша пакетов apt \nHISTTIMEFORMAT=\"%d/%m/%y %T \" history | grep \"apt update\" история команды обновления с точкой времени\ncat /etc/hostname имя хоста \ncat /etc/services | grep -iE \"ntp|zabbix\" список всех сервисов и сопоставленных им портов в системе \ncat /etc/mime.types | grep -Ew \"json|csv\" список сопосталвения файлов и их программ для открытия в системе\ncat /etc/hosts локальная таблица преобразовани ip в имя \ncat /etc/hosts.allow &amp;&amp; cat /etc/hosts.deny ограничить доступ к внешним сервисам \ncat /etc/hosts.{allow,deny} | grep -Pv \"^$|^#\" \necho \"in.telnetd: 192.168.3., .domain.ru\" &gt;&gt; /etc/hosts.allow разрешить соединение только для указанной подсети и домена\nls -l /dev | grep sd вывести список всех дисков и разделов в файловой системе \nls -l /dev | grep -wo sd. вывести только список дисков \ncat /proc/diskstats статистика дисков \ncat /proc/stat cpu user/nice/system/idle/iowait/irq/softirq/steal_time, ctxt - общее количество переключений контекста на всех процессорах, btime - время загрузки системы в секундах с начала эпохи unix, processes -  указывается количество созданных процессов и потоков, включая (но не ограничиваясь ими) те, которые созданы вызовами системных вызовов fork() и clone(), procs_blocked - количество процессов, заблокированных в данный момент и ожидающих завершения ввода-вывода \nstat -f /dev/sda \ncat /proc/buddyinfo информация о фрагментации памяти в ядре Linux, спользуется для диагностики проблем с фрагментацией памяти \ncat /proc/cgroups система контейнеризации и управления ресурсами доступными для процессов cgroups, позволяет ограничить доступ к любым ресурсам для процесса, а также контролировать его поведение в системе\n\nsysctl\nsysctl -a отобразить все параметры/настройки ядра Linux (Kernel), где представленны все параметры в виде переменных, имена переменных соответствуют пути файла в директории /proc/sys (вместо слеша в переменной используется точка) \nsysctl net.ipv6.conf.all \nsysctl net.ipv6.conf.all.disable_ipv6=1 отключить протокол IPv6 (&gt; /proc/sys/net/ipv6/conf/ens33/disable_ipv6) \nsysctl net.ipv6.conf.ens33.disable_ipv6=1 для интерфейса ens33 \nsysctl --system обновление информации из файлов/вернуть значения переменных до состояния сохраненного в файлах (удалить временные изменения из sysctl) \nsysctl -w net.ipv6.conf.ens33.disable_ipv6=1 сохранить настройку после перезагрузки (-w записать в файл) \nsysctl fs.file-nr кол-во открытых файловых дескрипторов в текущий момент, открытые файлы которые сейчас не используются, максимальное количество для открытия \nsysctl -a | grep fs.file-max максимальное количество открытых файлов (дескрипторов), которые могут быть открыты в файловой системе всеми процессами на уровне ядра ОС \nnano /proc/sys/fs/file-max изменить значение кол-ва дескрипторов \necho \"fs.file-max=500000\" &gt;&gt; /etc/sysctl.conf добавить в конфигурацию sysctl.conf \nsysctl -p применить настройки \nsysctl fs.nr_open лимит открытия файлов для каждого процесса отдельно \nls /proc/1/fd/ | wc -l узнать кол-во открытых дескрипторов у процессора с PID 1 \nsysctl fs.aio-nr количество асинхронных операций ввода и вывода файловой системе в масштабе всей системы (Asynchronous IO number requests) \nsysctl fs.aio-max-nr максимальное количество асинхронных операций ввода-вывода, рекомендуемое минимальное значение для fs.aio-max-nr — 1048576, но в загруженной среде ASE со многими ядрами может потребоваться настроить большее число \nsysctl fs.inotify.max_queued_events подсистема ядра inotify позволяет следить за изменениями в файловой системе, устанавливает максимальное количество событий, которые могут находиться в очереди, перед тем как их обработает программа \nsysctl fs.inotify.max_user_watches максимальное количество файлов и директорий, за которыми может наблюдать один объект inotify \nsysctl fs.inotify.max_user_instances максимальное количество объектов inotify, которые может создать один пользователь \nsysctl fs.mqueue.queues_max максимальное количества очередей сообщений POSIX, разрешенных в системе, которые позволяют процессам (и их потокам) обмениваться данными в виде сообщений (создаются и открываются с помощью функции mq_open) \nsysctl fs.mqueue.msg_max максимального количества сообщений в значении очереди \nsysctl fs.mqueue.msgsize_max максимальный размера сообщения \nsysctl vm.min_free_kbytes минимальный размер свободной оперативной памяти который необходимо поддерживать \nsysctl vm.swappiness процент свободной памяти, по достижении которого данные начинают переноситься на SWAP раздел \nsysctl -w vm.swappiness=80 при 80% свободной памяти (свыше 20% занятой оперативной памяти) начнет использоваться SWAP, в котоый помещяются неиспользуемые процессами страницы памяти на текущий момент, если приложению потребуются эти страницы, процесс их перенесения из раздела подкачки обратно в оперативную память (данные нужно обратно считать с диска в память) \nsysctl -w vm.swappiness=10 файл подкачки (выгрузка в виртуальную память) активируется только в том случае, если свободно 10% оперативной памяти \nsysctl vm.vfs_cache_pressure скорость удаления dentry и inode из кэша (100 по умолчанию) \nsysctl vm.dirty_background_ratio процент от общей оперативной памяти который может быть заполнен страничным кэшем, по достижении которой демон pdflush (dirty page flush) начинает сбрасывать данные из кэша оперативной памяти на диск. Когда объем свободной памяти становится меньше этого порога, ядро вызывает функцию wakeup_bdflush() для перевода в состояние выполнения потока pdflush, который выполняет функцию обратной записи измененных страниц памяти background_writeout() на диск, эта функция получает один параметр количества страниц, которые функция должна попытаться записать на диск. \nsysctl -w vm.dirty_background_ratio=5 \nsysctl vm.dirty_ratio вернхний предел объема оперативной памяти в процентах от free Available который может быть выделен под PageCache до их записи на диск, на этом уровне все новые операции ввода-вывода приостанавливаются до тех пор, пока на диск не будут записаны грязные (Dirty) страницы, значение должно быть выше чем dirty_background_ratio \nsysctl vm.dirty_expire_centisecs время хранения грязных (Dirty) страниц в кэше в сотых долях секунд (3000 = 30 секунд) для их записи на диск с целью. Функция wb_kupdate() демона pdflush выполняет обратную запись данных на диск, которые были изменены более чем dirty_expire_centisecs для синхронизации страничного кэша с данными на диске, т.к. при сбое, т.к. содержимое памяти после перегрузки не сохраняется. \nsysctl vm.dirty_writeback_centisecs интервал процесса проверки данных, которые подлежат записи на диск (500 - 5 секунд) \nsysctl abi.vsyscall32 разрешает выполнение 32 битных программ в 64 битной системе (по умолчанию 1 - разрешает) \nsysctl kernel.hostname изменить имя компьютера без перезагрузки \nsysctl kernel.printk уровень логирования \nsysctl -w kernel.printk=\"2 4 1 7\" \nsysctl net.ipv4.ip_default_ttl значение по-умолчанию для величины Time To Live исходящих пакетов (продолжительность жизни пакета в Internet - каждый раз, когда пакет попадает на очередной роутер, брандмауэр и т.п. величина TTL пакета уменьшается на 1) \nsysctl net.ipv4.ip_no_pmtu_disc запрещает поиск Path Maximum Transfer Unit (максимальный размер пакета для выбранного пути, это не MTU), когда система будет пытаться определить максимальный размер пакета, при котором не потребуется выполнять их фрагментацию, для передачи на заданный хост \nsysctl net.ipv4.tcp_mem векторная переменная (минимум, режим нагрузки, максимум), которая cодержит общие настройки потребления памяти для протокола TCP, измеряется в страницах (обычно 4Кб), а не байтах. Пока общий размер памяти для целей протокола TCP ниже минимального количества страниц, операционная система ничего не делает с памятью используемой различными TCP сокетами, в режиме нагрузки TCP начинает быстро освобождать память, и последний максимальный - объем памяти, который может использоваться для нужд TCP и при его достижении, начинаются потери пакетов. \nsysctl net.ipv4.tcp_rmem векторная величина размера буфера сокетов TCP для приема. Каждый сокет TCP имеет право использовать минимальную память по факту своего создания (по умолчанию – 4096 байт, 4 Кб) и его не стоит увеличивать, т.к. при высокой нагрузки займут много памяти. Значение по умолчанию применяется взамен параметра rmem_default (который используется другими протоколами), второй параметр - по умолчанию имеет удвоенное значение, 87380 * 2 bytes, или 174760 байт (170 Кб). Максимально возможный размер приемного буфера, это значение не отменяет максимума, заданного в rmem_max \nsysctl net.ipv4.tcp_wmem векторная величина размера буфера сокетов TCP для передачи \nsysctl net.core.rmem_default значение по умолчанию (имеет ниже приоритет, чем tcp_rmem) \nsysctl net.core.wmem_default значение по умолчанию \nsysctl net.core.rmem_max максимальный размер буфера на сокете получения данных в байтах (глобальный параметр, имеет выше приоритет, чем tcp_rmem) \nsysctl net.core.wmem_max максимальный размер буфера на сокете передачи данных в байтах \nsysctl net.core.optmem_max максимальный объём опциональных буферов памяти \nsysctl -w net.core.rmem_max=26214400 &amp;&amp; sysctl -w net.core.rmem_default=26214400 увеличить до 25 МБайт \nsysctl -w net.core.wmem_max=26214400 &amp;&amp; sysctl -w net.core.wmem_default=26214400 увеличить до 25 МБайт \nsysctl net.ipv4.tcp_no_metrics_save по умолчанию (0) TCP сохраняет различные метрики соединения в кэше маршрута при закрытии соединения, при включении (1) TCP не будет кэшировать метрики при закрытии соединений \nsysctl net.ipv4.icmp_echo_ignore_all если включено, ядро будет игнорировать все icmp запросы (рекомендуется для защиты от DOS атак) \nsysctl net.ipv4.icmp_echo_ignore_broadcasts игнорировать запросы ICMP ECHO, переданные широковещательными пакетами \nsysctl net.ipv4.icmp_ignore_bogus_error_responses игнорировать ошибочные ICMP запросы \nsysctl net.ipv4.conf.all.accept_source_route разрешать маршрутизацию от источников, при включении, позволяет отправителю определить путь, по которому пакет должен пройти по сети Internet, чтобы достигнуть пункта назначения. Это удобно для изучения и отладки работы сети, но нарушитель получает возможность подмены адресов компьютеров локальной сети и может попытаться подсунуть поддельные маршруты для того, чтобы перенаправить весть трафик через узел, который он контролирует (атака Man In The Middle). \nsysctl net.ipv4.conf.all.accept_redirects запретить(0)/разрешить(1) принимать и отправлять ICMP пакеты перенаправления \nsysctl net.ipv4.conf.all.send_redirects \nsysctl net.ipv4.conf.all.secure_redirects \nsysctl net.ipv4.ip_forward разрешает (1) или запрещает (0) маршрутизацию пакетов через текущий хост \nsysctl net.ipv4.conf.default.forwarding включить форвардинг пакетов - разрешить ядру операционной системы осущетсвлять проброс трафика с одного интерфейса на другой \nsysctl net.ipv4.ip_local_port_range диапазон локальных портов, доступных для установки исходящих подключений (создания локальных клиентских сокетов) \nsysctl net.ipv4.tcp_max_tw_buckets максимальное число сокетов, находящихся в состоянии TIME-WAIT одновременно, для предотвращения простейших разновидностей DoS-атак \nsysctl net.ipv4.tcp_tw_recycle разрешает/запрещает быструю утилизацию сокетов, находящихся в состоянии TIME-WAIT \nsysctl net.ipv4.tcp_tw_reuse позволять повторное использование TIME-WAIT сокетов в случаях, если протокол считает это безопасным \nsysctl net.ipv4.tcp_rfc1337 защита от TIME-WAIT атак \nsysctl net.ipv4.tcp_max_orphans максимальное число “осиротевших” TCP сокетов, не связанных каким-либо идентификатором пользовательского файла (user file handle), при достижение этого значения, соединения сбрасываются. Этот порог помогает предотвращать простые атаки DoS и увеличение параметра влияет на ОЗУ, каждое orphan-соединение поглощает около 64 Кбайт не сбрасываемой на диск (unswappable) памяти и не может быть сброшена в SWAP. При возникновении проблем, связанных с этим ограничением – в системный журнал будет подобное сообщение: TCP: too many of orphaned sockets, и это может служить поводом пересмотреть значения tcp_fin_timeout или tcp_orphan_retries. \nsysctl -w net.ipv4.tcp_max_orphans=65536 \nsysctl net.ipv4.tcp_orphan_retries число попыток закрыть соединение перед тем как оно будет разорвано принудительно и уничтожается TCP соединение, закрытое на локальной стороне сервера. По умолчанию используется значение 7, соответствующее приблизительно периоду от 50 секунд до 16 минут в зависимости от RTO (Retransmission Timeout). \nsysctl net.ipv4.tcp_fin_timeout задает максимальное время пребывания сокета в состоянии FIN-WAIT-2 и используется если другая сторона не закрыла соединение со своей стороны. Каждый сокет занимает в памяти 1.5 Кб, что может привести к значительным утечкам памяти в некоторых случаях. \nsysctl net.ipv4.tcp_syncookies помогает защититься от атак SYN flood, срабатывает только при достижении значения net.ipv4.tcp_max_syn_backlog, если количество SYN пакетов забивает всю очередь, включается механизм Syn cookies. SYN cookies вообще не использует очередь SYN, вместо этого ядро отвечает на каждый SYN пакет, как обычно SYN/ACK, но туда будет включено специально сгенерированное число на основе IP адресов и портов источника и получателя, а также времени посылки пакета. Атакующий никогда не получит эти пакеты, а поэтому и не ответит на них. При нормальном соединении, будет послан третий пакет, содержащий число, а сервер проверит был ли это ответ на SYN cookie и, если да, то разрешит соединение даже в том случае, если в очереди SYN нет соответствующей записи. \nsysctl net.ipv4.tcp_fastopen помогает уменьшить задержки в сети, позволяя начать передачу данных сразу при отправке клиентом первого TCP SYN (3 - включает для входящих и исходящих) \nsysctl net.ipv4.tcp_max_syn_backlog размер очереди (максимальное число) запоминаемых запросов на попытку установки TCP соединений (SYN-пакета в состоянии Waiting Acknowledgment) при отправки клиентом TCP SYN пакета, для которых не было получено сервером подтверждения от клиента (полуоткрытых соединений) \nsysctl -w net.ipv4.tcp_max_syn_backlog=4096 увеличить, если на сервере возникают перегрузки \nsysctl net.core.somaxconn размер очереди (максимальное число) полуоткрытых соединений (открытых сокетов) ожидающих установки соединения. Если в ответ на SYN-пакета (synchronize) клиентом был получен от сервера пакет SYN-ACK (acknowledges), сервер ожидает от клиента отправки ACK пакета, после чего соединение считается установленным. \nsysctl net.ipv4.tcp_syn_retries количество попыток передачи SYN-пакета при установлении нового соединения, на каждую попытку отводится примерно 30-40 секунд. Значение по-умолчанию 5 = 180 секундам. \nsysctl net.ipv4.tcp_synack_retries количество попыток передачи SYN-ACK-пакета в ответ на SYN-запрос для установки пассивного TCP-соединение, инициированное другим хостом, если уменьшить до одного, будет примерно 9 секунд \nsysctl net.core.netdev_max_backlog регулирует размер очереди пакетов между сетевой картой и ядром, если ядро не успевает обрабатывать пакеты (если сетевой интерфейс получает пакеты быстрее, чем ядро может их обработать) и очередь переполняется, то новые пакеты отбрасываются, если увеличить значение, можно справиться с пиковыми нагрузками \nsysctl -a | grep net.ipv4.tcp_keepalive после неактивности сокета посылает пакет keepalive на второую сторону, содержащий нулевые данные, после отправки первого пакета через время, указанное в tcp_keepalive_time отправляет повторно пакеты через каждые tcp_keepalive_intvl секунд tcp_keepalive_probes раз, если другая сторона не отвечает, сокет автоматически закрывается \ntcp_keepalive=$(sysctl -a | grep net.ipv4.tcp_keepalive | grep -Po \"(?&lt;=\\=\\s)[0-9]+\") забрать массив значений \necho $tcp_keepalive | awk '{print $3+($1*$2)}' 7200+(75*7) \nsysctl net.ipv4.conf.all.rp_filter 1 - строгий режим проверки и 2 - свободный режим проверки, включает фильтр обратного пути (reverse path filter) или защита от подмены адресов (спуфинга), все что поступает на сервер, проходит проверку на соответствие исходящего адреса с таблицей маршрутизации и такая проверка считается успешной, если принятый пакет предполагает передачу ответа через тот же самый интерфейс. Например, когда входящий трафик идет через один маршрутизатор, а исходящий через другой, могут теряться пакеты, поскольку обратный маршрут в таблице маршрутизации, задан через другой интерфейс. \nsysctl -w net.ipv4.conf.ens33.rp_filter=1 включает строгую проверку на интерфейсе ens33 \nsysctl net.ipv4.conf.all.log_martians включает/отключает логирование пакетов \nsysctl net.ipv4.tcp_window_scaling разрешает/запрещает масштабирование TCP-окна, как определено в RFC 1323. При передаче TCP-пакетов по толстым каналам возникают потери пропускной способности из-за того, что они не загружены полностью во время ожидания подтверждения о приеме предыдущего TCP-окна. Основная проблема состоит в том, что окно не может иметь размер больше, чем 216 байт (65 Кб). Разрешая масштабирование TCP-окна можно увеличить его размер и таким образом уменьшить потери пропускной способности. \nsysctl net.ipv4.tcp_retries2 \nsysctl net.ipv4.tcp_abort_on_overflow заставляет ядро отвергать новые соединения, если их поступаемое количество выше, с чем система в состоянии справиться \nsysctl net.ipv4.ip_nonlocal_bind позволяет отдельным локальным процессам выступать от имени внешнего (чужого) IP адреса, может потребоваться, когда необходимо прослушивать внешние IP адреса, например, сниффинг чужого траффика \nnet.ipv4.ipfrag_low_thresh максимальный объем памяти, выделяемый под очередь фрагментированных пакетов в диапазоне от 0 до 2147483647, когда длина очереди достигает этого порога, то обработчик фрагментов будет отвергать все фрагментированные пакеты и после уменьшения очереди они должны быть повторно переданы узлом-отправителем. \nsysctl net.ipv4.netfilter.ip_conntrack_max максимальное количество соединений для работы механизма connection tracking (используется в iptables)\n\nlimits\ncat /etc/security/limits.conf | grep -Ev \"^$|^#\"\n\nulimit -a отобразить список ограничений\n\nulimit -Sn отобразить значение текущего ограничения Soft (-S) для nofile (-n) \nulimit -Hn ограничение Hard (-H) \nulimit -n 3000 изменить ограничение количества открытых файлов для одного процесса (до перезагрузки) \nulimit -Sm 1500000 ограничение soft (-S) оперативной памяти (-m) в 1500 Мб для пользователя \nulimit -u 5000 ограничение максимального количества запущенных пользовательских процессов (-u) \nulimit -s ограничение места для размера аргументов (stack size) команды/скрипта (bash: /usr/bin/diff: Argument list too long) \nulimit -m максимальный объем оперативной памяти \nulimit -v максимальный объем виртуальной памяти \nulimit -f максимальный размер создаваемых файлов \nulimit -t максимальное количество процессорного времени\nsystemctl edit rsyslog ограничения на уровне Unit для конкретного сервиса\n\nsystemctl restart rsyslog \npid=$(ps -A | grep rsyslogd | awk '{print $1}') получить pid процесса \ncat /proc/$pid/limits проверить применение ограничений после перезапуска сервиса\n\nquota\nnano /etc/fstab примонтировать раздел на который необходимо установить квоту с указанными опциями\n\nmount -o remount,rw / перемонтировать файловую систему в режиме read and write \nmount | grep quota \nquotacheck -favugm выполнить проверку наличия служебных файлов aquota.user и aquota.group — если их нет, команда их создаст автоматически \nquotaon -avug включить квоту \nedquota -u lifailon создать квоту для пользователя или для группы (-g) на размер данных и кол-во файлов\n\nedquota -p lifailon user скопировать квоту на другого пользователя \nedquota -t изменить период отсрочки soft квоты до момента, когда она станет hard (по умолчанию 7 дней) \nquota lifailon -s отобразить квоты для пользователя \nrepquota -us / отчет для пользователей и групп (-u/-g), текущий used и soft/hard для Space limits и File limits, +-/-+/++ означает, что один из пределов достигнут максимума\n\nsu lifailon \ndd if=/dev/zero of=/tmp/test.file bs=1024000 count=400 создать файл размером 400MB\n\nls -lh /tmp/test.file\n\n\nBearstech\n\npussh\nPussh — инструмент для параллельного выполнения команд через SSH на нескольких хостах одновременно, выводя результаты с указанием имени каждого хоста. Был внутренним инструментом Bearstech (хостинг-провайдер в Париже, Франция) примерно с 2008 года.\n\n\nquickbench\nquickbench - скрипт без зависимостей для оценки базовой производительности.\n\n\nfetch\nНабор скриптов, для быстрого получения информации о системе без установки:\ncurl -s https://raw.githubusercontent.com/dylanaraps/neofetch/refs/heads/master/neofetch | bash \ncurl -s https://raw.githubusercontent.com/dylanaraps/pfetch/refs/heads/master/pfetch | bash \ncurl -s https://raw.githubusercontent.com/KittyKatt/screenFetch/refs/heads/master/screenfetch-dev | bash \ncurl -s https://raw.githubusercontent.com/ThatOneCalculator/NerdFetch/refs/heads/main/nerdfetch | bash \ncurl -s https://raw.githubusercontent.com/m0zgen/system-checks/master/system-check.sh | sudo bash \ncurl -s https://raw.githubusercontent.com/Lifailon/hwstat/refs/heads/rsa/hwstat.sh | bash\n\n\nnetworkmanager\napt install network-manager \nsystemctl status NetworkManager \nnmcli device status состояние интерфейсов \nnmcli general status \nnmcli connection show список доступных подключений (ethernet, vpn и WiFi-сетей) \nnmcli device wifi list список доступных Wi-Fi-сетей \nnmcli connection show \"Проводное соединение 2\" информация о сети \nnmcli connection up \"Проводное соединение 2\" подключиться \nnmcli conn down \"Проводное соединение 2\" отключиться \nnmcli radio wifi состояние Wi-Fi \nnmcli connection add con-name \"dhcp\" type ethernet ifname ens33 создать подключение, передать тип устройства ethernet (Проводное соединение) и ifname, название сетевого интерфейса \nnmcli conn modify \"dhcp\" ipv4.dns 8.8.8.8 настройки подключения (modify) \nnmcli radio wifi on включить или выключить (off) Wi-Fi \nnmcli device wifi connect \"TP-Link\" password 12345678 name \"TP-Link Wifi\" подключиться к Wi-Fi сети \nnmcli networking off отключить сеть через (если управление через Network Manager, указывается в блоке конфигурации renderer для netplan) \nnmcli networking on включить сеть \nsystemctl restart NetworkManager\n\nwireless\napt install wireless-tools \niwconfig \napt install iw \niw list \napt install wavemon \nwavemon отобразить качество соединения и мощность передатчика\n\nnetworking\nnano /etc/network/interfaces\nauto ens33 активировать интерфейс при загрузке \niface ens33 inet static статический \naddress 192.168.1.50/24 \n#netmask 255.255.255.0 \ngateway 192.168.1.254 \ndns-nameservers 8.8.8.8 1.1.1.1\nauto ens33 \niface ens33 inet dhcp динамический\nservice networking restart перезагрузка сети \nsystemctl restart networking.service\n\nnetplan\nnetplan --debug generate проверка конфигурации на ошибки \nnetplan apply применить изменения (перезапускает сеть) \nnetplan get прочитать конфигурацию\nnano /etc/netplan/*.yaml\n\nДинамический адрес (использовать два сетевых интерфейса):\n\n\n\nСтатический адрес:\n\n\nrenderer указывает, кому передать управление сетью NetworkManager (nmcli) в средах с графическим интерфейсом или networkd (networkctl)\nnetplan status в релизе netplan 0.106 от февраля 2023 (Ubuntu 23.04) может получить статус используемого renderer\n\nMAC и MTU:\n\n\n\nПодключение к WiFi:\n\n\n\nBonding для объединения физических сетевых интерфейсов в один логический:\n\n\n\nip\nip a ip addr show \nip -s link вывести ститстику всех сетевых интерфейсов \nip -br a show вывести только название интерфейса, статус работы и ip-адрес \nip link set dev ens33 up включить сетевой интерфейс \nip link set dev ens33 down выключить сетевой интерфейс  \nip link set mtu 1550 dev ens33 изменить mtu \nip link set dev ens33 address AA:BB:CC:DD:EE:FF изменить mac-адрес (предварительно нужно отключить интерфейс, работает до перезагрузки) \nip addr add 192.168.3.106/24 broadcast 192.168.3.255 dev ens33 добавить адрес \nip addr del 192.168.3.106/24 dev ens33 удалить адрес \nip route show отобразить таблицу маршрутизации \nip route add 192.168.4.0 via 192.168.3.100 добавить маршрут \nip route del 192.168.4.0 via 192.168.3.100 удалить маршрут \nip route add 192.168.4.0 dev ens33 указать сетевой интерфейс, через который отправлять пакеты в определенную подсеть \nip neigh show отобразить ARP-таблицу \nip neigh add 192.168.3.110 lladdr b0:be:76:43:21:41 dev ens33 \nip neigh del dev end33 192.168.3.110 \nip neigh flush очистить ARP-таблицу\n\nnet-tools\nifconfig ens33 up/down \nifdown -a выключить все сетевые интерфейсы (пропадут из списка ifconfig) и включить (ifup -a) \nifconfig ens33 192.168.3.106 netmask 255.255.255.0 broadcast 192.168.3.255 \nifconfig -s || netstat -i список сетевых интерфейсов \nnetstat -atu ALL (-a) tcp (-t) и udp (-u) \nnetstat -lntup LISTEN (-l) dont resolve names (-n) и сканирует директорию /proc для вывода PID/Program name (-p) \narp -a таблица сопоставления ip и mac адресов \nroute -e отобразить таблицу маршрутизации \nroute add -net 192.168.4.0 netmask 255.255.255.0 gw 192.168.3.100 добавить маршрут в подсеть 192.168.4.0 через шлюз 192.168.3.100 \nroute del -net 192.168.4.0 netmask 255.255.255.0 удалить маршрут\n\nnetworkd\nsystemctl status systemd-networkd \nnetworkctl list список всех адаптеров, тип и состояния \nnetworkctl status статус службы, Address и Gateway адаптера, DNS-адреса и лог systemd-networkd \nnetworkctl status ens33 характеристики адаптера (Network File, Driver, Vendor, Model, MTU, Speed)\n\nss\nss -a All отобразить все сокеты \nss -l показать только прослушиваемые сокеты (LISTEN) \nss -t отобразить только установленные TCP соединения (ESTAB/ESTABLISHED) \nss -ua отобразить все открытые UDP сокеты \nss -da DHCP сокеты \nss -x отобразить только локальные UNIX соединения \nss -r Resolve, определять сетевые имена адресов с помощью DNS \nss -p Processes, показать процессы, использующие сокет \nss -n Numeric не определять имена служб (отображать только номер порта в числовом формате) \nss -ltp | grep 8080 \nss -tna | grep 22\n\ndns\n\nresolv\ncat /etc/resolv.conf | grep nameserver \nnano /etc/resolv.conf работает до перезагрузки \ndomain domain.local \nsearch domain.local \nnameserver 8.8.8.8 \nnameserver 1.1.1.1\n\nresolved\nnetworkctl status отображает список всех настроенные DNS-серверов в системе через netplan (или другое) для всех адаптеров \nresolvectl status в systemd 239 (ubuntu 22.04) systemd-resolve переименован в resolvectl, выводит настроенные сервера для global и список все адресов для конкретного сетевого интерфейса Link (ens33) \nresolvectl status | grep \"Current DNS\" отображает текущие используемые DNS-сервер \nsystemd-resolve --status служба локального DNS сервера \nresolvectl flush-caches &amp;&amp; systemd-resolve --flush-caches очистить локальный кэш DNS \njournalctl -u systemd-resolved | grep -E \"IN A|IN PTR|IN AAAA|IN PTR|IN MX\" логи кэша DNS \nsystemctl status systemd-resolved статус службы и его лог \ncat /run/systemd/resolve/stub-resolv.conf файл-заглушка для демона systemd-resolved, по умолчанию nameserver 127.0.0.53, который перенаправляет обращения к локальному DNS серверу, а он, в свою очередь уже получает информацию от других серверов в интернете\nnano /etc/systemd/resolved.conf конфигурационный файл, отвечающий за настройку DNS-серверов\nВключить кэширование:\n\nln -svi /run/systemd/resolve/resolv.conf /etc/resolv.conf создать симлинк для совместимости с приложениями, которые не используют библиотечные вызовы, а обращаются к DNS серверам напрямую, получая их из /etc/resolv.conf \nls -la /etc/resolv.conf\nnano /etc/resolv.conf не управляется напрямую службой systemd-resolved, а иногда с помощью использования initscripts или NetworkManager, и любые пользовательские изменения могут быть изменены через время или после перезагрузки\n\napt install resolvconf сервис для обновления списа адресов в /etc/resolv.conf (что бы он не перезаписывался) \nsystemctl status resolvconf\nnano /etc/resolvconf/resolv.conf.d/head\n\n\ndig\ndig \ndig google.com \ndig @1.1.1.1 google.com a использовать DNS сервер Cloudflare для преобразования имени \ndig @9.9.9.9 google.com mx использовать DNS сервер Quad9 для получения MX записи (A, NS, TXT) \ndig -x 8.8.8.8 @9.9.9.9 разрешить ip в имя\n\nmtr\nmtr google.com объединяет traceroute и ping каждого узла в трассеровке \nmtr -I ens33 google.com указать интерфейс для проверки \nmtr -b google.com отображать имя и ip \nmtr --tcp google.com использовать TCP SYN-пакеты или UDP-дейтаграммы (–udp) \nmtr -s 1000 google.com указать размер пакета \nmtr -r -c 1 google.com --json указать кол-во ping пакетов (-c 1 и -i 2 изменить интервал) и вывести в виде отчета (–report) в формате json/xml/csv/raw\n\ndoggo\ncurl -sS https://raw.githubusercontent.com/mr-karan/doggo/main/install.sh | sh DNS cli client (https://github.com/mr-karan/doggo) \ndoggo yandex.ru запросить домен, используя настройки по умолчанию \ndoggo yandex.ru MX запросить MX записи домена \ndoggo yandex.ru MX @8.8.8.8 использует указанный сервер для преобразования имен DNS \ndoggo -q yandex.ru -t MX --nameserver 1.1.1.1 \ndoggo yandex.ru --aa --ad запрос с установленными флагами авторитетного ответа и аутентифицированных данных \ndoggo yandex.ru --cd --do запрос с отключенной проверкой и установленными флагами DNSSEC OK \ndoggo yandex.ru --gp-from Germany Запрос с использованием API Globalping из указанной локации\n\nvnstat\napt install vnstat журнал часового, ежедневного и ежемесячного сетевого трафика \nsystemctl status vnstat проверить службу \nvnstat -l мониторинг в реальном режиме \nvnstat -h ежедневная почасовая история\n\nnetcat\nnc -zv 192.168.3.100 5985 проверить порт без попытки соединения (-z) в подробном режиме (-v) \nnc -zvn 192.168.3.100 1-1000 сканирование tcp-портов, не используя преобразование DNS (-n) \nnc -zvn 192.168.3.100 1-1000 2&gt;&amp;1 | grep succeeded перенаправить вывод ошибок в stdout и отфильтровать вывод \nnc -zvnu 192.168.3.100 5550-5560 сканирование udp-портов (-u) \nnc -lp 8081 открыть сокет (чат сервер) в режиме прослушивания (-listen) с указанием номера порта (-p) \nnc 192.168.3.101 8081 подключиться к сокету (чат-клиент) \nnc -lp 8081 &gt; out.txt все поступившие данные на сокет записываются в файл (вместо вывода в консоль) \ncat /etc/passwd | nc -N 192.168.3.101 8081 передать содержимое файла на удаленный сокет принимающей стороны (содержимое /etc/passwd запишется в out.txt) и закрыть удаленный сокет (-N) \nnc -l -w 1 -p 8081 задать timeout (-w) ожидания, в течении которого сервер слушает запрос, если будет 0, может не успеть считать запрос, на стороне клиента timeout должен быть не ниже \nnc -w 5 -Uvl server.sock &gt; out.txt создать UNIX-сокет и передать вывод в файл, сокет закроется через 5 секунд (-w 5) или если будет задан параметр -N на стороне клиента \nlsblk | nc -Uv server.sock подключиться к локальному сокету с второго терминала и отправить вывод команды в файл сокета приема \nwhile true; do echo -e \"HTTP/1.1 200 OK\\n\\n$(systemd-analyze plot)\" | nc -l -w 1 -p 8085; done HTTP-сервер с выводом анализа загрузки системы\n\nsocket api\n\ncurl -s http://192.168.3.101:8085/api/date \ncurl -s http://192.168.3.101:8085/api/disk | jq .blockdevices[]\n\nsocket proxy\nncat -l 8080 -k --sh-exec \"ncat 192.168.3.101 80\" \nsocat TCP-LISTEN:8080,fork,reuseaddr TCP:192.168.3.101:80\n\nproxy\n\nfroxy --socks 1080 запустить SOCKS прокси на порту 1080 \nfroxy --forward 8080 запустить HTTP/HTTPS прокси на порту 1080 \nfroxy --forward 8080 &gt;&gt; froxy.log &amp; запустить фоновый процесс и передать вывод логов в файл \nfroxy --local 5514 --remote 192.168.3.100:514 запустить обратный прокси сервер на порту 5514, который перенаправляет на хост 192.168.3.100 и порт 514 (syslog) \nfroxy --local 192.168.3.100:2121 --remote 192.168.3.101:21 TCP туннелирование для RDP \nfroxy --local 127.0.0.1:8443 --remote https://example.com принимать HTTPS трафик на порту 8443 и переадресовать на указанный URL (поддерживаются GET и POST запросы с передачей заголовков и тела запроса от клиента, для использования API запросы и прохождения авторизации на сайтах) \nfroxy --local *:8443 --remote https://example.com --user admin --pass admin слушать на всех интерфейсах и использовать авторизацию\n\nnmap\nnmap localhost узнать какие локальные порты прослушиваются \nnmap -sV localhost определить какое какая ОС и ПО работает на портах и их версия \nnmap -sL 192.168.3.0/24 список хостов с разрешением имен без пинга \nnmap -sP 192.168.3.0/24 ping метод host discovery (TCP ACK SYN пакет, используя системныей вызов connect) с отображением производителя сетевой платы \nnmap -F 192.168.3.0/24 fast mode port \nnmap -A 192.168.3.100 подробное сканирование ОС и ПО (ssh на другом порту, version, ad sites, rdp-ntlm-info) \nnmap -sA 192.168.3.100 обнаружить фильтрацию пакетов fw (filtered/unfiltered) с помощью TCP ACK \nnmap -PN 192.168.3.100 сканировании защищенного хоста без ping \nnmap -sO 192.168.3.100 определить какие именно IP-протоколы доступны и их статус, если отсутствует, значит фильтруется \nnmap -PU 192.168.3.100 обойти межсетевой экран с помощью UDP-пинга \nnmap -sS 192.168.3.100 выполнить полуоткрытое сканирование (TCP SYN) без установки подключения \nnmap -sU 192.168.3.100 проверка только UDP-портов\n\nmasscan\napt install masscan асинхронный (отправляет пакеты SYN) сканер TCP портов (https://github.com/robertdavidgraham/masscan) \nmasscan 192.168.3.100 -p80 \nmasscan 192.168.3.100 -p0-65535 --rate 100 \nmasscan 192.168.3.100 -p0-65535 --rate 100 --ping-timeout 1000 \nmasscan 192.168.3.1-100 -p80 \nmasscan 192.168.3.0/24 -p80,443 \nmasscan 192.168.3.100 -p80 --output-format json --output-file result.json\n\nrustscan\nwget https://github.com/RustScan/RustScan/releases/download/2.0.1/rustscan_2.0.1_amd64.deb \\ snap install nmapтребуется установить пакет зависимости \\apt-get install -fразрешить зависимости \\dpkg –install rustscan_2.0.1_amd64.deb\\rustscan -a 127.0.0.1\\rustscan -a 192.168.3.100` 32400/tcp open plex\n\ntcp\n\ntcp-scan 192.168.3.100 1024 5000\n\ntcpdump\ntcpdump -D список доступных сетевых интерфейсов \ntcpdump -n -i ens33 icmp слушать icmp-пакеты от всех на указанном интерфейсе (-i) без отображения доменных имен (-n) \ntcpdump -n -i ens33 udp -e слушать udp-пакеты и отображать MAC-адреса (-e) \ntcpdump -n -i ens33 port 8080 слушать трафик 8080 порта \ntcpdump -n -i ens33 port 80 or 443 \ntcpdump -n -i ens33 portrange 21-80 \ntcpdump -n -i ens33 ip src 192.168.3.99 and dst 192.168.3.103 отобразить ip пакеты, которые отправлены с указанного (src) ip-адреса на указанный (dst) ip-адрес \ntcpdump -n -i ens33 -X host 192.168.3.100 and port 32400 отобразить содержимое пакетов (-X) для хоста и порта\n\ntshark\napt install tshark \napt install termshark terminal UI for tshark (https://github.com/gcla/termshark) \ntshark -D список интерфейсов \ntshark -i 1 \ndisown \ntshark -i 1 -Y \"syslog\" захват пакетов syslog (udp.port == 514) \ntshark -i 1 host 192.168.3.104 захват пакетов для конкретного IP-адреса \ntshark -i 1 net 192.168.3.0/24 захват пакетов указанной подсети \ntshark -i 1 src host 192.168.3.104 захват исходящих пакетов \ntshark -i 1 dst host 192.168.3.104 захват входящих пакетов \ntshark -i 1 dst host 192.168.3.104 and port 8086 отфильтровать по входящему хосту и порту \ntshark -i 1 dst host 192.168.3.104 and port 8086 and src host 192.168.3.99 отфильтровать по исходящему хосту \ntshark -i 1 -x dst host 192.168.3.104 and port 8086 and src host 192.168.3.101 прочитать пакеты в шестнадцатеричном формате (-x) \ntshark -i 1 -O TCP dst host 192.168.3.104 and port 8086 and src host 192.168.3.101 прочитать TCP-заголовки \ntshark -i 1 -a duration:10 -w ~/192.168.3.0.pcap сохранить захват \ntshark -Y 'ip.addr == 192.168.3.106' -r ~/192.168.3.0.pcap прочитать файл захвата с использованием фильтра \ntshark -Y \"(ip.addr == 192.168.3.106) or (ip.addr == 192.168.3.107)\" -r ~/192.168.3.0.pcap отфильтровать по двум адресам (или) \ntshark -Y \"(ip.addr == 192.168.3.104) and (tcp.port == 8086)\" -r ~/192.168.3.0.pcap отфильтровать по двум параметрам (и) \ntshark -Y \"!(ip.addr == 192.168.3.104)\" -r ~/192.168.3.0.pcap исключить \ntshark -Y \"not arp and not (udp.port == 53)\" -r ~/192.168.3.0.pcap отобразить весь udp-трафик, исключив ping и dns пакеты\n\nping\n\nfping\nfping yandex.ru google.com параллельная проверка доступности двух хостов \nfping -p 5 yandex.ru google.com 5 параллельных запросов к каждому хосту \nfping -ag 192.168.3.0/24 icmp проверка все подсети \nfping &lt; hosts.txt произвести ping всех хостов указанных в файле с новой строки\n\nnetping\nСкрипт для параллельного ping всей подсети:\n\n\nloadgen\nГенератор нагрузки на bash:\n\n\nfirewall\n\nufw\nsystemctl status ufw \nufw status \nufw enable включить ufw (Uncomplicated Firewall) \nufw disable отключить \nufw reload перезапустить/применить настройки \nufw reset сбросить настройки (отключить ufw и удалить все правила) \nufw default deny incoming все входящие пакеты отклонять (политика по умолчанию, какие действия будут применяться к пакетам, если они не подпадают под созданные правила) \nufw default allow outgoing все исходящие разрешать \nufw allow in 22 разрешить входящий трафик на порт 22 \nufw allow out 22 разрешить исходящий трафик на порт 22 \nufw deny in 80/tcp запретить входящий TCP-трафик на 80 порт \nufw delete deny in 80/tcp удалить правило \nufw allow 161,10050,10051/tcp открыть несколько портов \nufw allow proto tcp from 0.0.0.0/24 to 192.168.3.100 port 3389 разрешить доступ со всех IP-адресов по TCP-протоколу к IP-адресу и порту 3389 \nufw allow from 192.168.3.0/24 to 192.168.3.110 разрешить подключение всем с подсети 192.168.1.0 к интерфейсу 192.168.1.2 (для Proxmox MGW) \nufw allow 25/tcp открыть для всех направлений 25 порт \nufw limit ssh лимт подключений к определенному порту с одного IP-адреса (для защиты от перебора), по умолчанию подключения блокируются, если пользователь пытается создать шесть и больше подключений за 30 секунд (настроить время и количество запросов можно только через iptables) \nufw logging on включить логирование \nufw logging medium выбрать уровень логирования (low/medium/high) \ncat /var/log/ufw директория хранения логов. Синтаксис: [UFW ALLOW/BLOCK/AUDIT] IN=интерфейс OUT=итерфейс SRC=ip_источника DST=ip_назначения LEN=размер_пакета TOS=0x10 PREC=0x00 TTL=64 ID=728 DF PROTO=протокол SPT=порт_источника DPT=порт назначения LEN=размер_пакета\n\nshow\nufw show listening отображает все прослушиваемые порты и правила для них (с указанием очередного номера в списке: [20] allow 161,10050,10051/tcp) \nufw show raw все активные правила в формате iptables \nufw show added недавно добавленные правила \nufw show builtins правила, добавленные по умолчанию \nufw show user-rules правила, добавленные пользователем \nufw show before-rules правила, которые выполняются перед принятием пакета \nufw show after-rules правила, которые выполняются после принятия пакета \nufw show logging-rules правила логгирования пакетов\n\nfirewalld\napt install firewalld \nsystemctl status firewalld \nsystemctl start firewalld \npkill -f firewalld убить процесс, если при запуске failed \nfirewall-cmd --state статус работы \nfirewall-cmd --reload применить настройки (перечитать) \nfirewall-cmd --list-all список созданных правил (для services и ports) \nfirewall-cmd --list-port только открытые порты \nfirewall-cmd --list-service только открытые службы \nfirewall-cmd --list-all-zones отобразить список зон \nfirewall-cmd --get-active-zones список используемых зон \nfirewall-cmd --list-all --zone=public информация о конкретной зоне \nfirewall-cmd --permanent --add-port=22/tcp открыть 22 порт \nfirewall-cmd --permanent --add-port=8000-8080/udp открыть диапазон портов \nfirewall-cmd --get-services | grep ssh отобразить список доступных служб \nfirewall-cmd --permanent --add-service=ssh разрешить порты для сервиса ssh \nfirewall-cmd --permanent --new-service=speedtest добавить службу \nfirewall-cmd --permanent --service=speedtest --add-port=80/tcp добавить порт к службе \nfirewall-cmd --info-service=speedtest информация о службе \nfirewall-cmd --permanent --add-rich-rule 'rule family=\"ipv4\" source address=\"192.168.3.0/24\" service name=\"speedtest\" accept' открыть доступ для подсети \nfirewall-cmd --permanent --add-rich-rule 'rule family=\"ipv4\" source address=\"192.168.3.0/24\" port port=\"22\" protocol=\"tcp\" accept' \nfirewall-cmd --permanent --add-rich-rule=\"rule family='ipv4' source address='192.168.21.0/24' reject\" закрыть доступ для подсети \nfirewall-cmd --list-rich-rules список правил с условиями \nfirewall-cmd --permanent --remove-port=22/tcp удалить правило\n\niptables\niptables -L -v выводит все существующие правила для каждой цепочки \niptables -L | grep -E \"tcp|udp\" \nif (( $(iptables -L | wc -l | bc) == 8)); then echo active; else echo inactive; fi \niptables -A INPUT -p tcp --dport 22 -j ACCEPT открыть входящий порт ssh \niptables -A INPUT -p tcp -s !192.168.3.99 --dport 22 -j DROP закрыть входящий порт ssh, исключить 192.168.3.99 \niptables-save сохранить настройки, что бы они были активны после перезагрузки \niptables -F удалить все правила текущей таблицы\n\nnftables\nnft -a list ruleset список существующих правил \nnft list tables список существующих таблиц \nnft flush ruleset очистить правила \nnft add table inet filter создать таблицу filter \nnft add chain inet filter input { type filter hook input priority 0\\; } добавить цепочку input \nnft add rule inet filter input ct state related,established counter accept \nnft add rule inet filter input iifname \"lo\" counter accept \nnft add rule inet filter input ip protocol icmp counter accept разрешить icmp \nnft add rule inet filter input tcp dport {80, 443} counter accept открыть порты \nnft add rule inet filter input ip saddr { 192.168.100.0/24, 1.1.1.1/32 } tcp dport 22 counter accept открыть 22 порт для подсетей \nnft chain inet filter input { policy drop \\; } остальное блокировать \necho \"flush ruleset\" &gt; /etc/nftables.conf очистить все правила \nnft -s list ruleset &gt;&gt; /etc/nftables.conf добавить правила в конфигурацию \nsystemctl enable nftables.service \nnft delete rule inet filter input handle 5 удалить правило по номеру \nnft add rule inet filter input position 5 tcp dport 22 counter accept добавить правило в конкретное место с номером в списке\n\nssh\nw отобразить активные сессии и их активность (время/дата входа, IDLE время простоя и последняя выполняемая команда) \nwho отобразить активные сессии, время/дата входа и ip с которого подключен пользователь \nlast -a история всех последних входов пользователей в систему \nlastlog дата последнего входа каждого пользователя в систему \nlast reboot история перезагрузки \nid -G получить список id крупп в которых состоит текущий пользователь\napt install xclip xsel буфер обмена \ncat /etc/ssh/sshd_config | xclip \nxsel &gt; sshd_config.bak \nnano /etc/ssh/sshd_config \nPort 2121 изменить порт \nPermitRootLogin yes включить возможность подключения пользователем root \nPasswordAuthentication no отключить аудентификацию по паролю \nX11Forwarding yes включить X11 \nTCPKeepAlive yes отвечает за проверку активности соединения (отправка пустых keep-alive пакетов для сохранения соединения) \nClientAliveInterval 60 задать интервал ожидания в секундах, через который sshd запросит ответ от клиента \nClientAliveCountMax 3 количество запросов без ответа до завешрения сеанса (ClientAliveInterval * ClientAliveCountMax = 180 секунд) \nsystemctl restart sshd \nsystemctl status sshd\n\nkeygen\nssh-keygen -t rsa -b 4096 сгенерировать пару ключей \nid_rsa приватный/закрытый ключ хранится на клиенте, от кого происходит подключение (для подключения без пароля имя файла должно быть по умолчанию) \ncat ~/.ssh/id_rsa.pub | xclip публичный/открытый ключ, для передачи на сервер, куда будем подключаться3 \nxsel &gt; ~/.ssh/authorized_keys передать содержимое публичного ключа (id_rsa.pub) на сервер, куда подключаться\n\nx11\napt-get install virt-manager ssh-askpass \nvirt-manager \nexport DISPLAY=username-VirtualBox:10.0 &amp;&amp; firefox\n\nscp\nssh-copy-id root@192.168.3.105 -p 2121 скопировать публичный ключ на удаленный сервер (добавить новой строкой), утилита будет искать в директории текущего локального пользователя файл публичного ключа и скопирует содержимое файла ключа ~/.ssh/id_rsa.pub указанному при подключение пользователю на удаленный компьютер в файл authorized_keys \nscp -P 2121 /home/lifailon/files/* lifailon@192.168.3.105:/home/lifailon/downaload/ скопировать содержимое каталога files на удаленный компьютер в директорию downaload \nscp -P 2121 -r kup@192.168.3.105:/home/lifailon/downaload /home/lifailon/files/ скачать (-r) данные с удаленного сервера на локальный\n\nsshpass\n\n\nsudoers\ncat /etc/sudoers конфигурационный файл настройки прав доступа утилиты sudo \nvisudo открыть sudoers в режиме проверки синтаксиса \nDefaults env_reset, timestamp_timeout=10 задать ограничение времени для sudo на 10 минут \necho \"lifailon ALL=(ALL) NOPASSWD:ALL\" &gt; /etc/sudoers.d/lifailon создать конфигурацию пользователя для использования sudo без пароля \nchmod 644 /etc/sudoers.d/lifailon \nlifailon ALL=NOPASSWD: /usr/bin/service memcahched restart, /usr/bin/apt-get update, /usr/bin/apt-get upgrade разрешить перезапуск определенного сервиса, обновление списка пакетов и установку обновлений системы \n%powerusers ALL=NOPASSWD: /usr/bin/service memcahched restart доступ на группу \nvisudo --check проверка синтаксиса и всех прав доступа (0440) \nsudo -l проверка прав доступа (выводит список команд, которые текущий пользователь может выполнять с использованием sudo)\n\nstrace\nstrace -c top -n 1 &gt; /dev/null показывает статистику системных вызовов программы (time - процент от времени общего выполнения, call - кол-во обращений и ошибки) \npid=$(pidof dd) узнать pid процесса по имени \nstrace -p $pid показывает системные вызовы процесса (читает данные из одного места с помощью вызова read и записывает в другое через write) \nstrace -f -p $(pgrep -o sshd) -o ~/passwd.txt -v -e trace=write -s 64 следим за всеми процессами sshd (-f), ищем все PID sshd процессов (-p), триггер только на запись данных (-e) и ограничиваем вывод 64 байтами \ncat ~/passwd.txt | grep \"[1-32][1-32]) = [1-32][1-32]\"\n\napt\napt-mark showauto список установленных автоматически пакетов \napt-mark showmanual список установленных пакетов вручную \necho $(($(apt-mark showauto | wc -l) + $(apt-mark showmanual | wc -l))) количество всех установленных пакетов \napt list --installed список установленных пакетов apt (Advanced Package Tool) \napt update обновить список всех установленных пакетов системы из источников, указанных в файле конфигурации /etc/apt/sources.list \ncat /etc/apt/sources.list | grep -Ev \"^#\" список источников \napt list --upgradable отобразить список, для каких пакетов доступны обновления \napt list --upgradable -a upgradable from, installed и все доступные версии \napt install --only-upgrade powershell обновить один выбранный пакет \napt --fix-broken install исправить проблемы и ошибки с зависимостями \napt full-upgrade обновляет все пакеты, которые уже установлены в системе, доставляет новые пакеты зависимости и удаляет пакеты, которые устанавливались в систему и уже не используются \napt install net-tools установить пакет \napt download net-tools скачать пакет без установки \napt install net-tools --reinstall переустановить пакет \napt remove net-tools удалить пакет (конфигурационные файлы, которые были изменены в системе удалены не будут) \napt purge net-tools полностью удалить пакет, вместе со всеми его конфигурационными файлами \napt policy net-tools какая версия установленна и какие доступны \napt install net-tools=number ver. установить конкретную версию \napt autoremove очистить ненужные пакеты, которые система не использует \napt autoclean очистить кэш пакетов\n\nsnap\nСодержат саму программу (deb-пакет), а также все её зависимости и библитотеки необходимых версий для данной программы. \nls /snap директория пакетов \nls /var/lib/snapd/snaps расположение загруженных пакетов .snap \nsnap install snap-store установка магазина приложений \nsnap find nmap поиск приложения в магазине snap \nsnap info nmap информация о пакете (его наличии, версия, дата релиза и размер) \nsnap list список установленных в системе пакетов \nsnap list | sed 1d | wc -l количество установленных пакетов \nsnap list --all nmap все доступные версии определенного пакета \nsnap refresh nmap обновить пакет до последней версии \nsnap revert nmap откатить версию до предыдущей \nsnap install nmap --stable установить конкретную версию пакета \nsnap connections nmap посмотреть доступность приложения к интерфейсам системы \nsnap remove nmap удалить пакет\n\ndpkg\ndpkg -i spark.deb установить пакет \ndpkg -l список установленных deb-пакетов \ndpkg -l | wc -l количество установленных пакетов \ndpkg -l spark проверить, установлен ли пакет в системе и его версию \ndpkg -s spark проверить статус пакета \ndpkg -r spark удалить (–remove) .deb пакет \ndpkg -P spark удалить пакет вместе с фаилами конфигурации \ndpkg -L spark куда установлен пакет (opt/Spark)\n\nntp\n\ntime\ntimedatectl текущее время \ntimedatectl set-timezone 'Europe/Moscow' изменить временную зону на MSK, +0300 (изменится Local time) \ntimedatectl list-timezones список часовых поясов \ntimedatectl set-ntp no отключить NTP service \ntimedatectl set-time \"13:00:00\" после отключения NTP указать время в ручную \ntimedatectl set-ntp yes включить NTP service (NTP service: active)\n\nlanguage\nlocale установленные в системе локализации \nupdate-locale LANG=en_US.UTF-8 изменить локализацию \napt-get install language-pack-en language-pack-en-base установить пакет локализаций \nnano /etc/default/locale \nLANG=en_US.UTF-8 \ndpkg-reconfigure locales\n\ntimesyncd\nsystemctl status systemd-timesyncd \nsystemctl status systemd-timesyncd | grep \"Status\": | sed -E \"s/^.+server //; \"s/.\\\"//\"\" узнать адрес сервера синхронизации времени \napt install systemd-timesyncd установить службу, если unit не запускается \napt-get remove ntp ntpstat --purge &amp;&amp; apt autoremove удалить ntpd (если был установлен) \nnano /etc/systemd/timesyncd.conf \nNTP=192.168.3.233 DC (Domain Controller) \nNTP=0.debian.pool.ntp.org 1.debian.pool.ntp.org 2.debian.pool.ntp.org 3.debian.pool.ntp.org \nFallbackNTP=ntp.ubuntu.com резерв \nsystemctl restart systemd-timesyncd \ntimedatectl set-ntp true включить использование systemd-timesyncd для синхронизации времени (вместо ntpd) \ntimedatectl status\n\nntpd\napt install ntp установить NTP-сервер/клиент, при установке будет удален пакет systemd-timesyncd \nsystemctl status ntp \nsntp --version \nufw allow 123/udp &amp;&amp; ufw reload \ntimedatectl set-ntp false отключить синхронизацию через systemd-timesyncd на клиенте \nnano /etc/ntp.conf \npool 0.ubuntu.pool.ntp.org указать пул серверов \nserver 0.ru.pool.ntp.org указать на конкретный сервер (если это pool, возьмет один) \nrestrict default kod notrap nomodify nopeer noquery limited настройки/ограничения для локального NTP сервера \nsystemctl restart ntp \nsystemctl status ntp \ntimedatectl status \nntpq -p проверка синхронизации времени (+ сервер можно использовать для сверки часов, * синхронизирует сейчас, - не рекомандован, st - уровень stratum, when — когда последний раз сверялось время, delay - время задержки, offset - разница между локальным временем и временем на сервере - отстают от сервера или спешат)\n\ntop\ntop -c выводит полный путь к исполняемым файлам с ключами, вместо названия \ntop -H выводит потоки процессов \ntop -i не выводит процессы, которые не используют ресурсы процессора \ntop -o %CPU отсортировать по CPU \ntop -o %MEM отсортировать по Memory\n\nhtop\nspace выделить несколько процессов (отменить Shift+U) \nu выбрать конкретного пользователя \nl посмотреть файлы, которые использует процесс \ns отобразить статистику системных вызовов (strace PID attached) F8 - AutoScroll, F4 - Filter, F9 - Stop/Start Tracing \nF4 фильтр по ключевому слову (например, cron) \nF5 древовидная структура \nF6 сортировка (PERCENT_CPU/PERCENT_MEM/USER/PRIORITY/TIME) \nF7 повысить приортите (до -20), чем меньше приоритет, тем больше процессорного времени отводится процессу \nF8 понизить приоритет (до 19) \nF9/K действие с процессом (сигналы), для завершения процесса: 15, 2, 3, 9 или 19 \nS (STATE) состояние процесса \nR [running or runnable] запущенные или находятся в очереди на запуск \nS [interruptible sleep] прерываемый сон (не исполняется процессором и ждет события или условия для запуска) \nD [uninterruptible sleep] непрерываемый сон (кратковременное состояние, которое невозможно остановить сигналом, т.к. процесс не может на него ответить) \nZ [zombie] завершенный процесс, ожидающий пока родительский процесс примет результат \nT остановленный сигналом SIGSTOP (-19/CTRL+Z) \nX мертвый (не должен показываться)\n\nbpytop\nsudo apt install bpytop \npip3 list | grep psutil проверить пакет \npip3 install psutil --break-system-packages установить пакет в обход ограничений \npython3 -m venv myenv создать виртуальное окружение \nsource myenv/bin/activate активировать виртуальное окружение \npip install psutil установить библиотеку для получения информации о системе \nbpytop \ndeactivate\n\natop\napt install atop \nnano /etc/default/atop \nLOGINTERVAL=10 \nsystemctl restart atop \natop -g показать общую информацию о процессе (по умолчанию) \natop -m показать информацию о процессах, связанных с памятью \natop -d показать информацию о процессах, связанных с дисками \natop -n показать информацию о процессах, связанных с сетью \natop -v показывать различную информацию о процессах (PPID родителя, пользователь/группа, дата/время) \natop -c показать командную строку для каждого процесса \natop -A сортировать процессы в порядке наибольшей активности ресурсов (автоматический режим) \natop -C сортировать процессы в порядке потребления процессора (по умолчанию) \natop -M сортировать процессы в порядке потребления памяти \natop -D сортировать процессы в порядке дисковой активности \natop -N сортировать процессы в порядке сетевой активности \natop -E сортировать процессы в порядке активности GPU\n\niftop\napt install iftop установить пакет \niftop -ti ens33 использовать текстовый интерфейс без ncurses \niftop -ts 1 -i ens33 печать одного единственного текстового вывода (-s) через 1 секунд, затем выход из системы \niftop -tL 0 -s 1 -i ens33 количество строк (-L) для печати \niftop -ni ens33 не преобразовывать имена хостов \niftop -Ni ens33 не преобразовывать номера портов в сервисы \niftop -pi ens33 работать в режиме promiscuous (показывать трафик между другими хостами в одном сегменте сети) \niftop -bi ens33 не отображать гистограмму трафика \niftop -Bi ens33 отображать пропускную способность в байтах \niftop -o 10si ens33 сортировка по второму столбцу (среднее значение трафика за 10 секунд, значение по умолчанию)\n\niotop\napt install iotop \niotop -o показывать только процессы или потоки, фактически выполняющие ввод-вывод \niotop -ou mysql показывать активные процессы от пользователя \niotop -P показывать только процессы, без потоков \niotop -p PID\n\ntop other\npip install --user glances кроссплатформенный инструмент мониторинга системы на Python (https://github.com/nicolargo/glances) \nglances\nsnap install bashtop монитор ресурсов на Bash (https://github.com/aristocratos/bashtop) \nbashtop\nnpm install gtop -g панель мониторинга системы для терминала на JavaScript (https://github.com/aksakalli/gtop) \ngtop\nsnap install bottom кроссплатформенный графический монитор системы и процессов на Rust (https://github.com/ClementTsang/bottom) \nbottom\ncurl -sL https://raw.githubusercontent.com/wimpysworld/deb-get/main/deb-get | sudo -E bash -s install deb-get &amp;&amp; deb-get install zenith как top, но с масштабируемыми графиками, а также использованием CPU, GPU, сети и дисков на Rust (https://github.com/bvaisvil/zenith) \nzenith\n\nps\napt-get install -y procps установить пакет procps \npstree -a отобразить все (-a) работающие процессы (демоны) и их дочерние в виде дерева \nps -FA отобразить подробный вывод (-F, PPID - родительский процесс) всех (-A) работающих процессов \nps -LFC mysqld отобразить потоки (-L) в колонках LWP и NLWP конкретного процесса по имени (-C) \nps -Fl отобразить приостановленные процессы (фоновые задания &amp;) \nps f -F отображает активные процессы текущего пользователя \nps f -u root активные процессы указанного пользователя \nps -o pid -u lifailon вывести только pid процессов запущенных конкретным пользователем \nps -p 3618275 найти процесс по его PID (-p/-s) \nps -aux --sort -rss выбрать все процессы, кроме фоновых (-a), сопоставлять с именем пользователя (-u), все процессы вне терминала (-x) и отсортировать по RSS, добавляется %CPU и %MEM \nps -lax не сопоставляются идентификаторы процессов с именами пользователей, к выводу добавляется WCHAN - ресурс, которого ожидает процесс \nps -FA --sort time сортировать по времени работы процесса \nps -Ao comm,user,rss,vsz,command отфильтровать вывод по потреблению памяти, названию команды/процесса и полному вызову команды с ключами \nPRI приоритет процесса \nNI уступчивость процесса (nice value от 19 до -20) \n(($PRI+$NI))=((39+-20))=19 \nTTY терминал, из под которого запущен процесс \nTIME общее время процессора, затраченное на работу процесса (bsdtime/cputime/time) или накопленное процессорное время (пользовательское + системное) \nSTIME время запуска команды (bsdstart), если процесс был запущен менее 24 часов назад, то формат вывода будет HH:MM, если больше, то Mmm:SS (Sep 18) \nC целочисленное значение процента времени процессора (%CPU) за время жизни процесса \n%CPU процент времени центрального процесса выделенного процессу или использование процессорного времени деленное на время работы процесса (pcpu) \n%MEM процент реальной памяти, используемой процессом или отношение размера резидентного набора процесса к объему физической памяти на машине (pmem) \nSZ размер в физических страницах образа ядра процесса.  Сюда входят текст, данные и пространство стека \nRSS постоянное потребление физической памяти (Resident Set Size non-swapped), реальный размер процесса в оперативной памяти, которую процесс занял (то есть что-то сохранил в память) \nVSZ виртуальная память (Virtual Memory Size) в килобайтах (1024-байтных единицах), которую выделили процессу, но это не означает, что он успел в эту память что-то записать \nLWP идентификатор дочернего потока (Light-Weight Process), будет выведен текущий ID если один или первый поток \nNLWP количество (Number) дочерних потоков (ps -LFC mysqld | sed 1d | wc -l) \nPSR ядро процессора, на котором выполняется процесс \nSTAT R - выполняется, D - ожидает записи на диск, S - неактивен (&lt;20 с), T - приостановлен, Z - зомби, с дополнительными флагами (W - процесс выгружен на диск, &lt; - процесс имеет повышенный приоритет, N - процесс имеет пониженный приоритет, L - некоторые процессы блокированы в ядре, s - процесс является лидером сеанса) \nmaj_flt количество крупных страничных ошибок, произошедших с данным процессом \nmin_flt количество мелких ошибок страниц \nps -Ao comm,user,cputime,pcpu,pmem,sz,rss,vsz,nlwp,psr,pri,ni --sort cputime\n\nkill\nkill -INT (-2) PID прерывания с терминала, bash пошлёт сигнал SIGINT процессу (аналогично CTRL+C) \nkill -KILL (-9) PID принудительно завершить процесс \nkill -STOP (-19) PID остановить процесс, bash пошлёт сигнал SIGSTOP процессу (аналогично CTRL+Z) \nkill -CONT (-18) PID продолжить остановленный процесс\n\nprocs\nsnap install procs современная замена ps, написанная на Rust (https://github.com/dalance/procs) \nprocs\n\njobs\n(ping google.com) &amp; запустить задачу в фоне (отображается [job] - номер задачи и PID процесса) \njobs отобразить список фоновых задач (+ задача активна) \njobs -l | wc -l получить список всех запущенных заданий \nfg 1 открыть задачу по номеру \ndisown завершить все фоновые задачи (удалить/очистить всю очередь заданий) \ndisown %1 завершить последнию (если она первая) запущенную задачу \nkill %1 завершить последнию запущенную задачу\n\nnohup\nnohup ping ya.ru &gt; ping.log &amp; используется для запуска процесса, который продолжает работать, даже если пользователь выйдет из сеанса (например, при закрытии терминала) \nps -ef | grep \"ping ya.ru\" найти процесс \nkill $(pgrep ping) завершить процесс\n\ntask-spooler\nsudo apt install task-spooler \ntsp sleep 10 &amp;&amp; echo ok создать задачу \ntsp -l отобразить список задач \ntsp -s 0 отобразить статус задачи \ntsp -t 0 вывести вывод работы задачи (в режиме tail) \ntsp -C очистить все выполненные (со статусом finished) задачи\n\nmem\nfree -m объем оперативной памяти и SWAP в МБайт \nswapon точка монтирования SWAP, type, size, used, priority (берет информацию из /proc/swaps) \nipcs -lm объем страниц разделяемой памяти (shared memory) \ncat /proc/meminfo | grep Dirty отобразить объем грязных (Dirty) страниц в кэше (еще не записанных на диск) \nsync записать все кэшированные, но еще не записанные данные на диск (вместо кэша данные будут читаться из диска) \ncat /proc/meminfo | grep -iE \"^cache|^buff\" объем кэша и буфера \necho 1 &gt; /proc/sys/vm/drop_caches отправить сигнал на вход drop_caches для очистки страничного кэша (free buff/cache) - PageCache (сигнал 1) \necho 2 &gt; /proc/sys/vm/drop_caches очистка кэша структуры файловой системы - inode, dentrie (сигнал 2)\n\nlsof\nPID идентификационный номер процесса, который открыл файл \nTID идентификационный номер задачи/потока, пустой столбец означает, что это не задача а процесс \nFD файловый дескриптор файла (r - доступ для чтения, w - доступ для записи, u - доступ для чтения и записи, -r - режим неизвестен и есть символ блокировки на чтение часть файла, R - на весь файл) \nTYPE тип узла, связанного с файлом (REG - обычный файл файловой системы, DIR - директория, CHR - символьный файл, BLK - блочный файл, INET - Интернет-сокет, unix - доменный сокет UNIX, IPv4 - IPv4 сокет, sock - неизвестный сокет, DEL - указатель Linux для удалённого файла, LINK - файл символьной ссылки, PIPE: — способ обмена данными между процессами) \nSIZE/OFF размер файла или смещение файла в байтах \nlsof | sed 1d | wc -l кол-во открытых файлов/дескрипторов \ncat /proc/sys/fs/file-nr кол-во открытых файловых дескрипторов в текущий момент, открытые файлы которые сейчас не используются, максимальное количество для открытия \nlsof +D /var/log/ отобразить каким процессом и пользователем используются файлы в каталоге (+D dir) FD: r/w/u \ndd if=/dev/zero of=~/dd-zero-file занять файл процессом dd и Ctrl+Z остановить процесс (отправить в jobs) \nls -lh ~/dd* \nlsof ~/dd-zero-file отобразить каким процессом занят файл (List Open Files) \nlsof -c dd отобразить все файлы запущенные по имени процесса/команды (в формате wildcard) \nlsof -p 1832509 отобразить все открытые файлы по номеру PID-процесса (-p) \nlsof -c mysql отобразить все файлы которые держит открытыми процесс по названию процесса (-c) \nlsof -c bash | grep \"\\.sh\" найти все запущенные скрипты \nkill -9 $(lsof -t ~/dd-zero-file) отфильтровать для вывода уникальных номеров PID-процесса (-t) использующие файл, для их завершения (kill) \nkill -9 $(lsof -t +D /smb/backup) убить все процессы использующие файлы в директории для дальнейшего umount /smb/backup \nlsof -u root отобразить все файлы открытые пользователем  \nlsof -u^root | wc -l исключить пользователя (^) из поиска и отобразить кол-во открытых файлов \nlsof -i:8080 проверить открыт ли порт (-i:)\n\ndescriptor\nlsof -a -p $$ -d 0,1,2 отобразить дескрипторы текущего интерпритатора ps $$ \n0u STDIN — стандартный поток ввода (с клавиатуры) \n1u STDOUT — стандартный поток вывода (на экран/в файл) \n2u STDERR — стандартный поток ошибок \ncat test.txt 1&gt; out.txt 2&gt; error.txt перенаправить успешный вывод (если файл существует) в out.txt, если ошибка в error.txt \ncat test2.txt 2&gt; /dev/null не выводить ошибки \ncat=$(cat test 2&gt;&amp;1) используется для перенаправления стандартного вывода ошибок (stderr - standard error) в стандартный вывод (stdout - standard output) с указанием файлового дескриптора (&amp;) вместо файла\n\nvmstat\ncat /proc/vmstat отображает nr_free_pages, inactive/active anon, file \ncat /proc/zoneinfo с разбиением на зоны памяти в зависимости от ее назначения \nvmstat -V procps-ng 3.3.17 (разработчик top) \nvmstat -s статистика memory/swap/io/system/cpu \nvmstat -d | grep sda статистика диска \nvmstat -D суммарная статистика дисков \nvmstat -t 1 2 отобразить 2 отчета (суммарный и текущий) с частатой обновления 1 секунда и timestamp (-t) \nr количество запущенных процессов (работающих или ожидающих выполнения) \nb количество спящих процессов \nswpd объем используемой виртуальной памяти \nfree объем свободной памяти \nbuff количество памяти, используемой в качестве буферов \ncache объем памяти, используемой в качестве кеша \ninact количество неактивной памяти (-a) \nactive количество активной памяти (-a) \nsi объем памяти, выгруженный с диска (/s) \nso объем памяти, перенесенный на диск (/s) \nbi IOPS (Input/Output Operations Per Second) блоки, полученные от блочного устройства (block input/sec) \nbo IOPS блоки, отправленные на блочное устройство (block output/sec) \nin количество прерываний в секунду, включая часы \ncs количество переключений контекста в секунду \nus время, потраченное на запуск кода, не относящегося к ядру (время пользователя) \nsy время, потраченное на выполнение кода ядра (системное время) \nid время бездействия \nwa время, проведенное в ожидании ввода/вывода \nst время, украденное из виртуальной машины\n\nsysstat\napt install sysstat\n\niostat\niostat -h выводить данные в kb/mb/gb (avg-cpu: %user %system %idle, tps - количество запросов на чтение и запись к устройству в секунду) \niostat -hp вывести статистику по устройству и всех его разделам (-p) \niostat -ky /dev/sd* 1 1 | grep -w sd. выводить статистику в КБайт (-k), при отображении нескольких записей с заданным интервалом первый отчет со статистикой с момента загрузки системы опускается (-y) \niostat -h /dev/sda3 -o JSON вывод в формате JSON\n\nmpstat\nmpstat отобразить подробную статистику по использованию процессора по каждому ядру, и куда используются ресурсы \nmpstat -P ALL отобразить отдельно для каждого ядра. \nmpstat 2 10 отобразить 10 раз с обновлением каждые 2 секунды \n%user процент использования процессора программами, запущенными на уровне пользователя \n%nice процент использования процессора программами запущенными в пространстве пользователя, с изменённым приоритетом \n%system процент использования процессора ядром \n%iowait процент времени затраченного на ожидание завершения операций ввода/вывода, если значение параметра слишком большое, значит много времени тратится на ожидание завершения ввода/вывода \n%steal процент простоя виртуального процессора, пока гипервизор отдаёт мощность другому виртуальному процессору \n%idle процент времени пока процессор не занят ничем\n\npidstat\npidstat используется для мониторинга родительских и дочерних процессов и текущих потоков \npidstat -p ALL вывести все активные и неактивные задачи\n\nstress\nstress --cpu 2 --timeout 10 загрузить выбранное количество ядер в течении 10 секунд \nstress -v N нагрузить виртуальную память \nstress --io 100 &amp; количество процессов нагрузки на ввод-вывод \niostat -d /dev/sda 1 \nstress --hdd 100 &amp; нагрузка на диск \nvmstat 1 100\n\nstress-ng\napt-get install stress-ng \nstress-ng --sequential 0 --class io --timeout 60s --metrics-brie тест ввода вывода \nstress-ng --hdd 5 --hdd-ops 100000 будет запущено 5 стрессоров для жёстких дисков, которые будут остановлены по завершении 100 тыс. bogo-операций \nstress-ng --cpu 1 --cpu-method matrixprod --metrics --timeout 60 \nstress-ng --sequential 0 --class memory --timeout 60s --metrics-brief \nstress-ng --cpu 2 --io 4 --vm 1 --vm-bytes 1G --timeout 60s --metrics-brief\n\nsmart\n\nsmartmontools\napt install smartmontools \nsmartctl -a /dev/sda тест диска и информация о модели и температуре \nsmartctl -H /dev/sda SMART Health Status\n\nsensors\napt install lm-sensors \nsensors-detect сканировать датчики температуры \nsensors отобразить датчики\n\nbadblocks\nbadblocks -s /dev/sda тест на наличие нечитаемых/битых блоков/секторов на диске\n\nhdparm\nhdparm -I /dev/sda | grep -i model модель жесткого диска (Model Number, Serial Number, Firmware Revision) \nhdparm -v /dev/sda кол-во секторов и настройки \nhdparm -tT /dev/sda тест скорости работы без кэша (-t) и с кэшем (-T) \nhdparm -D /dev/sda включение/отключение управления дефектами дисков \nhdparm -r /dev/sda включает режим read only для диска \nhdparm -A /dev/sda включает режим read-look-ahead, когда диск просматривается перед чтением, включена по умолчанию \nhdparm -a /dev/sda включает режим read-ahead, когда чтение выполняется в первую очередь, позволяет улучшить производительность чтения больших объемов данных \nhdparm -b /dev/sda остановить жесткий диск до следующего к нему обращения \nhdparm -S 1 /dev/sda остановить вращение мотора диска до следующего к нему обращения \nhdparm -B 120 /dev/sda настройка управления питанием Advanced Power Management (APM), чем ниже значение, тем лучше энергосбережение (255 - для отключения) \nhdparm -Z /dev/sda отключает режим энергосбережения \nhdparm -M 128 /dev/sda управление уровнем шума (принимает значения от 128 - более тихую работу, до 254 - высокую)\n\ndisk\ndu -sh /home отобразить общий размер указанной директории (-s) \ndu -Sh /home отобразить общий размер всех дочерних (-S) директорий по пути \ndu -h /home отображает общий размер указанной директории и подкаталогов внутри директории \ndu -ah /home отобразить общий размер директории и всех дочерних файлов (-a) и директорий\nlsblk отображает список всех подключенных блочных устройств (/dev), их SIZE, TYPE (disk/part/lvm) и точку монтирования (MOUNTPOINTS) \nlsblk -e7 вывод без loop \nlsblk -f отображает используемую FSTYPE, UUID, FSAVAIL - сколько свободно на диске и FSUSE - сколько занято на диске в процентах \nlsblk -o NAME,MODEL,SERIAL,SIZE,STATE --nodeps | grep running отображает модель, размер и статус без структуры разделов/lvm (–nodeps) \nlsblk -E NAME исключить дублирование вывода по колонке \nlsblk -S вывод информации о SCSI-устройствах (–scsi) \nlsblk -b выводить SIZE в байтах (–bytes) \nlsblk -J вывод в формате JSON (–json) \nlsblk -P использовать формат вывода key=“value” \nlsblk -m выводить информацию о правах доступа\ndf -h выводит информацию примонтированных файловых системах. Отображает общий объём (Size), занятого (Used) и свободно (Avail) пространства \ndf -h -T отобразить Type файловой системы (ext4/cifs)\napt install duf установить duf \nduf аналог df\nmount | grep /dev/ отобразить все примонтированные файловые системы \nmount | grep -P \"mapper|lv|vg\" примонтированные lvm\nfindmnt отобразить список смонтированных файловых систем в древовидном формате \nfindmnt -l в формате списка \nfindmnt -t ext4\ne2label /dev/sda3 узнать метку диска \nblkid отобразить список подключённых дисков, их UUID и TYPE \nlsscsi отобразить параметры SCSI устройств подключенных к системе\n\nparted\nparted -l отобразить список всех разделов на дисках \nparted -l | grep -i model \ndd if=/dev/zero of=/tmp/disk.img count=1000 bs=1M создать образ диска заполненный нулями размером 1Гб \nparted /tmp/disk.img передать parted созданный файл-образ для управления ФС \nparted /dev/sdc передать parted диск \nmktable gpt создать таблицу разделов GPT \nprint отобразить тип таблицы (Partition Table: GPT) и список разделов на устройстве, если они были созданы \nprint free отобразить свободное место и все разделы \nmkpart primary ext4 0 500M создать первый, первичный (primary) раздел с ФС ext4 размером 500Мб. \nmkpart primary ext4 500 1000M создать второй раздел (начало и конец) \nresizepart 2 600M уменьшить 2-й раздел до 100МБ (указывается end-конец) \nresizepart 2 100% увеличить до всего свободного размера \nrm 2 удалить раздел\n\nfdisk\nfdisk -l отображает список всех подключенных устройств построчно с размером секторов для каждого раздела \nfdisk -x подробный вывод (узнать UUID разделов) \nfdisk -l | grep /dev/sd \nfdisk -l | grep -E \"/dev/sd.[1-9]\" \nfdisk -l | grep -E \"lv|vg\" \nfdisk /dev/sdc \nm список команд \np отобразить размер диска и список разделов (/dev/sdc1) \nn создать новый раздел (p), указать номер раздела - partition number (4-128, default 4), начало и конце сектора - enter (оставить по умолчанию) \ni информация о выбранном разделе разделе (начало, конец, общий размер сектора и размер диска) \nt задать тип раздела - 30/8E (Linux LVM) или 20/83 (Linux filesystem) \nl отобразить список всех типов \nw сохранить \nq выход \npartprobe /dev/sdc информирует ядро ОС об изменениях таблицы разделов, запрашивая у системы, чтобы она перечитала таблицу разделов\n\nsfdisk\nsfdisk -d /dev/sdc &gt; sdc.partition.table.txt backup (аналогично dump cfdisk) \nsfdisk -f /dev/sdc &lt; sdc.partition.table.txt восстановить\nsfdisk -d /dev/sda | sfdisk -f /dev/sdd для восстановления MD RAID1 (sda в sdd) \nmdadm --manage /dev/md1 --add /dev/sdd1 восстановление копирования \nwatch cat /proc/mdstat отображать прогресс синхронизации\n\nНовый диск для расширения LVM:\n\nls /dev/sd* отобразить все диски в файловой системе \nfdisk -l отобразить все диски через fdisk \ncfdisk /dev/sda разметка диска на разделы (новый вариант) \ncfdisk /dev/sdb инициализировать новый диск, выбрать таблицу разделов (gpt) \nnew - sda4 создать новый раздел sda4 или sdb1 \nFree space - Partition size: 100G \nwrite - yes \npvcreate /dev/sda4 создать физический виртуальный том из раздела \nvgextend ubuntu-vg /dev/sda4 добавить новый раздел в группу \nlvextend -l +100%FREE /dev/ubuntu-vg/ubuntu-lv добавить свободное место в группе для логического раздела ubuntu-lv \nlsblk \ndf -h система будет видеть старый объем диска, необходимо выполнить команду по изменению размера файловой системы \ndf -T -h отобразить тип ФС \nresize2fs -f /dev/ubuntu-vg/ubuntu-lv для ext* \nbtrfs filesystem resize +100g / для btrfs\n\nНовый диск для нового раздела:\n\ncfdisk /dev/sdс создать раздел (cfdisk/fdisk/parted) \nmkfs.ext4 /dev/sdc1 форматировать раздел \nmkdir /mnt/sdc1 &amp;&amp; mount /dev/sdc1 /mnt/sdc1 примонтировать раздел, -o -r - монтировать только на чтение (–options –read-only) \ndf -h &amp;&amp; lsblk раздел нового диска должен быть в статусе Mounted on или MOUNTPOINTS \nchmod 0777 /mnt/sdc1 разрешить всем пользователям доступ к диску \ndf -h -T отображает тип файловой системы примонтированных разделов \nnano /etc/fstab сохранить монтирование после перезагрузкиы \n/dev/sdc1 /mnt/sdc1 ext4 rw,relatime 0 0 добавить по наименованию или UUID устройства \numount /dev/sdc1 отмантировать раздел\n\nswap\nfallocate -l 4G /swapfile.img создать файл для swap \ndd if=/dev/zero of=/swapfile.img count=1024 bs=1M создать файл для swap \nchmod 600 /swapfile.img дать права \nmkswap /swapfile.img создать swap-пространство из файла или используя весь объём раздела (mkswap /dev/sda4) \nswapon /swapfile.img активировать swap-пространство \necho '/swapfile.img none swap sw 0 0' | sudo tee -a /etc/fstab примонтировать \nfree -m отобразить объём \nswapoff -a отключить \nrm /swapfile.img удалить файл\n\nlvm\nLogical Volume Management - управление логическими томами, это дополнительный слой абстракции от железа, позволяющий собрать несколько разных дисков в один, и затем разбить его на группы и разделы. Позволяет использовать программный RAID 0 и 1 (зеркалирование) с управляемым пространством, снапшотами и импортированием томов в другую систему.\n\nPV (Physical Volume) — физические тома\n\npvs отображает список Physical Volume \npvdisplay подробная информация \npvcreate /dev/sdb инициализация диска в LVM как физический том\n\nVG (Volume Group) — группы томов, для объединения физических томов и создания общего логического диска, который будет разбиватсья на разделы\n\nvgs отображает список Volume Group \nvgdisplay подробная информация \nvgcreate vg21 /dev/sdb создать группу томов с добавлением физического тома на диске sdb\n\nLV (Logical Volume) — логические разделы\n\nlvs отображает список Logic Volume и их объём \nlvdisplay подробная информация \nlvcreate -n boot -L 1G vg21 создать первый логический раздел с наименованием boot \nlvcreate -n home -L 9G vg21 создать второй логический раздел с наименованием home \nlvcreate -n lv21 -l+100%FREE vg21 создать один логический раздел lv21 для группы томов vg21 и назначить ему весь объем диска \nmkfs -t ext4 /dev/vg21/lv21 назначить файловую систем ext4 \nmkdir /mnt/lv21 создать папку для монтирования \nmount /dev/vg21/lv21 /mnt/lv21 примонтировать раздел к созданной папке \necho \"/dev/vg21/lv21 /mnt/lv21 ext4 defaults 0 0\" &gt;&gt; /etc/fstab добавить монтирование в автозагруку\n\nУвеличить\n\nРасширение физического раздела можно сделать за счет добавление нового диска путём добавления в группу или увеличением имеющегося виртуального диска. \npvcreate /dev/sdc eсли добавлен новый диск, инициализируем (минус: если один из дисков выходит из строя, данные будут не доступны, аналогично работе RAID 0) \npvresize /dev/sdb если увеличин объем дискового пространства виртуального диска (resize - изменить размер физического тома) \nvgextend vg21 /dev/sdc расширить группу vg21 за счет добавленного диска sdc (или vgdisplay) \nvgs отобразит у какой из групп всего памяти VSize и сколько доступно памяти VFree для распредиления логическим разделам памяти, которую расширили \nlvextend -l +100%FREE /dev/vg21/lv21 добавить все свободное простраство логическому разделу \nvgs VFree будет=0 а в lsblk объём раздела увеличится \nlvextend -L+1G /dev/vg21/lv21 добавить 1Гб от группы томов vg21 разделу lv21 \nlvextend -L500G /dev/vg21/lv21 добавить до конкретного размера диска 500Гб \nlvs проверить \ndf -T отобразить используемую ФС \nresize2fs /dev/vg01/lv01 изменить размер для файловой системы ext4\n\nУменьшить\n\ne2fsck -fy /dev/vg21/lv21 проверка диска \nresize2fs /dev/vg21/lv21 500M уменьшить размер ФС на 500Мбайт \nlvreduce -L-500 /dev/vg21/lv21 уменьшить размер логического тома на 500Мбайт \nvgs добавится VFree 500m для распределения другой логической группе\nresize2fs /dev/ubuntu-vg/ubuntu-lv 1G уменьшить размер ФС на 500Мбайт \nlvreduce -L-1000 /dev/ubuntu-vg/ubuntu-lv уменьшить размер логического тома на 1000Мбайт (Logical volume ubuntu-vg/ubuntu-lv successfully resized) \nvgs VFree 1000.00m\n\nУдалить\n\numount /dev/vg21/lv21 предварительно отмантировать \nlvremove /dev/vg21/lv21 удалить логический том \nlvs нет групп \nvgs VSize и VFree объём совпадает \nvgremove vg21 удалить группу томов \npvremove /dev/sdb удалить диск sdb из LVM\n\nRAID 1\n\nНовый диск sdc разбить на 2 раздела (основной sdc1, немного больше чем у целевого зеркалируемого раздела lv21 и sdc2 оставшийся объем для ведения файла журнала) \npvcreate /dev/sdc1 /dev/sdc2 добавить оба раздела в LVM \nvgextend vg21 /dev/sdc1 /dev/sdc2 добавить в имеющиюся группу vg21 (расширить группу vg21) \nvgs у группы vg21 VFree увеличится объём добавленных томов-разделов \nlvconvert -m1 /dev/vg21/lv21 /dev/sdb /dev/sdc1 /dev/sdc2 конвертируем логический том lv21, входящий в состав группы vg21 в зеркалируемый том (-m1), зеркалируется /dev/sdb (где находится lv21) на sdс1, а /dev/sdс2 используется для ведения файла журнала.\nlvs -a -o +devices раздел lv21 пишет на 2 устройства\n\nlsblk\n\nИзвлекаем (удаляем) sdb (оригинальный диск) \nlsblk отображает только два раздела (part) sdc1 и sdc2 зеркального диска без LVM, т.к. группа не активна \nКомандой lvs видим группу vg21 и ошибки:\n\nvgchange -ay vg21 активировать группу \nmount /dev/vg21/lv21 /mnt/lv21 примонтировать группу lv21\n\nSnapshot\n\nlvs \nlvcreate -L 1G -s -n snap-1 /dev/ubuntu-vg/ubuntu-lv предварительно нужно добавить VFree в Volume Group (Logical volume “snap-1” created) \nlvcreate -L 1G -s -n snap-1 /dev/vg21/lv21 параметр -s помечает, что 1Гб дискового пространства из группы vg21 будет использоваться для snapshot lv21  \nlvs Origin - к какому логическому тому (lv) относиться snapshot, Data% — процент исползованного объема от выделенного. \nlsblk отображает изменения в томах разделов \nmount /dev/vg21/snap-1 /mnt/snap содержимое снапшота можно смонтировать как обычный раздел, если отредактивароть снапшот и откатиться к нему, мы получим те данные, которые отредактировали \nlvconvert --merge /dev/vg21/snap-1 откатиться к снапшоту snap-1, понадобится перезагрузка ОС (даже если это не основной диск)\n\nExport/Import\n\numount /dev/vg21/lv21 отмантировать \nvgchange -an vg21 деактивировать группу томов (0 logical volume в volume group “vg21”) \nvgexport vg21 экспортировать группу (successfully exported) \npvdisplay список групп (VG Name vg21 (exported)) \nПереносим диск на новый компьютер: \npvscan сканировать группы на новой системе (PV /dev/sdb is in exported VG vg21) \nvgimport vg21 импортировать в систему (successfully imported) \nvgs и lvs проверить группы \nvgchange -ay vg21 активировать группу (1+ lg в vg “vg21”) \nlsblk проверить подключение LVM\n\nmd\n\nSOFT RAID\n\nmdadm --zero-superblock --force /dev/sd{b,c} занулить все суперблоки на дисках, которые будут добавлены в RAID-массив, т.к. диски могут содержать служебную информацию о других RAID (вывод: unrecognised md component device - ни один из дисков ранее не был добавлен в массив) \nmdadm --create --verbose /dev/md0 -l 1 -n 2 /dev/sd{b,c} создать зеркальный RAID1 (-l/–leve 1) и указать кол-во дисков (-n/–raid-devices) \nmkfs.ext4 /dev/md0 форматировать в fs ext4 \nmkdir /md0-sdb-sdc-raid1 создать директорию для монтирования \nmount /dev/md0 /md0-sdb-sdc-raid1 примонтировать вручную \nlsblk -o NAME,UUID | grep md* отобразить UUID устройства \necho \"UUID=20482c47-fa11-462d-b7b8-93a342a7edf8 /md0-sdb-sdc-raid1 ext4 defaults 1 2\" &gt;&gt; /etc/fstab добавить в автозагрузку по UUID, т.к. после перезагрузки ОС номер может измениться на md127 \nmount -a примонтировать все файловые системы из fstab \ncat /proc/mdstat проверить состояние всех доступных RAID-массивов: md127 : active raid1 sdc[1] sdb[0] \nmdadm -D /dev/md127 подробное (–detail) состояние массива. State: cleane (проблем нет)/degraded (диск неисправен/поврежден). Active/Working/Failed/Spare Devices - количество активных (в работе)/рабочих/нерабочих/запасных дисков в массиве. Consistency Policy - тип синхронизации после сбоя в массиве (resync - полная синхронизация после восстановления массива). \nmdadm /dev/md127 --add /dev/sdd добавить запасной диск (в Spare Device) для горчей замены (Hot-Spare), в статусе списка дисков будет указан какой диск (State - spare /dev/sdd) \nmdadm -G /dev/md127 —raid-devices=3 расширить массив до трех дисков (добавится из запасных дисков в активный в массив) \nmdadm /dev/md127 --fail /dev/sdb пометить рабочий диск как нерабочий (перевести диск в Failed Device) для замены на запасной из Spare Device, который начнет автоматическую синхронизацию для ввода в массив (Rebuild Status : 50% complete) \nmdadm /dev/md127 --remove /dev/sdb удалить нерабочий диск из массива \nmdadm --stop /dev/md127 остановить/разобрать массив (предварительно umount /md0-sdb-sdc-raid1). В случае, если один из двух дисков был извлечен и не было запасных дисков, массив будет остановлен автоматически (State : inactive) \nmdadm --assemble --scan --verbose команда просканирует все диски на наличие разобранного/развалившегося RAID-массива и самостоятельно (автоматически) попытается восстановить из них массив с изначальным именем (mdadm -D /dev/md0) \nmdadm --stop /dev/md127 &amp;&amp; mdadm --assemble --scan &amp;&amp; mount -a &amp;&amp; mdadm -D /dev/md0 если в системе остался один диск (второй извлечен), RAID-массив будет востановлен (пересобран) автоматически из одного диска с статусом: clean, degraded, можно сразу добавить новый диск для автоматической синхронизации данных \nmdadm --assemble /dev/md127 /dev/sdb /dev/sdc указать вручную из каких дисков пересобрать массив \necho 'check' &gt; /sys/block/md127/md/sync_action проверять целостность данных в массиве (mdadm -D /dev/md0 - Check Status : 80% complete) \ncat /sys/block/md127/md/mismatch_cnt вывод файла (0 - все впорядке) \necho 'idle' &gt; /sys/block/md127/md/sync_action остановить проверку\n\ntgt\n\niSCSI\n\napt install tgt серверная часть называется порталом, который содержит цели (Target), каждая из которых предоставляет клиенту - инициатору (Initiator) доступ к блочным устройствам. \ndd if=/dev/zero of=/storage/disk1.img bs=1 count=0 seek=200G создание динамического диска (разреженный файл) с максимальным размером 200 ГБ, где вместо последовательности нулей на диске хранят информацию об этих последовательностях в специальной таблице \ndd if=/dev/zero of=/storage/disk1.img bs=1M count=2048 создание фиксированного размера диск \ncp --sparse=always filename newfilename преобразование обычного файла в разреженный \nnano /etc/tgt/targets.conf \nnano /etc/tgt/conf.d/disk-1.conf\n\nsystemctl restart tgt \ntgtadm --mode target --op show отобразит все подключенные цели и предоставляемые ими блочные устройства.\n\ndd\ndd if=/dev/sr0 of=/tmp/cd.iso bs=2048 сохранить образ диска (if=источник) в файл (of=назначение) с указанием кол-ва байт для чтения и записи за один раз (2МБайт), по умолчанию используется размер блока - 512 байт (2b блока = 1024 байт, 1k = 1 КБайт/1024 байт, 1kB = 1000 байт, 1M = 1024 КБайт/1 МБайт) \ndd if=/dev/mem bs=2048 count=100 вывести содержимое оперативной памяти на экран (не использовать файл) \ndd if=/dev/zero of=/tmp/md-01 bs=4M count=256 создать файл заполненный нулями (из /dev/zero) размером 1ГБ с указанием кол-во копируемых блоков (bs*count) или очистить диск \ndd if=/dev/random of=/tmp/md-02 bs=4M count=256 создать файл размером 1ГБ заполненный рандомными цифрами \ndd if=/dev/sda of=/tmp/mbr.img bs=1b count=1 скопировать в файл первые 512 байт диска содержащие таблицу разделов MBR \ndd if=/dev/sda of=/tmp/sda.img создать образ жесткого диска, используетася для полного backup системы (копирование раздела на двоичном уровне,включая таблицу MBR и всю пустую область диска и разделов)\n\nbackup\n\nСмонтировать внешний носитель для создания образа: mount /dev/sdb1 /mnt/disk_b\ndd if=/dev/sda of=/mnt/disk_b/disk.img bs=5M создать образа диска (.img) # создаем образ системы\nПодключить новый диск для записи образа на диск (sdc)\ndd if=/mnt/disk_b/disk.img of=/dev/sdc bs=5M записать образ на диск (с sdb1 на sdc):\nИзвлечь физический ЖД или удалить виртуальный диск sda (системный) и sdb (с записью образа). Диск sdc с копией системы автоматически инициализируется как диск sda после перезагрузки системы.\ngzip disk.img сжать образ (все нули сожмутся полностью - удобно для хранения backup, поддерживает только .img)\ndd if=/dev/sda conv=sync,noerror bs=5M | gzip -c  &gt; /mnt/disk_b/disk.img.gz создать сжатый образ системы \ngunzip -c /mnt/disk_b/disk.img.gz | dd of=/dev/sdс развернуть образ на диск\n\nnc -lp 5000 | sudo dd of=/backup/sda.img.gz сохранение сжатого файла образа жесткого диска sdb на удаленном сервере (принимающая сторона) \ndd if=/dev/sda | gzip -c | nc 192.168.21.121 5000 на узле, у которого установлен жесткий диск (передающая сторона) \nnc -lp 5000 | gunzip -c | sudo dd of=/dev/sdb восстановление содержимого жесткого диска из сжатого образа (записывать не на системный диск), сохраненного на удаленном сервере на локальном узле (принимающая сторона) \ncat /backup/sda.img.gz | nc my_local_host.com 5000 на удаленном сервере, на котором сохранен файл образа жесткого диска (передающая сторона)\n\niso\ndd if=/dev/sda3 status=progress of=/mnt/disk_b/disk.iso bs=5M создать iso-образ (сохранить образ раздел) \ndd if=путь/к/образу.iso of=/dev/sdb1 записать ISO-образ ОС на внешнее устройство \nsync завершить запись этой командой (что бы при извлечении не потерять часть данных) \nmount -o loop /mnt/disk_b/disk.iso /mnt/iso примонтировать файл образа только для чтения (iso - это директория, которую предварительно нужно создать), подключается как /dev/loop6 \numount /mnt/iso отмантировать\n\nrdiff\napt install rdiff-backup на базе rsync с поддержкой инкрементных архивов используя технологию hard link, чтобы вернуться назад на заданный день \nrdiff-backup /usr/lifailon/ /backup/test/ \nrdiff-backup user@hostname::/remote-dir local-dir -v5 --print-statistics по ssh с сервера&nbsp;на локальный бэкап-сервер, в ней же будет находиться директория rdiff-backup-data, которая будет содержать информацию и логи о проводимых бэкапах, а также инкременты, необходимые для отката на любой прошлый выполненный бэкап \nrdiff-backup list files --changed-since 5D local-dir отобразить, какие файлы изменились за последние 5 дней \nrdiff-backup list files --at 5D local-dir отобразить список файлов, которые присутствовали в архиве 5 дней назад \nrdiff-backup restore local-dir/rdiff-backup-data/increments.2023-10-29T21:03:37+03:00.dir /tmp/restore восстановить файлы из инкримента\n\nusers\nsudo -u www-data выполнить команду от имени другого пользователя \nsu root войти под пользователем root \nsudo su изменить пользователя на root, при этом пользователь остается в той же директории потому, что выполняется ваш .bashrc. А также .profile пользователя root поэтому вы окажетесь в окружении root \nsudo -i указывает утилите что нужно переключиться в консоль от имени root, при этом перемещаясь в домашний каталог root, и будет выполнен его .bashrc и .profile \nsudo /bin/bash запускает еще одну оболочку bash от имени суперпользователя. Файлы конфигурации не читаются, но выполняется только .bashrc вашего пользователя. Вы не окажетесь в окружении root, а просто останетесь в своем окружении с правами суперпользователя\ncat /etc/passwd список/база данных пользователей зарегистрированных в системе \ncat /etc/group список групп \ncat /etc/shadow | grep -Ev \"^.+:\\*:\" пароли пользователей хранящиеся в зашифрованном виде (заданные с помощью /usr/bin/passwd), если * или ! пользователь не сможет войти в систему с использованием аутентификации по паролю, другие методы входа, как аутентификация на основе ключей или переключение на пользователя разрешены. Синтаксис: логин:пароль:последнее изменения пароля (количество дней исчисляется с 1 января 1970 года):минимальный срок действия пароля:максимальный срок действия:период предупреждения:период бездействия:срок хранения\ncat /etc/login.defs | grep -Pv \"^$|^#\" настройка поведения утилиты управления пользователями и параметрами входа в систему (настройки минимального и максимального id для выдачи новому пользователю/группе, количество попыток входа, таймау, что делать с директорий пользователя при создании или удалении и т.п.) \ncat /etc/login.defs | grep \"^PASS\" максимальное кол-во дней действия пароля (PASS_MAX_DAYS), минимальное количество дней допустимое между сменами пароля (PASS_MIN_DAYS), количество дней предупреждающих об истечении срока действия пароля (PASS_WARN_AGE), ограничения длины паролей (PASS_MIN_LEN/PASS_MAX_LEN), максимальное кол-во попыток входа при вводе неправильного пароля (LOGIN_RETRIES), время на вход (LOGIN_TIMEOUT), включить логирование успешных входов (LOG_OK_LOGINS), логирование неизветных имен для системы пользователей при неудачных попытках входа (LOG_UNKFAIL_ENAB)\n\npasswd\npasswd включить учетную запись root и задать ей пароль \npasswd username смена пароля пользователя \npasswd -l username заблокировать уч. запись \npasswd -u username разблокировать уч. запись\n\nchage\nchage -l root информация последней смене пароля и срок действия (последняя смена пароля, Срок действия пароля, Пароль неактивен, Срок действия учетной записи, Минимальное количество дней между сменой пароля, Максимальное количество дней между сменой пароля, Количество дней предупреждения до истечения срока действия пароля) \nchage -E lifailon установить дату истечения срока действия пользовательской учетной записи (-E) \nchage lifailon -M 30 установки минимального (-m) и максимального (-M) срока действия пароля\n\nid\nid lifailon узнать ID \nuid=1000(lifailon) gid=1000(lifailon) groups=1000(lifailon),4(adm),24(cdrom),27(sudo),30(dip),46(plugdev),116(lxd) \nusermod -u 1022 kup изменить UID \ngroupmod -g 1022 kup изменить GID\n\nusermod\nusermod -L lifailon заблокировать вход по паролю (перед паролем пользователя в файле /etc/shadow добавляется восклицательный знак) \nusermod --expiredate 1 -L lifailon заблокировать пользователя (не будет возможности авторизоваться через su: Authentication failure) \nusermod --expiredate 2023-10-25 lifailon задать дату блокировки \nusermod --expiredate \"\" -U lifailon разблокировать пользователя \nusermod -g root lifailon изменить основную группу пользователя \nusermod -a -G plugdev lifailon добавить пользователя в дополнительную группу (-G), обязательно нужно использовать вместе с -a, чтобы не удалять старые \nusermod -d /root lifailon изменить домашнюю директорию пользователя (-d) \nusermod -m -d /root lifailon переместить домашнюю папку сохранив все содержимое (-m) \nusermod -s /usr/bin/dash lifailon изменить оболочку по умолчанию (-s) \nusermod -u 2002 lifailon изменить id пользователя (-u) \nusermod -l lifailon failon изменить имя пользователя (-l) \nusermod --password \"NewPassword\" lifailon изменить пароль\n\nprofile\nnano /etc/bash.bashrc задать timeout для завершения бездейстующих (idle time) SSH и локальных сессий \nnano /etc/profile задать на уровне профиля (приоритет ниже)\n\n\nbashrc\n.bashrc файл переменных конкретного пользователя \n.bash_profile переменные вступают в силу каждый раз когда пользователь подключается удаленно по SSH. Если этот файл отсутствует система будет искать .bash_login или .profile \n/etc/environment файл для создания, редактирования и удаления каких-либо переменных окружения на системном уровне. Переменные окружения, созданные в этом файле доступны для всей системы, для каждого пользователя и даже при удаленном подключении. \n/etc/bash.bashrc файл выполняется для каждого пользователя, каждый раз когда он создает новую терминальную сессию. Это работает только для локальных пользователей, при подключении через интернет, такие переменные не будут доступны. \n/etc/profile системный файл profile, все переменные из этого файла, доступны любому пользователю в системе, только если он вошел удаленно. Но они не будут доступны, при создании локальной терминальной сессии, то есть если вы просто откроете терминал.\n\nuseradd\nuseradd -D отобразить параметры, которые будут применены для пользователя по умолчанию \nuseradd -o -u 0 -g 0 -s /bin/bash newroot создать нового пользователя с правами root \nuseradd -G adm,wheel -p password -s /bin/bash test2 разрешить пользователю читать логи и пользоваться sudo\nuseradd username \n-s указать командную оболочку для пользователя (по умолчанию /bin/sh - без оболочки, можно указать /bin/bash) \n-b указать базовый каталог для размещения домашнего каталога пользователя (по умолчанию /home) \n-d домашний каталог, в котором будут размещаться файлы пользователя \n-m создавать домашний каталог пользователя, если он не существует \n-c комментарий к учетной записи \n-g основная группа пользователя \n-G список дополнительных групп \n-N не создавать группу с именем пользователя \n-p задать пароль пользователя \n-l не сохранять информацию о входах пользователя в lastlog и faillog \n-o разрешить создание пользователя linux с неуникальным идентификатором UID \n-u идентификатор для пользователя\n\nadduser\nadduser username интерактивное создание пользователя, по умолчанию будет создан домашний каталог (/home/username), можно указать данные о пользователе или пропустить и задать пароль \ndeluser username удалить пользователя (каталог не удаляется)\n\nchmod\n\n--- нет прав \n--x разрешено только выполнение файла, как программы но не изменение и не чтение \n-w- разрешена только запись и изменение файла \n-wx разрешено изменение и выполнение, в случае с каталогом нельзя посмотреть его содержимое \nr-- права только на чтение \nr-x только чтение и выполнение, без права на запись \nrw- права на чтение и запись, но без выполнения \nrwx все права \n--s установлен SUID или SGID бит, первый отображается в поле для владельца, второй для группы \n--t установлен sticky-bit, значит пользователи не могут удалить этот файл\nr чтение \nw запись \nx выполнение \ns выполнение  от имени суперпользователя (дополнительный)\nu пользователь-владелец файла \ng группа-владельц файла \no все остальные пользователи\n+ включить \n- отключить\n-R поменять права на все подкаталоги и файлы указанной директории \n-v выводить информацию обо всех изменениях\nchmod u+x filename разрешить выполнение (x) для владельца (u) \nchmod ugo+x filename разрешить выполнение (x) для всех (ugo) \nchmod ug+r filename разрешить чтение (r) для владельца (u) и группы (g) \nchmod o-w filename запретить запись (w) для остальных пользователей (o) \nchmod -R g+rwx dir  дать полный доступ (rwx) группе (g) на директорию и всем файлам в ней (-R)\nПрава доступа в восьмеричной системе, которые полностью переписывают текущие права новыми для всех категорий пользователей:\n0 никаких прав \n1 только выполнение \n2 только запись \n3 выполнение и запись \n4 только чтение \n5 чтение и выполнение \n6 чтение и запись \n7 чтение, запись и выполнение\nchmod 744 filename разрешить полные права для владельца, а остальным только чтение \nchmod 664 filename чтение и запись для владельца и группы, только чтение для остальных\n\nchown\nchown lifailon tmp изменить владельца на пользователя lifailon для директории tmp \nchown lifailon:lifailon tmp изменить владельца и группу \nchown -R lifailon:lifailon tmp применить изменения ко всем подкаталогам (-R) \nchown --from=root:root lifailon:lifailon -R ./ изменить владельца и группу только для тех каталогов и файлов, у которых владелец и группа root в текущем каталоге\n\ngroups\ngroups lifailon отобразить в каких группах находится указанный пользователь \ntouch testdir при создании файла ему назначается основная группа пользователя который его создал (ls -l testdir) \ncat /etc/group список групп \nchgrp testdir tmp изменить группу на testdir для директории tmp \ngroupadd testdir создать группу \ndelgroup testdir удалить группу, если ошибка ‘testdir’ still has testdir' as their primary group! предварительно исключить из группы всех пользователей\nОпции: \n-g изменить основную группу для пользователя \n-G дополнительные группы, в которые нужно добавить пользователя (затирает предыдущие) \n-a добавить пользователя в дополнительные группы c параметром -G, а не заменять им текущее значение \n-R удалить пользователя из группы\n\nusermod\nusermod -aG sudo lifailon добавить пользователя в дополнительную группу (-aG, без затирания предыдущих групп) sudo (добавить в группу root) \nusermod -aG disk lifailon пользователь будет иметь прямой доступ к ЖД без команды sudo (например монтировать) \nusermod -g root lifailon изменить основную группу (-g) для пользователя на root \nusermod -R ssh lifailon удалить пользователя из группы\n\ndomain\n\nrealmd\nhostnamectl \nhostnamectl set-hostname srv-01.domain.local изменить имя сервера (/etc/hostname)\nnano /etc/resolv.conf \nnameserver 192.168.3.233 адрес DC \nsearch domain.local\napt -y install realmd libnss-sss libpam-sss sssd sssd-tools adcli samba-common-bin oddjob oddjob-mkhomedir packagekit \nnano /etc/realmd.conf задать атрибуты хоста, которые будут сохранены в учетной записи компьютера в AD (атрибуты operatingSystem и operatingSystemVersion)\n\nrealm discover domain.local --verbose возвращает полную конфигурацию домена и список пакетов, которые должны быть установлены для регистрации системы в домене \nrealm join --help | grep pass \nrealm join -U username domain.local –one-time-passwordввести в домен \\realm listпроверить после подключения (server-software: active-directory) \\id username@domain.local` получить сведения о пользователе домена\n\nsssd\nПрава доступа на логирование в Linux из под УЗ домена (sssd используется для аутентификации Kerberos)\nrealm permit -g 'ssh-connect-domain' добавит доменную группу (echo “simple_allow_groups = ssh-connect-domain” &gt;&gt; /etc/sssd/sssd.conf) \nrealm permit username@domain.local добавит пользователя (echo “simple_allow_users = username” &gt;&gt; /etc/sssd/sssd.conf) \nrealm deny --all запретить доступ всем пользователям (очищает список simple_allow_* в sssd.conf) \nsystemctl restart sssd\nСоздавать домашний каталог для нового доменного пользователя:\n\npam-auth-update обновить конфигурацию, выбрать созданную: activate mkhomedir\nПрава на sudo:\nnano /etc/sudoers.d/domain_admins nano /etc/sudoers.d/linux-admins\n\nssh username@domain.local@hostname\n\nsyslog\n\nserver\nsystemctl status rsyslog\nnano /etc/rsyslog.conf\n\nsystemctl restart rsyslog\n\nclient\nnano /etc/rsyslog.d/all.conf\n\nsystemctl restart rsyslog \nls /var/log/remote на сервере должна появиться директория с ip-адресом/именем клиента \nls -lh /var/log/remote/* \ncat /var/log/remote/192.168.3.104/syslog.log | grep influxd \nsystemctl restart zabbix-agent \ncat /var/log/remote/192.168.3.104/syslog.log | grep zabbix_agentd\n\nzabbix-agent\nnano /etc/zabbix/zabbix_agentd.conf\n\nsystemctl restart zabbix-agent\n\nommail\nnano /etc/rsyslog.conf\n\n\nlogrotate\nsystemctl status logrotate.timer\nnano /etc/logrotate.conf\n\nnano /etc/logrotate.d/logrotate_remote.conf\n\nУсловия:\nhourly каждый час \ndaily каждый день \nweekly каждую неделю \nmonthly каждый месяц \nyearly каждый год \nsize минимальный размер лога, меньше этого значения ротация выполняться не будет\nДействия:\nrotate 2 указать, сколько последних ротированных лог-файлов нужно хранить, остальные удалять \nmaxage 30 указать, за сколько последних дней хранить ротированные файлы, остальные удалять \ncopytruncate сначала создается копия файла лога, после уже обрезается действующий (нужно, когда программа должна писать лог непрерывно, возможность потери записей, если она придется на процесс усечения) \nextension сохранять оригинальный лог файл после ротации \ncompress сжимать ротированный лог (gzip) \ndelaycompress не сжимать последний и предпоследний журнал (позволяет избежать ошибок, связанных с отсутствием доступа к используемому файлу) \ncreate # 0644 root root создать пустой лог файл на месте старого \nolddir /path перемещать логи в отдельную папку при срабатывании условия \ndateext добавляет дату ротации перед заголовком старого лога \nmissingok не выдавать ошибки, если лог файла не существует \nnotifempty если файл пустой, не выполнять никаких действий \nprerotate script.sh endscript скрипт, который необходимо выполнить перед чисткой лога \npostrotate script.sh endscript скрипт, который необходимо выполнить после чистки лога \nsharedscripts если был указан путь в формате wildcard (*), выполнить скрипт один раз после завершения ротации всех файлов\nlogrotate -d /etc/logrotate.d/logrotate_remote.conf проверить ротацию (–debug) \nlogrotate -fv /etc/logrotate.d/logrotate_remote.conf запустить ротацию сейчас (–force) с подробным выводом (–verbose) \ncat /etc/cron.daily/logrotate задание на автоматический запуск создается по умолчанию, который читает конфигурационный файл ротации /etc/logrotate.conf, в нем указана директрия: include /etc/logrotate.d в которой лежат файлы ротации \nwhich logrotate узнать путь до исполняемого файла \ncrontab -e \n00 3 * * * /usr/sbin/logrotate -f /etc/logrotate.d/logrotate_remote.conf настроить собственное ручное расписание с ежедневным запусков в 3:00\n\nlog\n\nlazyjournal - терминальный пользовательский интерфейс для journalctl, журналов файловой системы, а также контейнеров Docker, Podman и Kubernetes для быстрого просмотра и фильтрации с поддержкой нечеткого поиска, регулярных выражений и раскрашивания вывода:\n\ncurl https://raw.githubusercontent.com/Lifailon/lazyjournal/main/install.sh | bash \nlazyjournal\n\nlnav - терминальный пользовательский интерфейс для логов файловой системы с таймстампами, возможностью поиска и подсветкой:\n\napt install lnav \njournalctl -f -a -xe -o json | lnav \nssh playground@demo.lnav.org\n\ntailspin - раскрашивание любого вывода:\n\napt install tailspin \ncat /var/log/syslog | tailspin\n\ntoolong - терминальный пользовательский интерфейс для интерактивного просмотра логов с поддержкой поиска и объединения журналов (заменяет tail, less и grep):\n\npipx install toolong \ntl /var/log/syslog* откроет все журналы syslog (включая поддержку чтения архивных журналов) \ntl /var/log/syslog /var/log/syslog.1 --merge объеденит два журнала в один \ncat /var/log/syslog /var/log/syslog.1 | tailspin | tl вначале красим вывод и потом передаем на вход toolong \\\n\nttyd - позволяет запускать терминальные интерфейсы в Web интерфейсе с поддержкой базовой авторизации:\n\nsudo apt install ttyd \nttyd -W -p 4444 tl /var/log/syslog* \nttyd -W -p 4444 -c admin:admin tl /var/log/syslog*\n\nsmb\n\ncifs\napt install cifs-utils установить SMB Client\nnano /root/.smbclient\n\nmkdir /smb &amp;&amp; mkdir /smb/backup создать директорию для монтирования \nnano /etc/fstab \n//192.168.3.100/Backup /smb/backup cifs user,rw,credentials=/root/.smbclient 0 0 rw права на чтение и запись \nmount -a примонтировать (открыть порты на сервере: 137/UDP; 138/UDP; 139/TCP; 445/TCP) \ndf -h\n//192.168.3.100/torrent-files /home/lifailon/torrent-files cifs user,rw,credentials=/root/.smbclient,perms=0666 0 0 \nchmod 666 /home/lifailon/torrent-files \nchown -R lifailon:lifailon /home/lifailon/torrent-files \nsmbclient $path_smb_qb --user=smb --password=kinozal\n\nsamba\niptables -I INPUT -p tcp --dport 445 -j ACCEPT используется для Samba \niptables -I INPUT -p tcp --dport 137 -j ACCEPT используется для работы NetBIOS (использование имени компьютера для доступа) \niptables -I INPUT -p tcp --dport 139 -j ACCEPT \niptables -I INPUT -p udp --dport 137:138 -j ACCEPT \niptables -L отобразить список правил \niptables -F очистить список правил \napt install iptables-persistent \nnetfilter-persistent save применить настройки\napt install samba \nsystemctl status smbd \nmkdir -p /public/share создать общую папку \nchmod 777 /public/share выдать права\nnano /etc/samba/smb.conf\n\n[Общая папка] имя общей папки, которое увидят пользователи при подключение\npath путь на сервере, где будут храниться данные\npublic для общего доступа, чтобы все могли работать с ресурсом\nwritable разрешает запись в сетевую папку\nread only = yes только для чтения. no - для полного доступа управлением ФС\nguest ok разрешает доступ к папке гостевой учетной записи\ncreate mask, directory mask, force create mode, force directory mode при создании новой папки или файла назначаются указанные права. В примере указаны полные права.\nsystemctl restart smbd применить настройки\nuseradd smb1 создать пользователя \npasswd smb1 задать пароль пользователю \nsmbpasswd -a smb1 создать пользователя для Samba\n\n\nclient cifs\napt install cifs-utils \nmkdir /mnt/share1 \nmount -t cifs \"//192.168.3.103/share1\" /mnt/share1 -o user=smb1 примонтировать удаленный каталог на клиенте Linux с авторизацией \ndf -handle \n//192.168.3.103/share1  24G  23G  1.2G  96%  /mnt/share1\n\nclient samba-client\napt install samba-client \nsmbclient -L 192.168.3.103 -U share1\n\nrecycle\n\nrecycle:repository где хранить удаленные объекты. Удаленные файлы попадут в скрытый каталог .recycle в котором создастся каталог с именем пользователя, удалившего файл или папку \nrecycle:keeptree удалять объекты с сохранением дерева каталогов \nrecycle:touch изменить дату изменения файла при его перемещении в корзину \nrecycle:versions при удалении файлов с совпадающими именами, добавлять номер версии \nrecycle:maxsize не помещать в корзину файлы, размер которых больше заданного параметра (в байтах). 0 - помещать файлы любого размера \nrecycle:exclude исключить файлы \nrecycle:exclude_dir исключить каталог\n\nnfs\n\nserver\napt install nfs-kernel-server установить сервер, с помощью которого будет выполнено открытие шары. Сервис NFS слушает соединения для TCP и UDP на порту 2049. \napt install rpcbind \nrpcinfo -p | grep nfs проверить, слушается ли порт nfs \ncat /proc/filesystems | grep nfs проверить, поддерживается ли NFS на уровне ядра (вывод: nodev nfsd) \nmodprobe nfs вручную загрузить модуль ядра nfs \nsystemctl status nfs-server служба сервера \nufw allow 111,2049 &amp;&amp; ufw reload \nmkdir nfs-folder создать папку для шары \nadduser nfs-user создать пользователя для подключения \nchown nfs-user:nfs-user nfs-folder изменить владельца шары \nchmod 775 nfs-folder дать полный доступ владульцу и группе \nnano /etc/exports файл настройки шары \n/nfs-folder 192.168.3.0/24(rw,sync,no_subtree_check) /путь/к/директории (шарим), удаленный IP-адрес клиента или подсеть (что бы разрешить все адреса используется 0.0.0.0/24 или символ *) и опции в скобках \nexportfs -a применить настройки (обновить таблицу экспорта NFS)\nOptions:\nrw разрешить чтение и запись в этой папке \nro разрешить только чтение \nsync отвечать на следующие запросы только тогда, когда данные будут сохранены на диск (по умолчанию) \nasync не блокировать подключения пока данные записываются на диск \nsecure использовать для соединения только порты ниже 1024 \ninsecure использовать любые порты \nnohide не скрывать дочернии директории, при открытии доступа к нескольким директориям \nroot_squash подменять запросы от root на анонимные (используется по умолчанию) \nno_root_squash не подменять запросы от root на анонимные (все подключения от имени пользователя root считаются по умолчанию анонимными nfsnobody, отключение этой опции не безопасно, потому что любой root пользователь сможет получить доступ на запись ко всем файлам) \nall_squash превращать все запросы в анонимные \nsubtree_check проверять не пытается ли пользователь выйти за пределы экспортированной папки \nno_subtree_check отключить проверку обращения к экспортированной папке, улучшает производительность, но снижает безопасность, можно использовать когда экспортируется раздел диска \nanonuid и anongid указывает uid и gid для анонимного пользователя\nРаботает стандартная система доступа UNIX, поэтому, если нужно чтобы пользователь подключивший директорию мог получить доступ к папке, то на клиентской стороне должен существовать пользователь с таким же UID (именем и ID), а на сервере для расшаренной директории должна принадлежать такому же пользователю или группе в которой он состоит (GID). Или дать полный доступ для всех пользователей (chmod 777 nfs-folder), тогда все созданные файлы будут от имени: nobody nogroup\n/nfs-folder 192.168.3.0/24(rw,sync,all_squash,anonuid=1020,anongid=1020) любой пользователь в сети сможет получить полный доступ ко всем файлам расшаренной директории, предварительно нужно создать пользователя с UID 1020 и указать, что бы все подключения считать запросами от анонимного пользователя, а анонимному пользователю присвоить UID 1020. Если у пользователя с id 1020 есть доступ к расшаренной директории на сервере, то при подключении директории на клиентской стороне он будет у пользователя с любым UID. При создании файлов и директорий под другим пользователем, будет указан владелец с номером UID и GID 1020. \nusermod -u 1020 nfs-user изменить UID \ngroupmod -g 1020 nfs-user изменить GID \nid nfs-user проверяем ID\n\nclient\napt install nfs-common установить на клиентском компьютере, что бы работать c файловой системой \nmkdir /mnt/nfs-folder &amp;&amp; mount 192.168.3.104:/nfs-folder/ /mnt/nfs-folder подключить шару и првоерить df -h (192.168.3.104:/nfs-folder  48G  20G  27G  43%  /mnt/nfs-folder) \numount /mnt/nfs-folder отключить \nshowmount -e 192.168.3.104 отобразить список всех доступных ресурсов\n\nftp\napt install vsftpd установка vsFTPd Server (Very Secure File Transfer Protocol Daemon) \nsystemctl status vsftpd \nufw allow 20:21/tcp открыть порты в Firewall \nufw allow 30000:31000/tcp \ncp /etc/vsftpd.conf /etc/vsftpd.conf.bak резервная копия настроек\nnano /etc/vsftpd.conf\n\nsystemctl restart vsftpd \nss -ln | grep -w \"21\" проверить, что 21 порт слушает (LISTEN) \nss -tn | grep -w \"21\" проверить установленные соединения на 21 порту (ESTAB) \ncat /var/log/vsftpd.log лог работы (CONNECT/LOGIN/UPLOAD/DOWNLOAD/RENAME/DELETE)\n\nftp client\nftp 192.168.3.104 доступен только без использования SSL \n230 Login successful вход в систему успешен \nls отобразить все файлы в текущей директории на удаленном компьютере \nget test.json скачать файл на локальный компьютер \nput out.txt загрузить файл на удаленный сервер \nbye закрыть соединение\n\nftps\nsudo openssl req -x509 -nodes -days 365 -newkey rsa:2048 -keyout /etc/ssl/private/vsftpd.key -out /etc/ssl/certs/vsftpd.crt сгенерировать самозаверяющий SSL-сертификат и закрытый ключ\nnano /etc/vsftpd.conf\n\nuseradd -m -s /bin/bash ftpuser пользователь с домашним именным каталогом и оболочкой bash \npasswd ftpuser задать пароль пользователю \necho \"ftpuser\" | tee -a /etc/vsftpd.chroot_list добавить пользователя в список ограниченных домашним каталогом \necho \"ftpuser\" | tee -a /etc/vsftpd.user_list добавить пользователя в список разрешенных для подключения \nmkdir /home/ftpuser/ftp создать домашнию директорию \nchown ftpuser:ftpuser ftp назначить владельца и группу для директории \nchmod 555 ftp ограничить доступ только на чтение и выполнение \nmkdir /home/ftpuser/ftp/upload создать директорию для загруки (с возможностью записи) \nchown ftpuser:ftpuser upload \nchmod 775 upload полный доступ для владельца и группы\n\nrsync\nrsync -options SRC DST\n-a режим архивирования, когда сохраняются все исходные атрибуты оригинальных файлов (дата изменения и создания) \n-b создание резервной копии \n-c проверка контрольных сумм для файлов \n-e использовать другой транспорт (например ssh) \n-h выводит цифры в формате, нормальном для чтения \n-l копировать символьные ссылки \n-L копировать содержимое ссылок \n-p сохранять права для файлов \n-q минимум информации \n-u не перезаписывать более новые файлы \n-v выводить подробную информацию о процессе копирования \n-w выполнить полное копирование без синхронизации \n-z сжимать файлы перед передачей \n--delete удалять остальные файлы у получателя, которых нет в источнике отправителя \n--progress выводить прогресс передачи файла (в %) \n--stat показать статистику передачи\nrsync -zvh /home/lifailon /backup копирование и синхронизация только файлов (skipping directory) указанной директории (в пределах одной локальной машины, например на внешний носитель). При редактировании файлов в исходной папке и повторном копирование заменит все содержимое (без синхронизации).\nnano /etc/rsyncd.conf\n\nchown kup:kup backup сменить владельца и группу директории \nchmod ug+rwx backup выдать им полные права (для удаленного пользователя) \nsystemctl start rsync запустить сервер\nСинхронизация на удаленной машине (192.168.3.103) авторизованным под пользователем, указанным в конфигурации:\nrsync -avzh /backup/ kup@192.168.3.103:/tmp/backup/ скопировать содержимое локальной папки backup (включая директории) на удаленный сервер. По умолчанию Rsync использует транспорт SSH (шифрованный) с запросом пароля (если не используется ключ). \nrsync -avzhe \"ssh -p 2121\" /tmp/backup/ kup@192.168.21.121:/tmp/backup/ если используется нестандартный порт \nrsync -avzh /tmp/backup/ rsync://192.168.21.121:/share явно задать использование транспорта Rsync \nПри редактировании исходных файлов, заменит содержимое только тех файлов, которые были изменены (sending incremental file list ./ test3) \nrsync -avzh kup@192.168.3.103:/tmp/backup /tmp/backup/ скопировать данные с удаленного сервера на локальный компьютер \nssh-keygen -t rsa в случае доступа к серверу по SSH необходимо будет создать ключ и загрузить его на сервер, чтобы аутентификация проходила без запроса пароля \nssh-copy-id -i /home/sk/.ssh/id_rsa.pub kup@192.168.21.10 передать ключ на сервер с которым будет происходить синхронизация \n00 03 * * * rsync -avzhe \"ssh -p 2121\" /tmp/backup/ kup@192.168.21.121:/tmp/backup/ добавить в планировщик, синхронизация каталогов будет выполняться каждый день в 3 часа ночи\n\napache\napt install apache2 \ncat /etc/apache2/apache2.conf \ncat /etc/apache2/ports.conf \nport=8443 \ncat /etc/apache2/ports.conf | sed -r \"s/^Listen.+/Listen $port/\" &gt; /etc/apache2/ports.conf \nsystemctl restart apache2 \nsystemctl status apache2 \nss -lpn | grep apache \necho \"&lt;H1&gt;$(hostname)&lt;/H1&gt;\" &gt; /var/www/html/index.html\n\napi server\nmkdir /var/www/api &amp;&amp; touch /var/www/api/api.sh &amp;&amp; chmod +x /var/www/api/api.sh \ncurl -s \"https://raw.githubusercontent.com/Lifailon/bash-api-server/rsa/www/api/api.sh\" &gt; /var/www/api/api.sh установить пример с шаблоном сервера api\nnano /var/www/api/api.sh\n\na2enmod auth_basic активировать модуль базовой HTTP аутентификации \nhtpasswd -b -c /etc/apache2/.htpasswd rest api настроить htpasswd для хранения пользовательских данных (создать пользователя rest с паролем api)\nnano /etc/apache2/sites-available/api.conf создать VirtualHost для обработки запросов\n\na2enmod cgi активировать модуль (en mod) Common Gateway Interface (CGI) \na2ensite api.conf активировать VirtualHost (en site) \nsystemctl restart apache2 \ntail -f /var/log/apache2/error.log \ntail -f /var/log/apache2/access.log\ncurl -s -X GET http://127.0.0.1:8443/api -u rest:api | jq .result \ncurl -s -X GET http://127.0.0.1:8443/api/info -u rest:api -H \"Content-Type: application/json\" | jq .content[]\nREQUEST_METHOD метод HTTP-запроса (GET, POST, HEAD и т.д.) \nREQUEST_URI оригинальный URI запроса \nQUERY_STRING строка запроса URL \nCONTENT_TYPE тип содержимого запроса в заголовке клиента (например, application/text) \nCONTENT_LENGTH длина тела запроса в байтах (чаще, для POST-запросов) \nread -n $CONTENT_LENGTH POST_DATA прочитать содержимое Body из стандартного ввода (stdin). \nHTTP_STATUS читаем содержимое переданного заголовка (например, “Status: text”), которое определяется заранее и регламентируется в дальнейшем \nHTTP_USER_AGENT название агента клиента из заголовка (например, curl/8.4.0) \nREMOTE_ADDR адрес клиента \nREMOTE_PORT порт клиента \nSERVER_NAME адрес сервера \nSERVER_PORT порт сервера \nSCRIPT_NAME путь и имя CGI-скрипта \nSERVER_SOFTWARE имя и версия сервера \nSERVER_PROTOCOL версия протокола HTTP (например, HTTP/1.1) \nHTTPS если установлено, то запрос был сделан с использованием HTTPS \nAUTH_TYPE тип аутентификации, если он был предоставлен \nREMOTE_USER имя пользователя, если была использована аутентификация \nDOCUMENT_ROOT корневой каталог веб-сервера\n\nstatus\napachectl -M | grep status_module проверить подключенный модуль статистики: status_module (shared) \nnano /etc/apache2/mods-available/status.conf \nRequire ip 192.168.3.0/24 указать для кого доступна статистика \nhttp://127.0.0.1:8443/server-status \napachectl -t проверить синтаксис (Syntax OK) \na2enmod status активировать модуль (Module status already enabled) \nsystemctl restart apache2 \nnetstat -tulpan | grep apache2 проверить порт \ncurl http://127.0.0.1:8443/server-status?auto\n\nwebdav\nnano /etc/apache2/ports.conf\n\nmkdir /var/www/webdav &amp;&amp; chown www-data:www-data /var/www/webdav создать каталог к которому будет доступ через WebDAV и предоставить доступ к нему для www-data\nnano /etc/apache2/sites-available/webdav.conf\n\na2enmod dav \na2enmod dav_fs \na2enmod auth_digest \na2enmod authn_core \na2enmod authn_file \na2enmod authz_core \na2enmod authz_user \nhtpasswd /etc/apache2/.htpasswd admin создать пользователя admin (ключ -с используется для пересоздания файла) \na2ensite webdav активировать конфигурацию сайта \nsystemctl restart apache2\n","path":null},{"url":"https://lifailon.github.io/node-js/","title":"Node.js","description":null,"body":"\n    \n\n\n    Памятка по основам синтаксиса JavaScript для Node.js в примерах.\n\n\n\nПеременные\nПеременная var поддерживает любую область видимости и ее возможно объявить повторно (считается устаревшим методом и рекомендуется не использовать).\n\nПеременная let позволяет изменять содержимое с другим типом данных (в отличии от const), но ограничина областью видимости (в отличии от var).\n\nПеременная константа const требует обязательной инициализации во время объявления, и не позволяет изменять значение переменной после ее объявления.\n\n\nТипы данных\n\nПреобразовать аргумент в число. Возвращает NaN, если преобразование невозможно.\n\nПреобразовать строку в целое число. Прекращает чтение, как только встречает нецифровой символ.\n\nПреобразовать строку в число с плавающей точкой.\n\nПреобразовать значение в строку.\n\nПреобразовать значение в булевое (логическое) значение. Все значения, кроме 0, null, NaN, undefined и пустой строки, преобразуются в true.\n\n\nФункции\n\n\nУсловия\n\nОднострочный формат условия ?:, который подходит для использования в теле переменной\n\nПроверить одно значение сразу на большое количество условий с помощью конструкции switch\n\n\nОбработка ошибок\n\n\nМассивы\nКлассический массив и его методы.\n\nВложенный массив, а также методы фильтрации и объединения:\n\n\nОбъекты\nПреобразовать объект в массив и наоборот:\n\nОбъект представляет из себя список пар (ключ-значение), разделенного запятыми. Используя переменную const при объявлении объектов, возможно изменять содержимое дочерних элементов.\n\nОбъекты и вложенные массивы JavaScript могут содержать дочерние массивы внутри [] и вложенные объекты внутри {}.\n\nКонвертация в JSON:\n\nМетоды объекта назначаются через функции\n\nОператор return используется для выхода из функции (т.е. последующий код не читается), который возвращает значение указанное после ключевого слова.\n\nЦиклы\nПримеры циклов взяты из проекта multranslate, для проверки всех строк в массиве и увеличения количества видимых строк с учетом autowrap. Имеется две реальных строки, необходимо узнать количество виртуальных строк с учетом длинны символов в строке. Например, если максимальная длинна одной строки составляет, 36, то на одну реальную строку в 92 символа приходится дополнительно еще 2 виртуальных. Количество найденных виртуальных строк прибавляется к изначально зафиксированному значению количества всех реальных строк.\n\nКлассический цикл for итерирует числами с типом данных number (int / integer). С каждой интерацией объявленное значение (let i = 0) увеличивается на заданное количество (i++ - на единицу), цикл завершается в случае успешного соблюдения условия (i &lt; bufferLine.length).\n\nЦикл for..in итерирует по индексам массива, с типом данных string. Сколько элементов в массиве (bufferLine.length), столько и будет индексов (отсчет начинается с нуля).\n\nЦикл for..of итерирует по элементам массива, с уникальным типом данных каждого элемента в массиве.\n\nМетод массива forEach выполняет указанную функцию для каждого элемента в массиве.\n\nЦикл while Выполняет тело цикла {} до тех пор, пока условие истинно\n\nЦикл do..while сначала выполняет тело цикла, а затем проверяет условие, это гарантирует, что интерация будет выполнена как минимум один раз.\n\nОператоры:\n\ncontinue - прерывает текущую интерацию, для продолжения цикла с следующим значением\nbreak - прерывает и завершает цикл\n\n\n\nАсинхронные операции\nPromise (промис) — это объект, который используется для обработки асинхронных операций, позволяя работать с результатами, когда они станут доступны, не блокируя основной поток выполнения. Он может находиться в одном из трех состояний:\n\nPending (Ожидание): Операция только отправлена на выполнение или еще выполняется.\nFulfilled (Выполнен): Операция завершилась успешно.\nRejected (Отклонен): Операция завершилась с ошибкой.\n\nС помощью ключевых слов resolve (разрешить/успех) и reject (отклонить/ошибка) производится управление возвращаемым результатом выполнения.\n\nМетод then используется для обработки успешного выполнения промиса (в состоянии fulfilled).\nМетод catch используется для обработки ошибок или отказов промиса (в состоянии rejected).\nasync — это ключевое слово, которое делает функцию асинхронной и позволяет использовать await, чтобы приостановить выполнение до тех пор, пока все промисы не будут выполнены.\nawait — это ключевое слово, которое используется внутри асинхронной функции (async). Оно заставляет ждать выполнения промиса и возвращает его результат.\n\nИспользовать внешнюю библиотеку ping: npm install ping\n\nawait Promise.all() - дожидается успешного выполнения всех запросов.\nawait Promise.allSettled() - дожидается выполнения всех запросов не зависимо от успеха (возвращает статус и результат).\nawait Promise.race() - дожидается первого успешного выполнения, что бы получить результат от него не зависимо от его успеха.\n\nРегулярные выражения\nПреобразовать строку в массив из букв (char).\n\nМетод split() используется для преобразования строки в массив.\n\nМетод join() используется для объединение массива в строку.\n\nМетод match() используется для поиска совпадений с регулярным выражением в строке. Он возвращает массив с найденными совпадениями или null, если совпадений не найдено.\n\nМетод search() возвращает только индекс первого совпадения.\n\nМетод replace() заменяет найденные совпадения в строке на другие значения.\n\n\nМатематические вычисления\n\n\nExpress\nСоздаем директорию, инициализируем проект и устанавливаем зависимости\n\nСерверная часть API сервера в файле server.js\n\nЗапуск сервера\n\n\nAxios\nКлиентская часть для работы с API\n\nПример GET запроса\n\nПример POST запроса\n\n\nFetch\n\n\nCheerio\nCheerio - это библиотека для работы с HTML и XML в Node.js\n\nПодключаем библиотеки и получаем содержимое страницы с помощью Axios через Proxy\n\nВытаскиваем данные с помощью Cheerio\n\n\nPuppeteer\nPuppeteer — это библиотека, которая предоставляет API для автоматизации любых действий в браузерах Google Chrome и Mozilla Firefox через протокол Chrome DevTools и WebDriver BiDi.\n\nПример получения списка файлов раздачи с сайта RuTor.\n\nПример создания API для получения результатов проверки скорости интернета в формате JSON через Ookla SpeedTest.\n\n","path":null},{"url":"https://lifailon.github.io/compose/","title":"Compose Stacks","description":null,"body":"\n    \n\n\n    Коллекция стеков Docker Compose из более чем 300 сервисов. Каждое приложение было отлажено и проверено в домашней лаборатории, конфигурации к некоторым сервисам доступны в исходном репозитории.\n\n\n\nBot Stack\n\nSSH Bot\nSSH Bot - Telegram бот, который позволяет запускать заданные команды на выбранном хосте в домашней сети и возвращать результат их выполнения. Бот не устанавливает постоянное соединение с удаленным хостом, что позволяет выполнять команды асинхронно.\n\nenv:\n\n\nOpenRouter Bot\nOpenRouter Bot - Telegram бота для общения с бесплатными и платными моделями ИИ через OpenRouter, или локальными LLM, например, через LM Studio.\n\nenv:\n\n\nKinozal Bot\nKinozal Bot - Telegram бот, который позволяет автоматизировать процесс доставки контента до вашего телевизора, используя только телефон. С помощью бота вы получите удобный и привычный интерфейс для взаимодействия с торрент трекером Кинозал и базой данных TMDB для отслеживания даты выхода серий, сезонов и поиска актеров для каждой серии, а также возможность управлять торрент клиентом qBittorrent или Transmission на вашем компьютере, находясь удаленно от дома, а главное, все это доступно из единого интерфейса и без установки клиентского приложения на конечные устройства. В отличии от других приложений, предназначенных для удаленного управления торрент клиентами, вам не нужно находиться в той же локальной сети или использовать VPN.\nKinozal News Channel - новостной канала на базе бота, который генерирует посты на основе новых публикаций в торрент трекере Кинозал (современная альтернатива RSS). Каждый пост содержит краткую информацию о раздаче (год выхода, страна производства, рейтинг, качество и перевод), а также #хештеги по жанру для фильтрации контента на канале и кнопки с ссылками описания фильма или сериала, бесплатный онлайн просмотр через плееры ▶️ Kinobox и 🧲 магнитные ссылки для прямой загрузки содержимого раздачи в торрент клиенте по умолчанию.\n\n\nyt-dlp Telegram Bot\nyt-dlp Telegram Bot - Telegram бот для загрузки видео из YouTube с помощью yt-dlp (like Gozilla Bot).\n\nenv:\n\n\nyt-dlp Telegram\nyt-dlp Telegram - еще один Telegram бот для загрузки видео из YouTube с ограничением 50 МБ.\n🔗 Telegram Bot Demo ↗\n\nconfig:\n\n\nRSS to Telegram Bot\nRSS to Telegram Bot - мониторит указанные RSS-ленты, добавленные через интерфейс Telegram и отправляет ссылки при обнаружение новых новостей.\n🔗 Telegram Bot Demo ↗\n\n\nFree Games Claimer Bot\nFree Games Claimer Bot - Автоматически получает список бесплатных игр и DLC в Telegram из Epic Games Store, Amazon Prime Gaming и GOG.\n\n\nTelegram Bot API\nTelegram Bot API - полнофункциональный сервер-заглушка Telegram Bot API, который может использоваться для отладки при создание ботов Telegram.\n\n\nTelegram Media Downloader\nTelegram Media Downloader - приложение для массовой загрузки медиафайлов из Telegram чатов и каналов, включая аудио, документы, фото и видео.\n\n\nPentaract\nPentaract - система облачного хранения данных, использующая Telegram в качестве хранилища, не используя файловую систему локального сервера или стороннего облачного хранилища.\n\n\nLLM Stack\n\nOpen WebUI\nOpen WebUI - платформа для самостоятельного размещения AI (веб-интерфейс для LLM), предназначенная для работы в полностью автономном режиме. Она поддерживает различные среды выполнения LLM, такие как Ollama и совместимые с OpenAI API.\n\nenv:\n\n\nNextChat\nNextChat (ранее ChatGPT-Next-Web) - веб-интерфейс для ChatGPT, Gemini и других AI совместимсых с OpenAI API.\n\nenv:\n\n\nContinue\nContinue - интеграция AI-агентов для выполнения рефакторинга во время написания кода в IDE.\n🔗 Continue VSCode Extension ↗\n\n\nAPI Stack\n\nScalar\nScalar - интерактивный справочник для документации OpenAPI (like Swagger UI) и REST API клиент в одном веб-приложение.\n🔗 API Reference Demo ↗\n🔗 API Client Demo ↗\n\n\nRestfox\nRestfox - легковесный и быстрый офлайн API-клиент (WebUI/Desktop) с поддержкой импорт коллекций из OpenAPI и экспорт в Postman и Insomnia.\n🔗 Restfox API Client Demo ↗\n🔗 Restfox Desktop Client ↗\n\n\nYaade\nYaade — это среда совместной разработки API, размещаемая на собственном сервере (еще один API клиент с веб-интерфейсом).\n\n🔗 Hoppscotch API Client Demo ↗\n🔗 HTTPie API Client Demo ↗\n🔗 Postman Collections to OpenAPI Docs ↗\n\nHTTPBin\ngo-httpbin - API сервер клиент для тестирования HTTP запросов и ответов (fork httpbin от Postman Labs).\n🔗 HTTPBin Demo ↗\n🔗 HTTPBin Go Demo ↗\n\n\nSwagger UI\nSwagger UI - браузер для спецификации OpenAPI (поддерживает загрузку любой переданной спецификации через url).\n🔗 Swagger UI Demo ↗\n🔗 Swagger Viewer VSCode Extension ↗\n\n\nSwagger Editor\nSwagger Editor - онлайн редактор документации OpenAPI с поддержкой генерации клентов и заглушек API для разных языков с помощью codegen.\n🔗 Swagger Editor Demo ↗\n\n\nMitm Proxy\nMitm Proxy - прямой (forward) прокси сервер для перехвата и изменения HTTP-трафика с веб-интерфейсом для анализа запросов и ответов (like Fiddler), удобно для отладки мобильных приложений.\n\n\nStep CI\nStep CI - инструмент командной строки для тестирования GraphQL, gRPC, SOAP и REST API в DevOps Pipelines (например, локально в консоли или в GitHub Actions)\n🔗 Step CI Demo ↗\n\n\nNetwork Stack\n\nNetworking Toolbox\nNetworking Toolbox - более 100 сетевых инструментов и утилит, предназначенных для работы в автономном режиме (от создателя web-check, dashy и AdGuardian-Term).\n🔗 Networking Toolbox Demo ↗\n\n\nWeb Check\nWeb Check - универсальный инструмент OSINT для анализа любого веб-сайта.\n🔗 Web Check Demo ↗\n\n\nIP Check\nIP Check / MyIP - набор инструментов для проверки IP-адресов. Включаем в себя проверки DNS, соединения WebRTC, speedtest, ICMP, MTR, доступность веб-сайтов и другие возможности.\n🔗 IP Check Demo ↗\n\n\nZoneMaster\nZoneMaster - веб-интерфейс, API и инструмент командной строки для проверки DNS.\ndocker run -t --rm zonemaster/cli zonemaster.net\n🔗 ZoneMaster Test Domains Demo ↗\nCheck Host - бесплатный онлайн инструмент и API для ICMP, HTTP/HTTPS, TCP, UDP и DNS проверок доступности узлов из разных стран.\nLooking.House - инструмент для проверки скорости загрузки и выгрузки (а также проверок ping, traceroute и mtr) из множества точек Looking Glass, расположенных в ДЦ по всему миру.\n\nPinguem\nPinguem - веб-интерфейс и экспортер Prometheus для асинхронной проверки доступности выбранных хостов или подсетей с использованием библиотеки node-ping.\n\n\nSmokePing\nSmokePing - система регистрации, построения графиков и оповещения о задержках, которая состоит из демона для организации измерения задержек и CGI-интерфейса для отображения графиков.\n🔗 SmokePing Demo ↗\n\n\nNtopng\nNtopng — форк оригинального ntop (написанного в 1998 году), с улучшенной производительностью, новыми функциями и веб-интерфейсом для анализа и мониторинга сетевого трафика. Поддерживает отображение графиков использования пропускной способности, анализ pcap файлов, списки активных подключений (like netstat или ss) и другую информацию.\n\n\nNetAlertX\nNetAlertX - сканер присутствия (форк Pi.Alert для Docker) и обнаружения в локальной или WiFi сети с отправкой уведомлений (например, в Telegram через Apprise).\n\n\nIVRE\nIVRE (Instrument de veille sur les réseaux extérieurs) - платформа сетевой разведки, включающая инструменты для пассивной и активной разведки (например, Nmap и Masscan).\n\n\nWebMan\nWebMan - веб-интерфейс для XML отчетов nmap.\n\n\nRTSP to Web\nRTSP to Web - RTSP клиент в браузере.\n\n\nGotify\nGotify - легковесный сервер для отправки и получения push-уведомлений в режиме реального времени, работающий через Веб-сокеты, который позволяет развернуть собственный сервис уведомлений, получая сообщения через API на мобильные приложения или в Веб-интерфейс. Поддерживает отправку сообщений через REST-API, Swagger документацию, управление пользователями и приложениями через WebUI и собственное Android приложение.\n\n\nApprise\nApprise - система для отправки уведомления более чем в 100+ служб, с поддержкой веб интерфейса для настройки конфигураций (используется в NetAlertX для отправки уведомлений в Telegram).\n\n\nAlerta\nAlerta - инструмент, который озволяет с помощью одной системы отслеживать оповещения из множества других инструментов мониторинга на одном экране.\n\n\nLibreSpeedTest\nLibreSpeedTest - сервер измерения скорости сети в Интернете на базе HTML5 для размещения на собственном сервере, с поддержкой мобильных устройств.\n🔗 LibreSpeedTest Demo ↗\n\n\nOpenSpeedTest\nOpenSpeedTest - бесплатный веб-инструмент для оценки производительности сети на базе HTML5, написанный на чистом JavaScript и использующий только встроенные веб-API.\n🔗 OpenSpeedTest Demo ↗\n\n\nSpeedTest Tracker\nSpeedTest Tracker - веб-приложение для отслеживания производительности и времени безотказной работы Интернет-соединения с собственным веб-интерфейсом для визуализации графиков измерений, а а также интеграция с Homapage.\n\n\nMySpeed\nMySpeed - веб-приложение от создателя Nexterm для автоматизации тестирования скорости Интернет-канала связи. Поддерживает сервера проверки скорости Ookla SpeedTest, LibreSpeed ​​и Cloudflare SpeedTest, настройку времени между тестами с помощью выражений Cron, отправку оповещений в Telegram, хранение результатов до 30 дней, а также метрики Prometheus и виджет для Homapage.\n\n\nSpeedTest Exporter\nSpeedTest Exporter - экспортер Prometheus, написанный на Python с использованием официального интерфейса командной строки Ookla Speedtest.\n🔗 Grafana Dashboard ↗\n\n\niperf\niperf - утилита командной строки (клиент-серверная архитектура) для проверки скорости загрузки и выгрузки в локальной сети.\n\n\nfail2ban\nfail2ban - демон для блокировки хостов, вызывающих множественные ошибки аутентификации по ssh и веб-приложения, используя анализ логов.\n\n\nTemp Mail\n🔗 Temp Mail UI ↗\n🔗 Temp Mail UI Demo ↗\n🔗 Temp Fast Mail ↗\n🔗 Temp Fast Mail Demo ↗\n\nSMTP Stack\n\nSMTP to Telegram\nSMTP to Telegram - SMTP сервер (листенер) для переадресации сообщений в Telegram.\n\n\nDocker MailServer\nDocker MailServer - простой и готовый к продакшену контейнеризированный почтовый сервер в стеке из SMTP, IMAP, LDAP, анти-спам системы и антивируса. Настраивается с помощью одного конфигурационного файл, не требует SQL базы данных.\n\n\nMailPit\nMailPit - SMTP-сервер для тестирования электронной почты, основанный на MailHog (который больше не поддерживается), с поддержкой веб-интерфейса (SMTP-клиент) для просмотра получаемх писем, а также API для автоматизированного тестирования и интеграции.\n🔗 MailPit API Docs ↗\n\n\nMailDev\nMailDev - SMTP-сервер и веб-интерфейс для просмотра и тестирования почты во время разработки (например, используется для проверки содержимого письма при отправки оповещений, сброса пароля и т.п.).\n\n\nHappy Deliver\nHappy Deliver - инструмент для тестирования доставки электронных писем, с анализом писем и оценкой SPF, DKIM, DMARC, BIMI, ARC, SpamAssassin, записи DNS, статус черного списка, качество контента и многое другое. Поддерживает полнофункциональный REST API для создания тестов и получения отчетов, встроенный сервер LMTP для бесшовной интеграции MTA и присвоения оценок (от A до F).\n🔗 Happy Deliver Demo ↗\n\n\nDevelopment Stack\n\nIT Tools\nIT Tools - большая коллекция утилит для разработчиков (криптография, конверторы, веб инструменты и многое другое).\n🔗 IT Tools Demo ↗\n\n\nCyberChef\nCyberChef - веб-приложение для выполнения всевозможных кибер-операций в веб-браузере, которые включают в себя простое кодирование (например, XOR и Base64), более сложное шифрование (например, AES, DES и Blowfish), создание двоичных и шестнадцатеричных дампов, сжатие и распаковка данных, вычисление хешей и контрольных сумм, парсинг IPv6 и X.509, изменение кодировок символов и многое другое.\n🔗 CyberChef Demo ↗\n\n\nTransform\nTransforms - универсальный веб-конвертер.\n🔗 Transforms Demo ↗\n\n\nMazanoke\nMazanoke - веб-приложение для сжатия (в процентах или мб), изменения разрешения (в пикселях) и конвертации изображений.\n🔗 Mazanoke Demo ↗\n\n\nJSON Crack\nJSON Crack - веб-приложение для визуализации JSON, YAML, XML и CSV в интерактивные графики.\n🔗 JSON Crack Demo ↗\n🔗 JSON Crack VSCode Extension  ↗\n\n\nMarkmap\nMarkmap - как JSON Crack для Markdown.\n🔗 Markmap Demo ↗\n🔗 Markmap VSCode Extension  ↗\n\nTermix\nTermix - платформа для управления серверами с веб-интерфейсом. Поддерживает SSH-терминал с разделением экрана, управление SSH-туннелями, удалённый редактор файлов с подсветкой синтаксиса и мониторинг ресурсов сервера.\n\n\nkkTerminal\nkkTerminal - веб-терминал для SSH-подключений с доступом к файлам и базовым мониторингом.\n\n\nNexTerm\nNexTerm - управление сервером в браузере с поддержкой 2FA для SSH (с поддержкой файлового браузера через SFTP), VNC и RDP, контейнерами Proxmox LXC, QEMU и развертывание приложений через Docker.\n\n\nLicenseAPI\nLicenseAPI - размещенная на собственном сервере система лицензирования для программного обеспечения от создателя Nexterm и MySpeed. Поддерживает графический интерфейс управления, систему разрешений, назначение метаданных лицензиям, проверка лицензий в автономном режиме и интеграцию с использованием REST API или SDK.\n\n\nCode Server\nCode Server - VSCode сервер в браузере.\n🔗 VSCode Demo ↗\n\n\nJudge0\nJudge0 IDE - онлайн-редактор кода, позволяющий писать и выполнять код (использует Judge0 под капотом, для выполнения исходного кода) на широком спектре языков. Подходит для тех, кто хочет быстро внести правки и запустить код или изучаения нового языка, не открывая полнофункциональную IDE на своем компьютере.\n🔗 Judge0 IDE Demo ↗\n\n\nGo Playground\nBetter Go Playground - улучшенная Go Playground на базе Monaco Editor и React.\n🔗 Go Playground Demo ↗\n\n\nGo Template Playground\nRepeatit (Go Template Playground) - игровая площадка для проверки шаблонов GoLang. Поддерживает рендиринг текста и html шаблонов, функции spting и heml, а также ввод параметров шаблона в форматах yaml, json и toml.\n🔗 Go Template Playground Demo ↗\n🔗 Helm Playground Demo ↗\n🔗 Jinja2 Playground Demo ↗\n\n\nD2 Playground\nD2 Playground - игровая площадка для современного языка сценариев диаграмм, преобразующий текст в диаграммы.\n🔗 D2 Playground Demo ↗\n🔗 D2 VSCode Extension ↗\n\n\nDrawIO\nDraw.io (like MS Visio) - веб-версия бесплатного приложения для создания различных диаграмм, блок-схем и т.п.\n🔗 Draw.io Demo ↗\n🔗 Draw.io VSCode Extension ↗\n\n\nDatabase Stack\n\nTools\n\n\nOuterbase Studio SQLite Playground - веб-интерфейс для управления базами данных.\n\n\nDBeaver  - кросплатформенный и универсальный SQL-клиент и инструмент для работы с базами данных.\n\n\nBeekeeper Studio - современный и простой в использовании SQL-клиент для MySQL, Postgres, SQLite, SQL Server и других баз данных для систем Linux, MacOS и Windows.\n\n\nHeidiSQL - легковесный графический интерфейс для управления MySQL/MariaDB, SQL Server, PostgreSQL, SQLite, Interbase и Firebird для системы Windows.\n\n\nRainFrog - TUI для управления Postgres, MySQL, SQLite, DuckDB и Oracle.\n\n\nDBLab - TUI клиент для PostgreSQL, MySQL, SQLite3, Oracle и SQL Server.\n\n\nLazySQL - кроссплатформенный инструмент управления базами данных с помощью TUI.\n\n\nDolphie - TUI панель для аналитики MySQL/MariaDB и ProxySQL в реальном времени.\n\n\nusql - универсальный интерфейс командной строки для PostgreSQL, MySQL, Oracle Database, SQLite3, Microsoft SQL Server и многих других баз данных, включая NoSQL и нереляционные базы данных.\n\n\nsq - инструмент командной строки, обеспечивающий доступ в стиле jq из баз данных, а также CSV или Excel.\n\n\n\nDBGate\nDBGate - менеджер баз данных для MySQL, PostgreSQL, SQL Server, MongoDB, SQLite и других. Работает под управлением Windows, Linux, Mac или как веб-приложение.\n\n\nRedis Insight\nRedis Insight - официальный веб-интерфейс для управления Redis.\n\n\nlibSQL\nlibSQL - форк SQLite, разработанный Turso для удаленного доступа к SQLite, аналогичный PostgreSQL или MySQL с встроенной поддержкой репликации данных.\n\n\nPostgreSQL\nPostgreSQL - объектно-реляционная база данных (СУБД) с открытым исходным кодом.\n\n\nPgWeb\nPgWeb - веб-клиент для работы с СУБД PostgreSQL, который возможно запустить из одного бинарного файла, а также позволяет подключиться к БД напрямую или через SSH туннель.\n\n\npgHero\npgHero - Панель управления для производительности PostgreSQL.\n🔗 pgHero Performance Dashboard Demo ↗\n\n\nPostgreSUS\nPostgreSUS - инструмент для резервного копирования, с поддержкой локального хранение бекапов, а также в Google Drive или S3 совместимом хранилища по расписанию с проверкой доступности (health check), визуализации в веб-интерфейсе и оповщениями в Telegram, Slack, Discord и другие системы.\n\n\nPG Backup\nDocker PG Backup - контейнер для резервного копирования любой совместимой с PostgreSQL базы данных (например, PostGIS) по расписанию cron.\n\n\nPostgREST\nPostgREST - полноценный RESTful API для управления базами данных PostgreSQL.\n\n\npREST\npREST - простой и готовый к использованию API, который обеспечивает работающее в реальном времени и высокопроизводительное приложение поверх существующей или новой базы данных Postgres.\n\n\nPatroni\nPatroni - шаблон для обеспечения высокой доступности (HA) серверов баз данных PostgreSQL с помощью etcd, HashiCorp/Consul, Apache/ZooKeeper или Kubernetes.\n\n\nIvory\nIvory - инструмент для визуализации работы с кластерами Postgres, который представляет из себя веб-интерфейс управления кластером Patroni и конструктор запросов Postgres.\n\n\nKafka\nApache Kafka - распределенная потоковая платформа с открытым исходным кодом, которая позволяет приложениям публиковать, подписываться, хранить и обрабатывать потоки данных. Для работы требует JVM и Zookeeper для координации распределенных систем, обеспечения их согласованности и отказоустойчивости.\n\n\nKafbat\nKafbat/Kafka UI - веб-интерфейс для мониторинга и управления кластерами Apache Kafka.\n\n\nKafka UI\nKafka UI - веб-интерфейс для управления Apache Kafka.\n\n\nBackup Stack\n\nRestic\nRestic — это быстрая, эффективная и безопасная программа для резервного копирования, которая поддерживает хранение резервных копий на S3, SFTP, REST Server, Rclone как backend и других хранилищах.\n\nREST Server\nREST Server - HTTP-сервер, реализующий REST API бэкэнда для Restic, который предоставляет безопасный и эффективный способ удалённого резервного копирования данных с помощью клиента резервного копирования restic по адресу rest: URL.\n\n\nZerobyte\nZerobyte - инструмент автоматизации резервного копирования для хранения данных в нескольких хранилищах. Он создан на основе Restic и предоставляет современный веб-интерфейс для планирования, управления и мониторинга зашифрованного резервного копирования удаленного хранилища. Поддерживает источники данных (volumes) из локального хранилища, NFS, SMB и WebDAV, хранилища данных (repositories) в S3, SSH/SFTP, rcloud (40+ cloud providers) и отправку уведомлений в Telegram, Discord, Slack, Pushover, Gotify, а также по SMTP или через Shoutrrr.\n\n\nBackrest\nBackrest — это веб-интерфейс для резервного копирования, построенное на основе Restic.\n\n\nDuplicati\nDuplicati - клиент резервного копирования, который безопасно хранит зашифрованные, инкрементальные и сжатые резервные копии в облачных хранилищах и на удаленных файловых серверах (поддерживает SFTP, WebDAV, S3-совместимые, Google Cloud и другие системы хранения). Поддерживает плагины, например, отправку оповещений в Telegram.\n\n\nKopia\nKopia - кроссплатформенный инструмент резервного копирования для Windows, macOS и Linux с быстрым инкрементным резервным копированием, сквозным шифрованием на стороне клиента, сжатием и дедупликацией данных. Поддерживается Веб-интерфейс поверх cli в стиле отображения флагов для исполняемого файла.\n\n\nProxmox Backup Server\nPBS (Proxmox Backup Server) - неофициальная сборка Proxmox Backup Server для запуска в контейнере на разных платформах.\n\n\nFS Stack\n\nSamba\nSamba - SMB/CIFS сервер для запуска в контейнере Docker, без конфигурации и с поддержкой корзины по умолчанию (директория .deleted в корне шары).\n\n\nSFTPGo\nSFTPGo - SFTP, HTTP/S, FTP/S и WebDAV сервер, с поддержкой хранилища в локальной файловой системе, объектно-совместимом S3 хранилище, Google Cloud Storage, Azure Blob Storage или других SFTP-серверах.\n\n\nSyncthing\nSyncthing - программа для непрерывной синхронизации файлов между двумя или более компьютерами. Работает на основе Block Exchange Protocol (BEP) для обмена данными, который использует TLS-шифрование для безопасной передачи данных по протоколу TCP.\n\n\nh5ai\nh5ai - современный интерфейс веб-сервера для файлового индексера. Визуально напоминается FTP сервер для удобного отображения и загрузки (например, его использует Libretro/RetroArch для публикации релизов).\n\n\nFileBrowser\nFileBrowser - веб-интерфейс для управления файлами в указанном каталоге. Поддерживает управление пользователями, загрузку, удаление, просмотр и редактирование файлов.\n\n\nTiny File Manager\nTiny File Manager - универсальный веб-файловый PHP-менеджер, который позволяет хранить, загружать, редактировать и управлять файлами и папками прямо через веб-браузер.\n🔗 Tiny File Manager Demo ↗\n\n\nDuFS\nDuFS - уникальный служебный файловый сервер, который поддерживает статическое обслуживание, загрузку, поиск и удаленное управление через API.\n\n\nGoSHS\nGoSHS - простая замена SimpleHTTPServer из Python, написанная на Go, которая позволяет загружать и скачивать файлы по HTTP/S с использованием сертификатов и базовой HTTP-аутентификации.\n\n\nS3 Stack\n\nMinIO\nMinIO - высокопроизводительное, совместимое S3 решение для хранения объектов с встроенной системой высокой доступности (например, используется в Velero для хранения данных резервного копирования Kubernetes).\n\n\ns3fs\ns3fs - инструмент для монтирования S3 совместимого хранилища на базе FUSE, позволяя управлять файлами и каталогами в локальной файловой системе.\n\n\nCloud Stack\n\nNextCloud\nNextCloud - кросплатфоренная и self-hosted облачная система хранения (fork ownCloud от 2016 года) с возможностью расширения за счет плагинов (поддерживает ВКС на базе Talk, Kanban на базе Deck и ряд других возможностей).\n\npostgres_password:\n\n\nownCloud\nownCloud - прародитель NextCloud, основанный в 2010 году.\n\nenv:\n\n\nlocalstack\nLocal Stack - эмулятор облачных сервисов, работающий в одном контейнере на ноутбуке или в среде CI. Позволяет запускать свои приложения AWS (Amazon Web Services, например, S3 хранилище, CloudWatch Log Events или Lambda-функции) полностью на локальном компьютере, не подключаясь к удаленному облачному провайдеру.\n\n\nDNS Stack\n\nTechnitium DNS Server\nTechnitium DNS Server - авторитетный, рекурсивный и кэширующий DNS-сервер, который можно использовать для самостоятельного хостинга DNS. Поддерживает кластеризацию (в 14 релизе от 08.11.2025), записи в формате wildcard для субдоменов, черные списки с автоматически обновлением из файлов и url (с поддержкой regex), браузер для управления кешем, API, встроенный DNS-клиент, магазин приложение и многое другое.\n\n\nDNS Client\nDNS Client - веб-клиент, уже встроенный в DNS сервер, который позволяет отправлять запросы к любому DNS-серверу. Поддерживает проверку DNSSEC с использованием алгоритмов RSA, ECDSA и EdDSA для всех транспортных протоколов DNS, а также поддерживает протоколы DNS-over-HTTPS, DNS-over-TLS и DNS-over-QUIC.\n🔗 DNS Client Demo ↗\n\n\nPi-hole\nPi-hole - популярное и легковесное решение для блокировки рекламы (отображает график блокировок, автоматически обновляет списки и поддерживает простое API).\nPi-hole Exporter - экспортер метрик для Prometheus.\n\n\nAdGuard Home\nAdGuard Home - более современный блокировщик рекламы и отслеживания.\nAdGuard Home Sync - синхронизирует конфигурацию AdGuardHome (DNS записи, клиенты, фильтры и общие настройки) с экземплярами реплик.\n\nAdGuardian-Term - TUI интерфейс для управления AdGuard.\ndocker run -it lissy93/adguardian\n\nCoreDNS\nCoreDNS сервер с встроенным плагином blocklist.\n\n\nPowerDNS\nPowerDNS/PDNS - DNS сервер.\nPowerDNS-Admin - веб-интерфейс для PowerDNS с расширенными функциями. Поддерживает управление прямыми и обратными зонами, контроль доступа в определенной зоне, управление пользователями (а также LDAP, OAuth и 2FA), ведение журнала активности, конфигурация службы PDNS и мониторинг статистики, предоставляет API для управления зонами и записями, а также другие функции.\n\n\nBlocky\nBlocky - быстрый и легкий DNS-прокси как блокировщик рекламы для локальной сети с множеством функций, поддерживает управление через встроенный RapiDoc.\n\n\nGravity\nGravity - легковесное решение DNS, DHCP и TFTP сервера, использующее etcd для полной репликации, подходящее для малых и средних сетей. Поддерживает встроенную кластеризацию (HA), кеширование DNS, блокировку рекламы и метрики Prometheus, а также современный интерфейс с графиками.\n\n\nGoAway\nGoAway - легкий DNS-сервер, с блокировкой рекрамы и современным интерфейсом панели управления (like Pi-hole).\n\n\nACME DNS\nACME DNS - DNS-сервер с RESTful HTTP API, предоставляющий простой способ автоматизации запросов DNS ACME.\n\nProxy Stack\n\nTraefik\nTraefik - обратный прокси сервер с поддержкой автоматического опредиления сервисов Docker, встроенным веб интерфейсом, метриками Prometheus и трассировкой OTLP.\n\n\nNginx Proxy &amp; Docker Gen\nNginx Proxy - настраивает контейнер, работающий под управлением nginx и docker-gen (docker-gen генерирует конфигурации обратного прокси-сервера для nginx и перезагружает nginx при запуске и остановке контейнеров).\nDocker Gen - генератор файлов, который визуализирует шаблоны с использованием метаданных контейнера Docker.\nACME Companion - используется для автоматической генерации сертификатов letsencrypt, для хостов, использующих переменную LETSENCRYPT_HOST.\nNginx Exporter - экспортер метрик для Prometheus.\n\n\nNginx Proxy Manager\nNginx Proxy Manager - веб-интерфейс для управления Nginx сервером в роли Proxy сервера.\n\n\nHAProxy\nHAProxy - обратный прокси сервер и “умный” балансировщик нагрузки (поддерживает healthcheck для проверки доступности).\n\n\nGoDoxy\nGoDoxy - обратный прокси-сервер для контейнеров Docker или Podman с веб-интерфейсов и агентами для быстрого доступа к веб-интерфейсам сервисов, управления контейнерами и конфигурациями прокси сервера, мониторинга доступности и ресурсов серверов и контейнеров.\n🔗 GoDoxy Demo ↗\n\nenv:\n\n\nPromxy\nPromxy — это прокси-сервер Prometheus, который позволяет пользователю видеть множество сегментов Prometheus как единую конечную точку API.\n\n\nPangolin\nPangolin — это обратный прокси-сервер с туннелированием, размещаемый на собственном сервере, с контролем доступа на основе личности и контекста, разработанный для легкого раскрытия и защиты приложений, работающих где угодно. Pangolin выступает в роли центрального узла и соединяет изолированные сети, даже находящиеся за строгими брандмауэрами, через зашифрованные туннели, обеспечивая легкий доступ к удаленным сервисам без открытия портов и использования VPN.\n\n\nTiny Proxy\ntinyproxy — легковесный прямой (forward) HTTP/HTTPS-прокси-сервер.\n\n\nProxyfor\nProxyfor - прямой (forward) и обратный прокси сервер с TUI и Веб-интерфейсом от создателя dufs для отображения и фильтрации запросов и ответов.\n\n\nFroxy\nFroxy - кроссплатформенная утилита командной строки для реализации SOCKS, HTTP и обратного прокси сервера на базе .NET. Поддерживается протокол SOCKS5 для туннелирования TCP трафика и HTTP протокол для прямого (классического) проксирования любого HTTPS трафика (CONNECT запросы), а также TCP, UDP и HTTP/HTTPS протоколы для обратоного проксирования. Для переадресации веб-траффика через обратный прокси поддерживаются GET и POST запросы с передачей заголовков и тела запроса от клиента, что позволяет использовать API запросы и проходить авторизацию на сайтах (передача cookie).\n\n\nNoDPI\nNoDPI - утилита для обхода DPI (Deep Packet Inspection).\n\n\nVRRP\n\nKeepAlived\nKeepAlived - используется для обеспечения высокой доступности (HA) за счет протокола VRRP (Virtual Router Redundancy Protocol), который поднимает один виртуальный IP-адрес для нескольких хостов с проверкой доступности и переключением адреса на другой хост в случае провального healthcheck. Чаще всего используется для отказоустойчивости балансировщиков нагрузки.\nОбраза контейнера на базе легковесного Alpine с использованием команд для установки и запуска keepalived.\n\n\nSSO\n\nAuthentik\nAuthentik - IDP (поставщик идентификации) и SSO (единая точка входа), который построен с безопасностью в центре каждого фрагмента кода, каждой функции, с акцентом на гибкость и универсальность.\n\nenv:\n\n\nAuthelia\nAuthelia - сервер аутентификации и авторизации с открытым исходным кодом, обеспечивающий несколько методов двухфакторной аутентификации и единый вход (SSO) для приложений через веб-портал. Он действует как компаньон для обратных прокси, разрешая, запрещая или перенаправляя запросы.\n\n\nKeycloak\nKeycloak - сервер управления идентификацией и доступом с открытым исходным кодом. Позволяет добавить аутентификацию в приложения и защитить сервисы с минимальными усилиями (не нужно заниматься сохранением данных пользователей или их аутентификацией).\n\n\nZitadel\nZitadel - SSO решение, как альтернатива Keycloak. Поддерживает самообслуживание пользователей и идентификацию с помощью сторонних провайдеров, в том числе OpenID, OAuth 2.x, SAML2, LDAP, Passkey / FIDO2, OTP, 2FA.\n\n\nWarpgate\nWarpgate — интеллектуальный и полностью прозрачный хост-бастион SSH, HTTPS, MySQL и PostgreSQL, которому не требуется клиентское приложение или оболочка SSH. Поддерживает 2FA и SSO (TOTP и OpenID Connect), а также позволяет настроить свой DMZ, добавлять учетные записи пользователей и определять их определенным хостам и URL-адресам в сети. Warpgate будет записывать каждый сеанс, чтобы вы могли просмотреть его в реальном времени и воспроизвести позже через встроенный веб-интерфейс администратора.\n\n\nVoidauth\nVoidauth - провайдер SSO-аутентификации и поставщик OpenID Connect (OIDC) с открытым исходным кодом, который защищает ваши приложения, размещенные на собственном сервере. Поддерживает управление пользователями, пароли, приглашение пользователей, самостоятельную регистрацию, поддержку по электронной почте и другие функции.\n\n\nPAM\n\nJumpServer\nJumpServer - платформа управления привилегированным доступом (PAM - Privileged Access Management) с открытым исходным кодом, которая предоставляет безопасный доступ по требованию к конечным точкам SSH, RDP, Kubernetes, Database и RemoteApp через веб-браузер.\n\n\nLDAP\n\nLLDAP\nLLDAP - облегченный сервер аутентификации (Light LDAP), предоставляющий продуманный и упрощенный интерфейс LDAP для аутентификации и современный интерфейс управления (интегрируется со многими бэкендами, от KeyCloak до Authelia, Nextcloud и другими).\n\n\nGlauth\nGlauth - современный и молодой сервер аутентификации (Go-lang LDAP Authentication) с управлением через конфигурацию и поддержкой метрик Prometheus.\n\n\nOpenLDAP &amp; phpLDAPadmin\nOpenLDAP - реализация протокола Lightweight Directory Access Protocol с открытым исходным кодом. В состав входят LDAP-демон сервера (slapd) и автономный демон балансировки нагрузки LDAP (lloadd).\nphpLDAPadmin - универсальный Веб-интерфейс для LDAP.\n\n\nOpenDJ &amp; LDAP UI\nOpenDJ - совместимая служба каталогов, разработанная для платформы Java и обеспечивающая высокопроизводительное, высокодоступное и безопасное хранилище для идентификационных данных.\nLDAP UI - минималистичный Веб-интерфейс для каталогов LDAP.\n\n\nDocker Stack\n\nDockge\nDockge - веб-интерфейс для управления стеками Docker Compose от создателя Uptime-Kuma.\n\n\nKomodo\nKomodo - система для управления и мониторинга контейнеров Docker и стеков Compose.\n🔗 Komodo Demo ↗\n\nenv:\n\n\n1panel\n1panel - веб-интерфейс для управления сервером на базе Linux, файлами, базами данных, контейнерами Docker и стеками Docker Compose.\n\n\nDockMan\nDockMan - веб-интерфейс для управления контейнерами и файлами в стеках Docker Compose (like Dockge, но без форматирования).\n\n\nDocker Web Manager\nDocker Web Manager - менеджер управления контекстами Docker (context manager) на базе fzf и веб-интерфейс для lazydocker и ctop на базе ttyd с поддержкой авторизации.\n\n\nisaiah\nisaiah - самостоятельный клон LazyDocker для веб-браузера.\n\n\nArcan\nArcane - интерфейс WebUI для управления контейнерами Docker, образами, сетями и томами. Для установки можно использовать генератор compose для настройки подключения БД PostgreSQL и OIDC Authentication.\n\n\nDweebUI\nDweebUI - веб-интерфейс для мониторинга ресурсов и управления контейнерамм, образами, томами и сетями, а также имеет встроенный магазин приложений (не работают логи и нет доступа к терминалу).\n\n\nDockpeek\nDockpeek — это веб-интерфейс для отображения статистики и обновления образов контейнеров Docker.\n\n\nWatchtower\nWatchtower - система для обнаружения новых образов в реестре Docker, а также их автоматического обновления и перезапуска контейнера с отправкой уведомлений.\n\n\nDIUN\nDIUN (Docker Image Update Notifier) - система для получения уведомлений об обновлении образа Docker в реестре Docker.\n\n\nWUD\nWUD (What’s up Docker) - веб-интерфейс для поиска обновлений и автоматизации выполнения действий (отправки оповещений, запуска обновления и т.п.).\n\n\nDozzle\nDozzle - веб интерфейс для просмотра, анализа и фильтрации (по stream, level, а также поиск с помощью regex и sql-запросов) логов контейнеров Docker или Kubernetes. Поддерживает подключение удаленных хостов с помощью агентов или сокета Docker (например, через прокси в ограниченном режиме доступа) и файловым журналам хостовой системы с помощью кастомного контейнера, а также управление контейнерами (запуск, остановка и доступ к терминалу).\n\n\nBeszel\nBeszel - клиент-серверная система мониторинга не требующая настройки для контейнеров Docker и хостов, на которых они запущены. Использует PocketBase для backend, а также поддерживает оповещения в Telegram с помощью Webhook через Shoutrrr.\n\n\nDockMon\nDockMon - платформа для мониторинга и управления Docker-контейнерами, которая поддерживает многохостный мониторинг и предлагает настраиваемый дашборд с WebSocket-обновлениями. Ключевые возможности включают статистику CPU, памяти, сети, просмотр логов, полный журнал событий, систему авто-рестарта и оповещения через различные платформы.\n\n\nDocker Socket Proxy\nDocker Socket Proxy - прокси сервер для локального сокета Docker на основе HAProxy (не требуется внесение изменений в системные файлы демона или службы), который поддерживает ограничение доступа к конечным точкам с использованием переменных окружения, отображение статистики соединений и метрики Prometheus.\n\n\nDocker Registry\n\n\nNexus\nNexus - единый репозиторий для хранения Docker образов (Docker Registry), двоичных файлов, пакетов (например, npm или nuget) и других артефактов.\n\n\nKubernetes Stack\n\nKompose UI\nKompose UI - веб-интерфейс для kompose (конвертирует docker-compose файлы в манифесты Kubernetes).\n\nАльтернативные решения:\nCompose Bridge Transformer - официальный шаблон, который используется в команде docker-compose bridge convert\nKatenary - инструмент для преобразования файлов docker-compose в рабочий Helm Chart для Kubernetes, с помощью одной команды katenary convert -c docker-compose.yml -o ./charts.\n\nWeb kubectl\nWeb kubectl - веб-интерфейс для kubectl и k9s на базе gotty от создателей 1panel. Загружаете собственные конфигурации и переключаетесь между ними в интерфейсе.\n\n\nKubePi\nKubePi — это современная панель управления Kubernetes (like Kubernetes/Dashboard), а также Helm Charts (like Helm Dashboard) от создателей 1panel. Единый интерфейс предоставляет командный доступ управления кластерами, с поддержкой разграничения прав доступа, LDAP, SSO, а также логирует операции управления и авторизации.\n\n\nKubewall\nKubewall - панель управления Kubernetes, с возможностью управления несколькими кластерами (импорт конфигурации через веб-интерфейс) и интеграцией ИИ (OpenAI, Claude, Gemini, DeepSeek, OpenRouter, Ollama, Qwen, LM Studio).\n\n\nKite\nKite - легкая и современная панель управления Kubernetes, с поддержкой переключения между разными кластерами, указанными в kubeconfig.\n🔗 Kite Demo ↗\n\n\nHeadlamp\nHeadlamp - интерфейс для управления и мониторинга кластеров Kubernetes (like Kubernetes/Dashboard) от команды сообщества SIG (Special Interest Groups).\n\n\nHelm Dashboard\nHelm Dashboard - веб-интерфейс для просмотра установленных Helm чартов, истории их изменений и соответствующих ресурсов Kubernetes.\n\n\nKube Ops View\nKube Ops View (Kubernetes Operational View) - read-only системная панель, которая позволяет удобно перемещаться между кластерами, отслеживать ноды и состояние подов (визуализирует ряд процессов, таких как создание и уничтожение подов).\n\n\nKubetail Dashboard\nKubetail Dashboard - веб-интерфейс и инструмент командной строки для отображения логов из разных подов в одном потоке (поддерживает фильтрацию по содержимому сообщений при установки в кластер).\n🔗 Kubetail Dashboard installed in Kubernetes Demo ↗\n\n\nVelero UI\nVelero UI - веб-интерфейс для управления Velero и мониторинга резервного копирования ресурсов в кластерах Kubernetes.\n\n\nVUI\nVUI (Velero UI) - еще один интерфей для управления и мониторинга Velero, который состоит из трех компонентов.\n\n\nRancher\nRancher - инструмент для быстрого запуска и управления кластерами Kubernetes через Веб-интерфейс.\n\n\nk3s\nk3s - легковесный Kubernetes от Rancher/SUSE. Позволяет установить кластер в контейнере Docker или одной командой с помощью скрипта, занимает в два раза меньше памяти, и все это в двоичном файле размером менее 100 МБ.\n\n\nCI/CD Stack\n\nJenkins\nJenkins - CI/CD платформа на базе Java, которая использует свой декларативный синтаксис описания конвееров с поддержкой скриптового языка Groovy, гибкой параметрорезацией и большого числа плагинов.\n🔗 Jenkins Jack VSCode Extension ↗\n\nDockerfile:\n\nenv:\n\n\nGitLab\n\n\nGitea\nGitea - легковесный локальный аналог GitLab/GitHub (самостоятельный хостинг Git), API (с поддержкой Swagger Docs) и системой CI/CD на базе GitHub Actions (поддерживает обратную совместимость) с использованием act.\n🔗 Git Gitea ↗\n🔗 Actions VSCode Extension ↗\n\n\nGoCD\nGoCD - система CI/CD с поддержкой настройки всех этапов (stage, jobs, tasks, exec commands, artifacts, env и params) через пользовательский интерфейс или в формате XML.\n\n\nDrone CI\nDrone CI - CI/CD платформа, построенная на технологии DinD (Docker in Docker)\n\n\nHarness\nHarness - система CI/CD на базе Drone, хостинг исходного кода (gitness) и реестр артефактов с открытым исходным кодом.\n\n\nWoodpecker\nWoodpecker - еще одна платформа CI/CD на базе Drone.\n\n\nSemaphore\nSemaphore - графический интерфейс для Ansible, Terraform, OpenTofu, Bash, Pulumi, Docker и PowerShell, с поддержкой API и LDAP авторизацией.\n\n\nGaia\nGaia - пользовательский интерфейс для импорта и запуска модулей Terraform. Поддерживает импорт модулей из исходного кода (Github/Gitlab), проверку значений переменных Terraform (обязательные переменные, проверка на основе регулярных выражений), настройка значений по умолчанию или маскирование переменных для пользователей, запуск модулей (планирование/применение/уничтожение) и управление состоянием.\n\n\nWexflow\nWexflow - движок автоматизации процессов, который используется для перемещение или преобразование файлов, загрузка на FTP/SFTP, отправка электронных писем, запуск скриптов (PowerShell, Bash, Python и т. д.), планирование и объединение задач в цепочку, запуск рабочих процессов по событиям, cron или watchfolders, визуальное проектирование процессов (интерфейс Designer), интеграция с API и базами данных (поддерживается более 6 баз данных), поддерживает условную логики (if/else, switch, while), более 100 встроенных заданий и мобильное приложение для Android.\n\n\nn8n\nn8n - платформа автоматизации рабочих процессов с встроенными возможностями ИИ. Сочетание визуального создания кода с пользовательским кодом и более 400 интеграций.\n\n\nVault Stack\n\nHashiCorp Vault\nHashiCorp Vault - инструмент хранения и управления секретами (например, API ключи, пароли, сертификаты и многое другое).\nHashiCorp Consul - распределенное и высокодоступное (HA) решение для подключения и настройки приложений в динамической распределенной инфраструктуре, например, для отказоустойчивости Vault.\n\n\nVaultWarden\nVaultWarden - неофициальный легковесный и обратно совместимый сервер современного менеджера паролей Bitwarden, написанный на Rust.\n\n\nPassBolt\nPassBolt - менеджер паролей для совместного использования в командах (поддерживает веб-интерфейс, мобильное и desktop приложение, расширение браузера и интсрумент командной строки).\n🔗 Passbolt Chrome Extension ↗\n\n\nKeeWeb\nKeeWeb - веб-интефрейс и интерфейс рабочего стола для баз данных kdbx.\n🔗 KeeWeb Demo ↗\n🔗 KeeWeb Chrome Extension ↗\n\n\nKeePassXC\nKeePassXC - современный и кроссплатформенный интерфейс KeePass с открытым исходным кодом, а также собранный образ с веб-интерфейсом на базе Selkies.\n\n\nRepo Manager\nRepo Manager - веб-интерфейс для зеркалирования и управления репозиториями rpm и deb, от создателя Motion UI.\n\n\nMonitoring Stack\n\nChange Detection\nChange Detection - следите за обновлениями на веб-сайтах, с поддержкой новостной RSS ленты, REST API, а также уведомлениями в Telegram, Discord, Slack, Webhook и другие каналы.\n\n\nUptime Kuma\nUptime Kuma - инструмент для мониторинга веб-приложений, поддерживающий настройку добавления хостов и правил с помощью веб-интерфейса.\nUptime Kuma API - Swagger документация для Uptime Kuma API.\n🔗 Uptime Kuma Demo ↗\n\n\nGatus\nGatus - современная и ориентированная на разработчиков (IaC подход для управления через конфигурацию) панель мониторинга состояние API и веб-сервисов с помощью HTTP, ICMP, TCP и DNS-запросов, с проверкой результатов тестирования в запросах (используются списки условий, проверка кода ответа, времени ответа, срок действия сертификата, тела запроса, парсинг json и другие функции). Поддерживает экспорт метрик Prometheus и динамическая панель инструментов Grafana.\n🔗 Gatus Health Dashboard Demo ↗\n🔗 Gatus Demo ↗\nВ демо-версии присутствует интерфейс (конструктор) для настройки и проверки правил мониторинга (без экспорта в формате конфигурации).\n\n\nStatPing\nStatPing - страница статуса для проверки доступности веб-сайтов с настройкой в веб-интерфейсе, автоматическим построением графиков и оповещениями в Telegram.\n🔗 StatPing Android ↗\n\n\nGrafana\nGrafana - система для визуализации метрик из более чем 100 источников данных.\n\n\nPrometheus Stack\nPrometheus - система мониторинга и оповещения с открытым исходным кодом, которая собирает и анализирует метрики работы серверов и приложений в реальном времени. Она хранит данные в виде временных рядов (значений с метками времени и ключами/меткам/тегами для идентификации). Веб-интефрейс поддерживает браузер запросов с визуализацией на графиках, отображение ролей из Alertmanager, их статусы и валидность, а также статус работы экспортеров, базы данных TSDB, доступные метки (labels в Service discovery), текущие флаги запуска сервера и итоговая конфигурация для экспорта.\nAlertmanager - система оповещений для экосистемы Prometheus (например, в Telegram, при превышение заданных порого в конфигурации), а также поддерживает свой веб-интерфейс.\nPromLens – веб-конструктор для анализа и визуализации запросов PromQL (уже встроен в интерфейс Prometheus).\nPushGateway - автономный шлюз-экспорт для сбора метрик через API (выступает в роли listener для приема метрик из скриптов, как в InfluxDB).\nBlackbox Exporter - мониторинг ICMP, TCP, DNS, HTTP/HTTPS и gRPC для предоставления метрик в формате Prometheus (похож на Gatus).\nNode Exporter - основной экспортер Prometheus для сбора системных метрик Linux.\nProcess Exporter - экспортер Prometheus для сбора метрик запущенных процессов.\ngithub-exporter - предоставляет базовые метрики для репозиториев из API GitHub через совместимую с Prometheus конечную точку.\ncAdvisor (Container Advisor) - экспортер метрик для всех запущенных контейнеров Docker с собственным веб-интерфейсом от Google.\nLogPorter - простая и легковесная альтернатива cAdvisor для получения всех основных метрик из контейнеров Docker.\n\n\nLoki\nLoki - централизованный сервер и агент promtail для агрегации и хранения логов удаленных систем от Grafana (как Prometheus, но для логов) из файловой системы и контейнеров через сокет Docker с поддержкой фильтрации по node, container, level и tag.\n\n\nJaeger\nJaeger - распределенная система трассировки для анализа времени обработки запросов и ответов к веб-приложениям (например, используется в Traefik), созданная компанией Uber Technologies и переданная в дар Cloud Native Computing Foundation.\n🔗 Demo ↗\n\n\nParca\nParca - система непрерывного профилирования для анализа использования процессора и памяти приложениями, вплоть до номера строки. Использует единый профилировщик eBPF, который автоматически обнаруживает цели из Docker, Kubernetes или systemd, поддерживая C, C++, Rust, Go и другие языки.\n🔗 Demo ↗\n\n\nGraphite\nGraphite - система хранения метрик временных рядов, которая принимает данные по TCP или UDP (например, для отправки данных с помощью netcat) протоколам и состоит из трех основных компонентов:\n\nGraphite Web - веб-интерфейс на django для визуализации метрик на графиках.\nWhisper - файловая БД для временных рядов (хранит данные в .wsp файлах).\nCarbon (TCP) и StatsD (UDP) - агенты для приема метрик по сети (кэширует и записывает данные в БД).\n\nOhmGraphite - экспортер метрик из LibreHardwareMonitor, который работает как служба Windows для отправки данных в Graphite, InfluxdDB, Prometheus или TimescaleDB (база данных временных рядов, упакованная как расширение Postgres).\n\n\nInfluxDB\nСистема мониторинга (экосистема Influx) состоит из следующих компонентов:\n\nInfluxDB - база данных времянных рядов, для хранения метрик.\nTelegraf - агент для сбора, обработки, агрегации и записи метрик, логов и других произвольных данных (поддерживает более 300 плагинов, которые позволяют мониторить системы из коробки, например, inputs.docker).\nChronograf - веб-интерфейс на базе React, который позволяет динамически  визуализировать метрики на графиках (похоже на Grafana и Zabbix), даже без настройки.\n\n1-я версия InfluxDB поддерживает управление базой и отправку данных, используя API (например, с помощью curl).\nInfluxDB Studio - инструмент рабочего стола для управления базами данных InfluxDB 1.8 на базе InfluxData.Net (как MS SSMS).\nFlux - скриптовый язык для запросов к базам данных InfluxDB версии 2.0 и выше.\n\n\nZabbix\n\n\nNetdata\nNetdata - платформа мониторинга инфраструктуры с нулевой настройкой. Поддерживает отображение всех возможных метрик из коробки, TOP процессов, просмотр логов с гистограммой (like Loki), настройка пользовательских Dashboards, оповещений (Alers), а также отображение событий и аномалий.\n🔗 Netdata Demo ↗\n\n\nOpenObserve\nOpen Observe (O2) — централизованная система наблюдения для логов (like Loki), метрик (like Prometheus), трассировок (like Jaeger), аналитики, RUM (мониторинг реальных пользователей — производительность, ошибки, воспроизведение сеансов), предназначенная для работы в масштабах петабайт. Он прост и удобен в использовании, в отличие от Elasticsearch, который требует понимания и настройки множества параметров, позволяет запустить его менее чем за 2 минуты. OpenObserve имеет свой встроенный пользовательский интерфейс, что устраняет необходимость в отдельной установке сторонних инструментов, таких как Kibana.\nПоддерживает большое количество источников данных, например, otel-collector на базе протокола OTLP (OpenTelemetry protocol), а также curl, FluentBit, Filebeat, Logstash, Syslog-ng, Prometheus и Telegraf.\n\n\nHighLight\nHighLight - инструмент мониторинга нового поколения для разработчиков. В отличие от других (устаревших…) инструментов, отличается целостностью. Поддерживает мониторинг ошибок, логов и сессий.\n\n\nELK Stack\nElasticsearch - распределенная поисковая и аналитическая система, основанная на библиотеке Apache Lucene. Она используется для быстрого поиска и анализа больших объемов данных в реальном времени, например, для полнотекстового поиска. Стек состоит из трех приложений:\n\nLogstash - система для сбора логов из различных источников, преобразования их в нужный формат и отправляет в Elasticsearch.\nKibana - веб интерфейс для отображения данных.\nBeats - агент для сбора операционных метрик и логов.\n\nelastop - TUI интерфейс для мониторинга кластеров Elasticsearch в режиме реального времени.\n\n\nGraylog\nGraylog - централизованная система сбора, индексации и анализа логов или других данных из удаленных систем (например, с помощью rsyslog или beats агентов), которая может использовать Elasticsearch или Graylog Data Node для хранения данных.\n\n\nLog Bull\nLog Bull - простая альтернатива ELK и Loki, которая размещается на собственном сервере, не требует настройки и открытый исходный код. Для отправки логов используются библиотеки на разных языка, в т.ч. с помощью curl.\n\n\nRsyslog Collector\nRsyslog Collector - централизованная система для сбора логов, который поддерживает сбор как системных логов (подключение к серверу через конфигурацию /etc/rsyslog.conf), так и контейнеров Docker с помощью драйвера логирования syslog. Контейнер собирает все логи в файл /var/log/all.log и не требует настройки конфигурации.\n\n\nRsyslog Dockerlogs\nRsyslog Dockerlogs - запускает контейнер rsyslog для чтения журналов из демона Docker с помощью модуля imdocker для переадресации в rsyslog сервер.\n\n\nRsyslog GUI\nRsyslog GUI - Rsyslog сервер и веб-интерфейс на базе PimpMyLog для анализа логов (чтения, сортировки и фильтрации по содержимому сообщений).\n\n\nSloggo\nSloggo - легковесный сборщик логов по стандарту RFC 5424 (протокол Syslog) на базе библиотеки go-syslog. Для хранения данных использует встроенную базу данных DuckDB (like SQLite), а также предоставляет интерфейс на базе data-table-filters для поиска и фильтрации.\n\n\nLogspout\nLogspout - маршрутизатор журналов для контейнеров Docker, работающий внутри Docker. Он подключается ко всем контейнерам на хосте и перенаправляет их логи на указанный сервер Syslog.\n\n\nFluent Bit\nFluent Bit - быстрый и легковесный агент для сбора логов, метрик и трассировок в системах Linux, BSD, OSX и Windows.\nПример пересылки логов из контейнера Zerobyte в AWS CloudWatch через Fluent Bit:\n\n\nVector\nVector - сквозной агент и агрегатор данных для сбора метрик и логов и перенаправления их в любые поставщики данных (заявлено, что работает до 10 раз быстрее любого альтернативного решения в этой области).\n\n\nToolong\nToolong - терминальное приложение (TUI) для просмотра, отслеживания, объединения и поиска по содержимому файловых журналов, а также собранный образ с веб-интерфейсом на базе ttyd.\n\n\nWebTail\nWebTail - веб-интерфейс и пакет Go для непрерывного стрименга файлов (приемущественно логов) через веб-сокет в браузер (русский разработчик).\n\n\nPatchMon\nPatchMon - централизованное управление обновлениями в различных серверных средах. Агенты обмениваются данными с сервером PatchMon только по исходящим каналам, исключая входящие порты на контролируемых хостах, обеспечивая при этом всестороннюю видимость и безопасную автоматизацию.\n\n\nScrutiny\nScrutiny - решение для мониторинга и управления состоянием жесткого диска, объединяющее предоставленные производителем показатели SMART с реальными показателями отказов. Встроенная интеграция со smartd, автоматическое определение всех подключенных жестких дисков и настройка уведомлений через web-hook.\n\n\nQDirStat\nQDirStat - графическое приложение для анализа дискового пространства в стиле WizTree и SpaceSniffer, которое предоставляет визуализацию размера папок и файлов в древовидном и цветном формате.\n\n\nHomelab Stack\n\nHome Assistant\nHome Assistant - система домашней автоматизации для управления умными устройствами.\n🔗 Home Assistant Demo ↗\n\n\nHomePage\nHomepage - быстрая и полностью статическая панель управления для быстрого доступа к веб-приложениям в формате закладок. Поддерживает мониторинг доступности веб-сервисов с помощью ICMP и HTTP, нагрузки CPU, памяти и сетевого трафика контейнеров Docker через сокет, автоматическое обнаружение приложений с помощь labels, подключение через конфигурацию к приложениям в кластерах Kubernetes и мониторинг сервисов через API (поддерживает более 100 интеграций с помощью виджетов).\n\n\nGlances\nGlances - TUI интерфейс мониторинга системы, процессов (как top или htop) и контейнеров (как ctop), а также Web режим с адаптивным дизайном для смартфонов. Используется для интеграции показателей в Homepage через виджеты, а также поддерживает экспорт метрик в InfluxDB, Prometheus, PostgreSQL/TimeScaleDB, Graphite и другие базы данных.\n\n\nGlance\nGlance - панель управления, которая объединяет все RSS каналы в одном месте, с встроенной поддержкой Hacker News posts, subreddit, YouTube channel, Twitch channels, релизы GitHub, статусы контейнеров Docker и другие возможности конфигурации.\n\n\nLinkwarden\nLinkwarden - самостоятельный менеджер закладок с открытым исходным кодом для совместной работы, позволяющий собирать, читать, комментировать и полностью сохранять все важное в одном месте.\n\n\nDashy\nDashy - панель управления, которая поддерживает мониторинг статуса, виджеты для отображения информации и динамического контента из собственных сервисов, темы, наборы значков, редактор пользовательского интерфейса, SSO, конфигурация на основе одного yaml файла, а также возможность настройки через веб-интерфейс\n🔗 Dashy Demo ↗\n\n\nHeimdall\nHeimdall - панель управления для любых ссылок на веб-приложения, от создателей проекта Linuxserver.\n\n\nFlame\nFlame - стартовая страница для вашего сервера, размещаемая на собственном сервере. Дизайн вдохновлен SUI, поддерживает аутентификацию, встроенный редактор для добавления и обновления закладок, а также интеграция с Docker и Kubernetes для автоматического добавления приложений на основе labels.\n\n\nThinkDashboard\nThinkDashboard - легковесная, размещаемая на собственном сервере панель закладок, созданная на Go и чистом JavaScript.\n\n\nIt’s MyTabs\nIt’s MyTabs - веб-интерфейс для просмотра и проигрывания табулатуры гитары, похожий на Songsterr, от создателя Uptime-Kuma и Dockge.\n🔗 Demo ↗\n\n\nGrist\nGrist (like MS Excel) - современный реляционный редактор электронных таблиц в вебе и приложением рабочего стола, как достойная замена Microsoft Excel.\n🔗 Grist Demo ↗\n🔗 Grist Static Demo ↗\n🔗 Grist Desktop ↗\n\n\nArchiveBox\nArchiveBox - веб-приложение для сохранения контент с веб-сайтов в различных форматах, с сохранением файлов HTML, PNG, PDF, TXT, JSON, WARC и SQLite, которые гарантированно будут доступны для чтения десятилетиями. Предлагает cli, REST API и Webhooks для интеграции с другими сервисами.\n🔗 ArchiveBox Demo ↗\n\n\nMemos\nMemos - сервис заметок (like Google Keep) с поддержкой синтаксиса Merkdown и интеграцией с Telegram (запись теста и файлов через бота).\n🔗 Memos Demo ↗\n\n\nImmich\nImmich - система хранения и просмотра фото и видео (клон Google Photo).\n🔗 Immich Demo ↗\n\n\nPhotoPrism\nPhotoPrism - приложение для работы с фотографиями на базе искусственного интеллекта, используя современные технологии для автоматического добавления тегов и поиска изображений.\n🔗 PhotoPrism Demo ↗\n\n\nInvidious\nInvidious - альтернативный интерфейс YouTube с открытым исходным кодом.\n\n\nMeTube\nMeTube - Веб-интерфейс для загрузки видео из YouTube с помощь yt-dlp.\n\n\nJitsi Meet\nJitsi Meet - система видео-конференц связи (ВКС/VCS), с выделенными комнатами и управлением доступа (поддерживает демонстрацию экрана и запись разговоров).\n\n\nGuacamole\nApache Guacamole — это клиент-серверное веб-приложение для централизованного удаленного доступа к серверам и рабочим столам на основе протоколов RDP, VNC и SSH через веб-браузер и управления доступом.\n\n\nMeshCentral\nMeshCentral - сервер для управления множеством компьютеров в локальной сети через веб-интерфейс.\n\nenv:\n\n\nEternalVows\nEternalVows - легковесный шаблон свадебного сайта для самостоятельного размещений. Позволяет настроить имена, дату, место проведения, историю, расписание, детали площадки (с картой), ссылки на подарочные реестры, часто задаваемые вопросы и опциональные ссылки для обмена фотографиями через YAML файл без необходимости пересборки.\n\n\nWindows\nWindows внутри контейнера Docker.\n\n\nKanban\n\nFocalboard\nFocalboard - инструмент управления проектами с открытым исходным кодом, который является альтернативой Trello, Notion и Asana (разработка и поддержка прекращена в 2024 году).\n\n\nWekan\nWekan - полностью открытое решение для совместной работы с Kanban досками, развивающиеся с 2015 года.\n\n\nPlanka\nPlanka - инструмент управления проектами в стиле Kanban для команды.\n🔗 Demo ↗\n\n\nKanboard\nKanboard - программное обеспечение для управления проектами, ориентированное на методологию Kanban. Поддерживает хранение данных в SQLite или PostgreSQL.\n\n\nKan\nKan - современное решение Kanban, как льтернатива Trello.\n\n\nNVR\n\nZoneMinder\nZoneMinder - самостоятельная систем видеонаблюдения, которое поддерживает IP, USB и аналоговые камеры, позволяющее осуществлять захват, анализ, запись и мониторинг любых камер видеонаблюдения или систем безопасности, подключенных к компьютеру на базе Linux. Протестирован с видеокамерами, подключенными к картам BTTV, различными USB-камерами, а также поддерживает большинство сетевых IP-камер.\n\n\nScrypted\nScrypted - высокопроизводительная платформа для интеграции сетевого видеорегистратора с интеллектуальными функциями обнаружения. Мгновенная потоковая передача с низкой задержкой для интеграции с HomeKit, Google Home и Alexa.\n\n\nSentryShot\nSentryShot - система видеонаблюдения для просмотра в реальном времени с задержкой менее 2 секунд, поддержкой круглосуточной записи в пользовательскую базу данных, обнаружение объектов с помощью TensorFlow Lite (TFLite) и пользовательской модели, а также адаптивный и уобный веб-интерфейс для мобильных устройств.\n\n\nMotion UI\nMotion UI - веб-интерфейс для управления системой видеонаблюдения Motion от создателя RepoManager.\n\n\nTorrent Stack\nУдаленный SMB каталог для хранения медиа-контента:\n\n\nJackett\nJackett - сервер API и веб-интерфейс для поиска и загрузки торрент файлов из любых индексеров (торрент-трекеров).\n\n\nFreshRSS\nFreshrss - агрегатор RSS-каналов с поддержкой хранения данных в SQLite, PostgreSQL и MySQL/MariaDB, а также предоставляет единую точку всех добавленных RSS лент, API и виджет Homepage.\n🔗 FreshRSS Demo ↗\n\n\nRSS Bridge\nRSS Bridge - генерирует RSS-каналы в форматах Atom/XML и JSON с поддержкой HTML разметки для веб-сайтов, у которых их нет. Поддерживает более 400 мостов, например, из Telegram каналов, фильтрацию по заголовкам или содержимому RSS каланов (например, предварительно сгенерированных).\n🔗 RSS Bridge Demo ↗\n🔗 Public Hosts ↗\n\n\nRSS Proxy\nRSS Proxy - позволяет создавать ATOM или JSON-ленты из любого статического сайта или ленты (Web to Feed), анализирует HTML страницы и преобразует в RSS ленту с поддержкой фильтрации.\nRSS Proxy Demo\n\n\nqBittorrent\nqBittorrent - кросплатформенный торрент-клиент с поддержкой современного веб-интерфейса и адаптивного API. Поддерживает подписку на RSS ленты новостей и поиск торрентов через плагины.\nqBt_SE - плагины поисковой системы qBittorrent для торрент трекеров Kinozal, RuTracker, Rutor и NNM-Club.\nqBitController - приложение с открытым исходным кодом на Kotlin для удаленного управления qBittorrent с устройств Android, iOS, Windows, Linux и macOS.\nElectorrent - rлиент удаленного управления для qBittorrent, Transmission, Deluge, uTorrent, rTorrent и Synology.\n🔗 qBittorrent OpenAPI Docs ↗\n\n\nTransmission\nTransmission - кросплатформенный торрент-клиент с поддержкой веб-интерфейса, API и каталога автоматического обнаружения torrent-файлов для загрузки (возможно интегрировать с Jackett). Поддерживает нативное GUI для macOS, Linux на базе GTK и Windows на базе QT.\nTransmission Remote GUI (TransGUI) - кроссплатформенный desktop интерфейс для удаленного управления демоном Transmission через протокол RPC. Он быстрее и функциональнее встроенного веб-интерфейса Transmission, который визуально похож на qBittorrent и uTorrent.\nTransmission Remote - приложение Android для удаленного управления клиентом Transmission с мобильного телефона.\n\n\nNefarious\nNefarious - веб-приложение для автоматической загрузки фильмов и сериалов. Под капотом используется Jackett для поиска торрентов и Transmission для управления загрузкой.\n\n\nDeluge\nDeluge - торрент-клиент, использующий модель демон-клиент на базе библиотеки libtorrent, который поддерживает пользовательские веб-интерфейс, интерфейс рабочего стола на базе GTK и интерфейс командной строки.\n\n\nCloud Torrent\nCloud Torrent - торрент клиент с поддержкой поиска раздач и просмотра медиа-контента в браузере, от создателя Chisel (быстрый TCP/UDP-туннель, работающий по протоколу HTTP и защищенный через SSH).\n\n\nrQbit\nrQbit - современный торрент-клиент, с поддержкой веб-интерфейса, API, Desktop и cli, а также может использоваться как библиотека на Rust. Поддерживает стриминг видео, включая трансляцию на плееры, например, VLC.\n\n\nPlex\nPlex - медиа-сервер (система потоковой передачи медиаконтента), которая позволяет смотреть фильмы, сериалы, фото и прослушивать музыку на различных устройствах, а также поддерживает API для удаленного управления (без документации, ключ API можно получить только вечер DevTool).\n\n\nTautulli\nTautulli - система мониторинга, аналитики и уведомлений для Plex Media Server с адаптивным дизайном для мобильных устройств.\n\n\nOverseerr\nOverseerr - веб-приложение с собственным интерфейсом для управления запросами к медиа-библиотеки Plex а также интегрируется с Sonarr и Radarr.\n\n\nJellyfin\nJellyfin - медиа-сервер с открытым исходным кодом, который является ответвлением проприетарного Emby с версии 3.5.2 и портированный на платформу .NET для обеспечения полной кроссплатформенной поддержки (API совместим с Emby).\n\n\nJellyseerr\nJellyseerr - fork Overseerr для Jellyfin. Поддерживает полную интеграцию с Jellyfin, Emby и Plex (включая Sonarr и Radarr), включая аутентификацию с импортом и управлением пользователями, а также базы данных SQLite и PostgreSQL.\n\n\nUSM\nUSM (Universal Media Server) - медиасервер, поддерживающий протоколы DLNA, UPnP и HTTP/S. Он способен передавать видео, аудио и изображения между большинством современных устройств. Изначально он был основан на PS3 Media Server от shagrath для обеспечения большей стабильности и совместимости файлов.\n\n\nSonarr\nSonarr - PVR (Personal Video Recorder) для пользователей Usenet и BitTorrent. Он позволяет отслеживать несколько RSS-каналов на предмет новых серий и захватывать, сортировать и переименовывать их. Его также можно настроить на автоматическое повышение качества уже загруженных файлов, когда становится доступен более качественный формат.\n\n\nRadarr\nRadarr - fork Sonarr для работы с фильмами.\n\n\nProwlarr\nProwlarr - менеджер и прокси-сервер для индексаторов, созданный на основе популярного базового стека *arr для интеграции с различными приложениями PVR. Prowlarr поддерживает управление торрент-трекерами, Usenet индексаторами, а также легко интегрируется с Radarr, Sonarr, Lidarr и Readarr, без необходимости настройки индексатора для каждого приложения.\n🔗 Prowlarr API Docs ↗\n\n\nPosterizarr\nPosterizarr - автоматизированный конструктор постеров для Plex и Jellyfin/Emby. Это PowerShell скрипт с полноценным веб-интерфейсом, который автоматизирует генерацию изображений для вашей медиатеки. Он загружает обложки с Fanart.tv, TMDB, TVDB, Plex и IMDb, уделяя особое внимание изображениям без текста и применяя ваши собственные пользовательские наложения и текст.\n\n\nGame Stack\n\nSunshine\nSunshine - самостоятельный хостинг-сервер игровых трансляций (like NVIDIA GameStream и Parsec) для клиента Moonlight.\n\n\nWolf\nWolf - потоковый сервер для Moonlight, который позволяет нескольким удаленным пользователям совместно использовать один сервер для игр. Особенности включают поддержку многопользовательского режима, создание виртуальных столов с возможностью настройки разрешения и FPS, а также одновременное использование различных графических процессоров для задач, таких как кодирование и игры. Сервер обеспечивает низкую задержку в стриминге видео и аудио, совместим с игровыми контроллерами и ориентирован на Linux и Docker, что обеспечивает безопасность в низкопривилегированных контейнерах.\n\n\nDolphin\nDolphin - эмулятор GameCube и Wii собранный в Docker образе для запуска в браузере на базе Selkies.\n\n\nDuckStation\nDuckStation - эмулятор PlayStation 1, собранный в Docker образе.\n\n\nRetroAssembly\nRetroAssembly - библиотека ретро-игры в браузере, с поддержку виртуального контроллера.\n\n\nEmulator.js\nEmulator.js - веб-интерфейс для RetroArch.\n🔗 Emulator.js Demo ↗\n\n\nJunie\nJunie - интерфейс Libretro, работающий в браузере.\n🔗 Junie Demo ↗\n\n\nQuizzle\nQuizzle - платформа проведения викторин для школ от создателя Nexterm и MySpeed.\n\n","path":null}]